<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>È°µÈù¢Ê†áÈ¢ò</title>
    <link rel="stylesheet" href="css/style.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <style>
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            text-align: left;
        }
        
        .code-example pre {
            text-align: left;
            margin: 0;
        }
        
        .code-example code {
            text-align: left;
        }
        
        pre {
            text-align: left !important;
        }
        
        code {
            text-align: left !important;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        
        /* Ê¶ÇÂøµËß£ÈáäÊ†∑Âºè */
        .concept-explanation {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 12px;
            margin: 20px 0;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
            position: relative;
            overflow: hidden;
        }
        
        .concept-explanation::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #ffd700, #ff6b6b, #4ecdc4, #45b7d1);
        }
        
        .concept-explanation h4 {
            margin: 0 0 15px 0;
            font-size: 1.2em;
            font-weight: bold;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .concept-explanation p {
            margin: 10px 0;
            line-height: 1.6;
            font-size: 0.95em;
        }
        
        .concept-explanation strong {
            color: #ffd700;
            font-weight: bold;
        }
        
        /* ÂÖ¨ÂºèËß£ÈáäÊ†∑Âºè */
        .formula-explanation {
            background-color: #f8f9ff;
            color: #4a5568;
            padding: 8px 12px;
            border-left: 3px solid #667eea;
            margin: 5px 0 15px 20px;
            font-style: italic;
            font-size: 0.9em;
            border-radius: 0 6px 6px 0;
        }
        
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
            position: relative;
        }
        
        .math-formula::before {
            content: 'üìê';
            position: absolute;
            top: 10px;
            right: 15px;
            font-size: 1.2em;
            opacity: 0.6;
        }
        
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        
        /* È°∂ÈÉ®ÂØºËà™ÊåâÈîÆÊ†∑Âºè */
        .top-navigation {
            margin: 20px 0;
            padding: 20px;
            background: rgba(248, 249, 250, 0.8);
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
        
        .nav-btn {
            background: linear-gradient(135deg, #007bff, #0056b3);
            color: white;
            border: none;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.9em;
            box-shadow: 0 2px 8px rgba(0, 123, 255, 0.3);
        }
        
        .nav-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0, 123, 255, 0.4);
            background: linear-gradient(135deg, #0056b3, #004085);
        }
        
        .nav-btn.active {
            background: linear-gradient(135deg, #28a745, #1e7e34);
            box-shadow: 0 4px 15px rgba(40, 167, 69, 0.4);
            transform: translateY(-1px);
        }
        
        .nav-btn.active:hover {
            background: linear-gradient(135deg, #1e7e34, #155724);
        }
        
        /* ÂÜÖÂÆπÂàÜÈ°µÊ†∑Âºè */
        .content-section {
            display: none;
            animation: fadeIn 0.5s ease-in;
        }
        
        .content-section.active {
            display: block;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        /* ÂìçÂ∫îÂºèËÆæËÆ° */
        @media (max-width: 768px) {
            .nav-btn {
                padding: 8px 12px;
                margin: 3px;
                font-size: 0.8em;
            }
            
            .top-navigation {
                padding: 15px;
            }
        }
        
        @media (max-width: 480px) {
            .nav-btn {
                padding: 6px 10px;
                margin: 2px;
                font-size: 0.75em;
                display: block;
                width: 100%;
                margin-bottom: 8px;
            }
            
            .top-navigation {
                padding: 10px;
            }
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="navigation-container"></div>



<script>
// Âä®ÊÄÅÂä†ËΩΩÂØºËà™Êù°
function loadNavigation() {
    fetch('nav.html')
        .then(response => response.text())
        .then(html => {
            // Êõ¥Êñ∞ÂØºËà™‰∏≠ÁöÑÈìæÊé•Ë∑ØÂæÑ
            let updatedHtml = html;
            
            // Â§ÑÁêÜÊ†πÁõÆÂΩïÊñá‰ª∂ÈìæÊé•Ôºàindex.html, syllabus.htmlÁ≠âÔºâ
            updatedHtml = updatedHtml.replace(/href="index\.html"/g, 'href="index.html"');
            updatedHtml = updatedHtml.replace(/href="\.\/([^/]*\.html)"/g, 'href="$1"');
            
            // Â§ÑÁêÜÊ®°ÂùóË∑ØÂæÑÈìæÊé•ÔºàÂ∑≤ÁªèÊòØÂÆåÊï¥Áõ∏ÂØπË∑ØÂæÑÔºåÂè™ÈúÄË¶ÅÊ∑ªÂä†Ê†πË∑ØÂæÑÂâçÁºÄÔºâ
            updatedHtml = updatedHtml.replace(/href="\.\/part([^"]*)"/g, 'href="part$1"');
            
            document.getElementById('navigation-container').innerHTML = updatedHtml;
            
            // Ê∑ªÂä†ÁßªÂä®Á´ØËèúÂçïÂàáÊç¢ÂäüËÉΩ
            const menuToggle = document.getElementById('menuToggle');
            const navMenu = document.querySelector('.nav-menu');
            if (menuToggle && navMenu) {
                menuToggle.addEventListener('click', function() {
                    navMenu.classList.toggle('active');
                });
            }
        })
        .catch(error => console.error('ÂØºËà™Âä†ËΩΩÂ§±Ë¥•:', error));
}

// È°µÈù¢Âä†ËΩΩÂÆåÊàêÂêéÂä†ËΩΩÂØºËà™
document.addEventListener('DOMContentLoaded', loadNavigation);
</script>



    
    <style>
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
    </style>
    

                </div>
            
<!-- ‰∏ªÂÜÖÂÆπÂå∫Âüü -->
            <div class="container">
                <h1 class="text-center mb-4">Ê∑±Â∫¶Â≠¶‰π†Âú®ÈáëËûç‰∏≠ÁöÑÂ∫îÁî®</h1>
                
                <!-- È°∂ÈÉ®ÂØºËà™ÊåâÈîÆ -->
                <div class="top-navigation text-center mb-4">
                    <button class="nav-btn active" data-section="overview">üß† Ê∑±Â∫¶Â≠¶‰π†Ê¶ÇËø∞</button>
                    <button class="nav-btn" data-section="neural-networks">üîó Á•ûÁªèÁΩëÁªúÂü∫Á°Ä</button>
                    <button class="nav-btn" data-section="lstm-models">üîÑ LSTMÊó∂Èó¥Â∫èÂàó</button>
                    <button class="nav-btn" data-section="cnn-models">üñºÔ∏è CNNÂõæÂÉèËØÜÂà´</button>
                    <button class="nav-btn" data-section="transformer-models">üîÑ TransformerÊ≥®ÊÑèÂäõ</button>
                    <button class="nav-btn" data-section="gan-models">üé≠ ÁîüÊàêÂØπÊäóÁΩëÁªú</button>
                    <button class="nav-btn" data-section="reinforcement-learning">üéØ Âº∫ÂåñÂ≠¶‰π†</button>
                    <button class="nav-btn" data-section="autoencoder">üîÑ Ëá™ÁºñÁ†ÅÂô®</button>
                    <button class="nav-btn" data-section="practical-applications">üíº ÂÆûÈôÖÂ∫îÁî®</button>
                    <button class="nav-btn" data-section="performance-comparison">üìä ÊÄßËÉΩÂØπÊØî</button>
                </div>
                    <!-- Ê¶ÇËø∞ -->
    <main class="container">
                    <section id="overview" class="content-section mb-5">
                        <h2>üß† Ê∑±Â∫¶Â≠¶‰π†Ê¶ÇËø∞</h2>
                        <p>Ê∑±Â∫¶Â≠¶‰π†ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåÈÄöËøáÊûÑÂª∫Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÊù•Â≠¶‰π†Êï∞ÊçÆÁöÑÂ§çÊùÇÊ®°Âºè„ÄÇÂú®ÈáëËûçÈ¢ÜÂüüÔºåÊ∑±Â∫¶Â≠¶‰π†Ë¢´ÂπøÊ≥õÂ∫îÁî®‰∫é‰ª∑Ê†ºÈ¢ÑÊµã„ÄÅÈ£éÈô©ÁÆ°ÁêÜ„ÄÅÁÆóÊ≥ï‰∫§Êòì„ÄÅÊ¨∫ËØàÊ£ÄÊµãÁ≠âÂú∫ÊôØ„ÄÇ</p>
                        <div class="math-formula">
                            <h5>Ê∑±Â∫¶Â≠¶‰π†ÁöÑÊ†∏ÂøÉÊ¶ÇÂøµ</h5>
                            <div class="concept-explanation">
                                <h4>üí° ‰∏∫‰ªÄ‰πàÈúÄË¶ÅËøô‰∫õÁ•ûÁªèÁΩëÁªúÂÖ¨ÂºèÔºü</h4>
                                <p>Á•ûÁªèÁΩëÁªúÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÊ®°Êãü‰∫∫ËÑëÁ•ûÁªèÂÖÉÁöÑÂ∑•‰ΩúÊñπÂºè„ÄÇÂú®ÈáëËûçÈ¢ÑÊµã‰∏≠ÔºåÊàë‰ª¨ÈúÄË¶Å‰ªéÂ§çÊùÇÁöÑÂ∏ÇÂú∫Êï∞ÊçÆ‰∏≠ÊâæÂà∞ÈöêËóèÁöÑÊ®°ÂºèÔºåËÄå‰º†ÁªüÁöÑÁ∫øÊÄßÊ®°ÂûãÂæÄÂæÄÊó†Ê≥ïÊçïÊçâËøô‰∫õÈùûÁ∫øÊÄßÂÖ≥Á≥ª„ÄÇ</p>
                                <p><strong>ÁîüÊ¥ªÂåñÁêÜËß£Ôºö</strong>Â∞±ÂÉè‰∫∫Á±ªÂ≠¶‰π†ÊäïËµÑ‰∏ÄÊ†∑ÔºåÊàë‰ª¨ÂÖàËßÇÂØüÂ∏ÇÂú∫Êï∞ÊçÆÔºàÂâçÂêë‰º†Êí≠ÔºâÔºåÁÑ∂ÂêéÊ†πÊçÆÁªìÊûúÁöÑÂ•ΩÂùèË∞ÉÊï¥Êàë‰ª¨ÁöÑÂà§Êñ≠Ê†áÂáÜÔºàÂèçÂêë‰º†Êí≠ÔºâÔºå‰∏çÊñ≠ÈáçÂ§çËøô‰∏™ËøáÁ®ãÁõ¥Âà∞ÂÅöÂá∫ÂáÜÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇ</p>
                                <p><strong>ÂÆûÈôÖÂ∫îÁî®Ôºö</strong>Âú®ËÇ°‰ª∑È¢ÑÊµã‰∏≠ÔºåÁ•ûÁªèÁΩëÁªúÂèØ‰ª•ÂêåÊó∂ËÄÉËôëÊäÄÊúØÊåáÊ†á„ÄÅÂü∫Êú¨Èù¢Êï∞ÊçÆ„ÄÅÂ∏ÇÂú∫ÊÉÖÁª™Á≠âÂ§ö‰∏™Âõ†Á¥†ÔºåÂπ∂Ëá™Âä®ÂèëÁé∞ÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇ</p>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>üîç ÂâçÂêë‰º†Êí≠ÂÖ¨ÂºèÊé®ÂØº</h4>
                                <p><strong>Ê≠•È™§1ÔºöÁ∫øÊÄßÂèòÊç¢</strong></p>
                                <p>ÂØπ‰∫éÁ¨¨lÂ±ÇÔºåÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜÂâç‰∏ÄÂ±ÇÁöÑËæìÂá∫a^[l-1]ËΩ¨Êç¢‰∏∫ÂΩìÂâçÂ±ÇÁöÑËæìÂÖ•z^[l]Ôºö</p>
                            </div>
                            \[ z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]} \]
                            <div class="formula-explanation">
                                <p><strong>ÂÖ¨ÂºèÂê´‰πâÔºö</strong></p>
                                <ul>
                                    <li>W^[l]ÔºöÁ¨¨lÂ±ÇÁöÑÊùÉÈáçÁü©ÈòµÔºåÁª¥Â∫¶‰∏∫(n^[l], n^[l-1])</li>
                                    <li>a^[l-1]ÔºöÂâç‰∏ÄÂ±ÇÁöÑÊøÄÊ¥ªËæìÂá∫ÔºåÁª¥Â∫¶‰∏∫(n^[l-1], 1)</li>
                                    <li>b^[l]ÔºöÁ¨¨lÂ±ÇÁöÑÂÅèÁΩÆÂêëÈáèÔºåÁª¥Â∫¶‰∏∫(n^[l], 1)</li>
                                    <li>z^[l]ÔºöÁ¨¨lÂ±ÇÁöÑÁ∫øÊÄßËæìÂá∫ÔºåÁª¥Â∫¶‰∏∫(n^[l], 1)</li>
                                </ul>
                                <p><strong>ËÆ°ÁÆóÁ§∫‰æãÔºö</strong>ÂÅáËÆæËæìÂÖ•Â±ÇÊúâ3‰∏™ÁâπÂæÅÔºàÂºÄÁõò‰ª∑„ÄÅÊàê‰∫§Èáè„ÄÅÊäÄÊúØÊåáÊ†áÔºâÔºåÈöêËóèÂ±ÇÊúâ4‰∏™Á•ûÁªèÂÖÉÔºö</p>
                                <pre>
W^[1] = [[0.2, 0.3, -0.1],    a^[0] = [[100],     b^[1] = [[0.1],
         [0.1, -0.2, 0.4],              [1000],              [0.2],
         [-0.3, 0.5, 0.2],              [0.6]]               [0.0],
         [0.4, 0.1, -0.2]]                                   [-0.1]]

z^[1] = W^[1] √ó a^[0] + b^[1] = [[0.2√ó100 + 0.3√ó1000 - 0.1√ó0.6 + 0.1],
                                 [0.1√ó100 - 0.2√ó1000 + 0.4√ó0.6 + 0.2],
                                 [-0.3√ó100 + 0.5√ó1000 + 0.2√ó0.6 + 0.0],
                                 [0.4√ó100 + 0.1√ó1000 - 0.2√ó0.6 - 0.1]]
      = [[319.84], [-179.56], [470.12], [49.78]]
                                </pre>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>üîç ÊøÄÊ¥ªÂáΩÊï∞Êé®ÂØº</h4>
                                <p><strong>Ê≠•È™§2ÔºöÈùûÁ∫øÊÄßÊøÄÊ¥ª</strong></p>
                                <p>Á∫øÊÄßÂèòÊç¢ÂêéÔºåÊàë‰ª¨ÈúÄË¶ÅÈÄöËøáÊøÄÊ¥ªÂáΩÊï∞ÂºïÂÖ•ÈùûÁ∫øÊÄßÔºö</p>
                            </div>
                            \[ a^{[l]} = g^{[l]}(z^{[l]}) \]
                            <div class="formula-explanation">
                                <p><strong>ÊøÄÊ¥ªÂáΩÊï∞ÈÄâÊã©ÂéüÁêÜÔºö</strong></p>
                                <ul>
                                    <li><strong>ReLUÔºö</strong>g(z) = max(0, z)ÔºåËÆ°ÁÆóÁÆÄÂçïÔºåÈÅøÂÖçÊ¢ØÂ∫¶Ê∂àÂ§±</li>
                                    <li><strong>SigmoidÔºö</strong>g(z) = 1/(1+e^(-z))ÔºåËæìÂá∫[0,1]ÔºåÈÄÇÂêàÊ¶ÇÁéá</li>
                                    <li><strong>TanhÔºö</strong>g(z) = (e^z - e^(-z))/(e^z + e^(-z))ÔºåËæìÂá∫[-1,1]ÔºåÈõ∂‰∏≠ÂøÉ</li>
                                </ul>
                                <p><strong>ËÆ°ÁÆóÁ§∫‰æãÔºà‰ΩøÁî®ReLUÔºâÔºö</strong></p>
                                <pre>
z^[1] = [[319.84], [-179.56], [470.12], [49.78]]
a^[1] = ReLU(z^[1]) = [[319.84], [0], [470.12], [49.78]]
                                </pre>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>üîç ÂèçÂêë‰º†Êí≠Êé®ÂØº</h4>
                                <p><strong>Ê†∏ÂøÉÊÄùÊÉ≥Ôºö</strong>‰ΩøÁî®ÈìæÂºèÊ≥ïÂàôËÆ°ÁÆóÊçüÂ§±ÂáΩÊï∞ÂØπÊØè‰∏™ÂèÇÊï∞ÁöÑÊ¢ØÂ∫¶</p>
                                <p><strong>Êé®ÂØºËøáÁ®ãÔºö</strong></p>
                                <p>1. Ê†πÊçÆÈìæÂºèÊ≥ïÂàôÔºö‚àÇL/‚àÇW^[l] = (‚àÇL/‚àÇz^[l]) √ó (‚àÇz^[l]/‚àÇW^[l])</p>
                                <p>2. Áî±‰∫éz^[l] = W^[l]a^[l-1] + b^[l]ÔºåÊâÄ‰ª•‚àÇz^[l]/‚àÇW^[l] = a^[l-1]</p>
                                <p>3. Âõ†Ê≠§ÂæóÂà∞ÊùÉÈáçÊ¢ØÂ∫¶ÂÖ¨Âºè</p>
                            </div>
                            \[ \frac{\partial L}{\partial W^{[l]}} = \frac{\partial L}{\partial z^{[l]}} \cdot a^{[l-1]T} \]
                            <div class="formula-explanation">
                                <p><strong>ËÆ°ÁÆóÁ§∫‰æãÔºö</strong>ÂÅáËÆæ‚àÇL/‚àÇz^[1] = [[0.1], [0], [0.2], [0.05]]</p>
                                <pre>
‚àÇL/‚àÇW^[1] = ‚àÇL/‚àÇz^[1] √ó a^[0]^T
          = [[0.1],  √ó [[100, 1000, 0.6]]
             [0],
             [0.2],
             [0.05]]
          = [[10, 100, 0.06],
             [0, 0, 0],
             [20, 200, 0.12],
             [5, 50, 0.03]]
                                </pre>
                            </div>
                            
                            \[ \frac{\partial L}{\partial b^{[l]}} = \frac{\partial L}{\partial z^{[l]}} \]
                            <div class="formula-explanation">
                                <p><strong>ÂÅèÁΩÆÊ¢ØÂ∫¶Ôºö</strong>Áî±‰∫éz^[l] = W^[l]a^[l-1] + b^[l]Ôºå‚àÇz^[l]/‚àÇb^[l] = 1</p>
                                <p><strong>ËÆ°ÁÆóÁ§∫‰æãÔºö</strong>‚àÇL/‚àÇb^[1] = [[0.1], [0], [0.2], [0.05]]</p>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>üîç Ê¢ØÂ∫¶‰∏ãÈôçÊõ¥Êñ∞</h4>
                                <p><strong>Êõ¥Êñ∞ÂéüÁêÜÔºö</strong>Ê≤øÁùÄÊ¢ØÂ∫¶ÁöÑÂèçÊñπÂêëÁßªÂä®ÔºåÂØªÊâæÊçüÂ§±ÂáΩÊï∞ÁöÑÊúÄÂ∞èÂÄº</p>
                                <p><strong>Â≠¶‰π†ÁéáÈÄâÊã©Ôºö</strong>Â§™Â§ßÂèØËÉΩË∑≥ËøáÊúÄ‰ºòËß£ÔºåÂ§™Â∞èÊî∂ÊïõÂ§™ÊÖ¢</p>
                            </div>
                            \[ W^{[l]} := W^{[l]} - \alpha \frac{\partial L}{\partial W^{[l]}} \]
                            <div class="formula-explanation">
                                <p><strong>ÂèÇÊï∞Êõ¥Êñ∞Á§∫‰æãÔºö</strong>ÂÅáËÆæÂ≠¶‰π†ÁéáŒ± = 0.01</p>
                                <pre>
W^[1]_new = W^[1]_old - 0.01 √ó ‚àÇL/‚àÇW^[1]
          = [[0.2, 0.3, -0.1],     [[10, 100, 0.06],
             [0.1, -0.2, 0.4],  - 0.01 √ó [0, 0, 0],
             [-0.3, 0.5, 0.2],       [20, 200, 0.12],
             [0.4, 0.1, -0.2]]       [5, 50, 0.03]]
          = [[0.1, -0.7, -0.1006],
             [0.1, -0.2, 0.4],
             [-0.5, -1.5, 0.0788],
             [0.35, -0.4, -0.2003]]
                                </pre>
                                <p><strong>Êî∂ÊïõÂà§Êñ≠Ôºö</strong>ÂΩìÊ¢ØÂ∫¶Êé•ËøëÈõ∂ÊàñÊçüÂ§±ÂáΩÊï∞ÂèòÂåñÂæàÂ∞èÊó∂ÂÅúÊ≠¢ËÆ≠ÁªÉ</p>
                            </div>
                        
<div class="row">
                            <div class="col-md-6">
                                <h5>Ê∑±Â∫¶Â≠¶‰π†Âú®ÈáëËûç‰∏≠ÁöÑ‰ºòÂäø</h5>
                                <ul>
                                    <li>Ëá™Âä®ÁâπÂæÅÊèêÂèñ</li>
                                    <li>Â§ÑÁêÜÈùûÁ∫øÊÄßÂÖ≥Á≥ª</li>
                                    <li>ÈÄÇÂ∫îÂ§ßËßÑÊ®°Êï∞ÊçÆ</li>
                                    <li>Á´ØÂà∞Á´ØÂ≠¶‰π†</li>
                                    <li>ÂÆûÊó∂È¢ÑÊµãËÉΩÂäõ</li>
                                </ul>
                            
<div class="col-md-6">
                                <h5>‰∏ªË¶ÅÂ∫îÁî®Âú∫ÊôØ</h5>
                                <ul>
                                    <li>ËÇ°‰ª∑È¢ÑÊµã‰∏éË∂ãÂäøÂàÜÊûê</li>
                                    <li>‰ø°Áî®È£éÈô©ËØÑ‰º∞</li>
                                    <li>È´òÈ¢ë‰∫§ÊòìÁ≠ñÁï•</li>
                                    <li>Ê¨∫ËØàÊ£ÄÊµã</li>
                                    <li>ÊäïËµÑÁªÑÂêà‰ºòÂåñ</li>
                                </ul>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- Á•ûÁªèÁΩëÁªúÂü∫Á°Ä -->
                    <section id="neural-networks" class="content-section mb-5">
                        <h2>üîó Á•ûÁªèÁΩëÁªúÂü∫Á°Ä</h2>
                        <div class="model-card">
                            <h4>Â§öÂ±ÇÊÑüÁü•Êú∫ (MLP) <span class="badge bg-info complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(n¬∑m¬∑h¬∑e)</span></h4>
                            <div class="concept-explanation">
                                <h4>üí° ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÊøÄÊ¥ªÂáΩÊï∞ÂíåÊçüÂ§±ÂáΩÊï∞Ôºü</h4>
                                <p>ÊøÄÊ¥ªÂáΩÊï∞ÊòØÁ•ûÁªèÁΩëÁªúÁöÑ"ÂºÄÂÖ≥"ÔºåÂÜ≥ÂÆöÁ•ûÁªèÂÖÉÊòØÂê¶Ë¢´ÊøÄÊ¥ª„ÄÇÂú®ÈáëËûçÂª∫Ê®°‰∏≠ÔºåÂ∏ÇÂú∫ÂèçÂ∫îÂæÄÂæÄÊòØÈùûÁ∫øÊÄßÁöÑ‚Äî‚ÄîÂ∞èÁöÑÂèòÂåñÂèØËÉΩÂºïËµ∑Â§ßÁöÑÊ≥¢Âä®ÔºåÊàñËÄÖÂú®Êüê‰∏™ÈòàÂÄº‰πãÂâçÊØ´Êó†ÂèçÂ∫î„ÄÇ</p>
                                <p><strong>ÊøÄÊ¥ªÂáΩÊï∞ÈÄâÊã©Ôºö</strong>ReLUÈÄÇÂêàÊ∑±Â±ÇÁΩëÁªúÔºàÈÅøÂÖçÊ¢ØÂ∫¶Ê∂àÂ§±ÔºâÔºåSigmoidÈÄÇÂêàÊ¶ÇÁéáËæìÂá∫ÔºàÂ¶ÇÊ∂®Ë∑åÊ¶ÇÁéáÔºâÔºåTanhÈÄÇÂêàÈúÄË¶ÅË¥üÂÄºÁöÑÂú∫ÊôØ„ÄÇ</p>
                                <p><strong>ÊçüÂ§±ÂáΩÊï∞‰ΩúÁî®Ôºö</strong>Ë°°ÈáèÈ¢ÑÊµã‰∏éÂÆûÈôÖÁöÑÂ∑ÆË∑ùÔºåÊåáÂØºÊ®°ÂûãÂ≠¶‰π†ÊñπÂêë„ÄÇMSEÈÄÇÂêàÂõûÂΩí‰ªªÂä°ÔºàÂ¶Ç‰ª∑Ê†ºÈ¢ÑÊµãÔºâÔºå‰∫§ÂèâÁÜµÈÄÇÂêàÂàÜÁ±ª‰ªªÂä°ÔºàÂ¶ÇÊ∂®Ë∑åÂà§Êñ≠Ôºâ„ÄÇ</p>
                            </div>
                            <div class="math-formula">
                                <h5>Êï∞Â≠¶ÂéüÁêÜ</h5>
                                <p><strong>ÊøÄÊ¥ªÂáΩÊï∞Ôºö</strong></p>
                                \[ \text{ReLU}(x) = \max(0, x) \]
                                <p class="formula-explanation">‰øÆÊ≠£Á∫øÊÄßÂçïÂÖÉÔºö‰øùÁïôÊ≠£ÂÄºÔºåÊäëÂà∂Ë¥üÂÄºÔºåËÆ°ÁÆóÁÆÄÂçï‰∏îÊúâÊïàÈò≤Ê≠¢Ê¢ØÂ∫¶Ê∂àÂ§±</p>
                                \[ \text{Sigmoid}(x) = \frac{1}{1 + e^{-x}} \]
                                <p class="formula-explanation">SÂûãÂáΩÊï∞ÔºöËæìÂá∫ËåÉÂõ¥[0,1]ÔºåÈÄÇÂêàÊ¶ÇÁéáÈ¢ÑÊµãÔºåÂ¶ÇËÇ°Á•®‰∏äÊ∂®Ê¶ÇÁéá</p>
                                \[ \text{Tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \]
                                <p class="formula-explanation">ÂèåÊõ≤Ê≠£ÂàáÔºöËæìÂá∫ËåÉÂõ¥[-1,1]ÔºåÈõ∂‰∏≠ÂøÉÂåñÔºåÊî∂ÊïõÊõ¥Âø´</p>
                                <p><strong>ÊçüÂ§±ÂáΩÊï∞Ôºö</strong></p>
                                \[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \]
                                <p class="formula-explanation">ÂùáÊñπËØØÂ∑ÆÔºöË°°ÈáèÈ¢ÑÊµãÂÄº‰∏éÁúüÂÆûÂÄºÁöÑÂπ≥ÊñπÂ∑ÆÔºåÈÄÇÂêàÂõûÂΩí‰ªªÂä°Â¶ÇËÇ°‰ª∑È¢ÑÊµã</p>
                                \[ \text{Cross-Entropy} = -\sum_{i=1}^{n} y_i \log(\hat{y}_i) \]
                                <p class="formula-explanation">‰∫§ÂèâÁÜµÔºöË°°ÈáèÊ¶ÇÁéáÂàÜÂ∏ÉÂ∑ÆÂºÇÔºåÈÄÇÂêàÂàÜÁ±ª‰ªªÂä°Â¶ÇÊ∂®Ë∑åÊñπÂêëÈ¢ÑÊµã</p>
                            
<div class="neural-network-viz" id="mlp-visualization">
                                <h6>MLPÁΩëÁªúÁªìÊûÑÂèØËßÜÂåñ</h6>
                                <!-- ËøôÈáåÂ∞ÜÈÄöËøáJavaScriptÂä®ÊÄÅÁîüÊàêÁΩëÁªúÂõæ -->
                            
<div class="code-example">
                                <h6>ËÇ°‰ª∑È¢ÑÊµãMLPÂÆûÁé∞</h6>
                                <pre><code class="language-python">
import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
class StockPriceMLP:
    """
    ËÇ°‰ª∑È¢ÑÊµãÂ§öÂ±ÇÊÑüÁü•Êú∫
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(n¬∑m¬∑h¬∑e) - n:Ê†∑Êú¨Êï∞, m:ÁâπÂæÅÊï∞, h:ÈöêËóèÂ±ÇÁ•ûÁªèÂÖÉÊï∞, e:ËÆ≠ÁªÉËΩÆÊï∞
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(m¬∑h + h¬∑o) - o:ËæìÂá∫Â±ÇÁ•ûÁªèÂÖÉÊï∞
    """
    def __init__(self, input_dim, hidden_layers=[64, 32], dropout_rate=0.2):
        self.input_dim = input_dim
        self.hidden_layers = hidden_layers
        self.dropout_rate = dropout_rate
        self.model = None
        self.scaler = MinMaxScaler()
    def build_model(self):
        """ÊûÑÂª∫MLPÊ®°Âûã"""
        model = tf.keras.Sequential()
        # ËæìÂÖ•Â±Ç
        model.add(tf.keras.layers.Dense(
            self.hidden_layers[0],
            input_dim=self.input_dim,
            activation='relu',
            kernel_regularizer=tf.keras.regularizers.l2(0.001)
        ))
        model.add(tf.keras.layers.Dropout(self.dropout_rate))
        # ÈöêËóèÂ±Ç
        for units in self.hidden_layers[1:]:
            model.add(tf.keras.layers.Dense(
                units,
                activation='relu',
                kernel_regularizer=tf.keras.regularizers.l2(0.001)
            ))
            model.add(tf.keras.layers.Dropout(self.dropout_rate))
        # ËæìÂá∫Â±Ç
        model.add(tf.keras.layers.Dense(1, activation='linear'))
        # ÁºñËØëÊ®°Âûã
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
    def prepare_data(self, data, target_col='close', lookback=30):
        """ÂáÜÂ§áËÆ≠ÁªÉÊï∞ÊçÆ"""
        # ÁâπÂæÅÂ∑•Á®ã
        features = self.create_features(data)
        # ÂàõÂª∫Êó∂Èó¥Â∫èÂàóÊï∞ÊçÆ
        X, y = [], []
        for i in range(lookback, len(features)):
            X.append(features.iloc[i-lookback:i].values.flatten())
            y.append(data[target_col].iloc[i])
        X = np.array(X)
        y = np.array(y)
        # Êï∞ÊçÆÊ†áÂáÜÂåñ
        X_scaled = self.scaler.fit_transform(X)
        return X_scaled, y
    def create_features(self, data):
        """ÂàõÂª∫ÊäÄÊúØÊåáÊ†áÁâπÂæÅ"""
        df = data.copy()
        # ‰ª∑Ê†ºÁâπÂæÅ
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        # ÁßªÂä®Âπ≥Âùá
        for period in [5, 10, 20, 50]:
            df[f'sma_{period}'] = df['close'].rolling(period).mean()
            df[f'ema_{period}'] = df['close'].ewm(span=period).mean()
        # ÊäÄÊúØÊåáÊ†á
        df['rsi'] = self.calculate_rsi(df['close'])
        df['macd'], df['macd_signal'] = self.calculate_macd(df['close'])
        df['bb_upper'], df['bb_lower'] = self.calculate_bollinger_bands(df['close'])
        # Ê≥¢Âä®ÁéáÁâπÂæÅ
        df['volatility'] = df['returns'].rolling(20).std()
        df['volume_sma'] = df['volume'].rolling(20).mean()
        return df.dropna()
    def calculate_rsi(self, prices, period=14):
        """ËÆ°ÁÆóRSIÊåáÊ†á"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    def calculate_macd(self, prices, fast=12, slow=26, signal=9):
        """ËÆ°ÁÆóMACDÊåáÊ†á"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal
    def calculate_bollinger_bands(self, prices, period=20, std_dev=2):
        """ËÆ°ÁÆóÂ∏ÉÊûóÂ∏¶"""
        sma = prices.rolling(period).mean()
        std = prices.rolling(period).std()
        upper = sma + (std * std_dev)
        lower = sma - (std * std_dev)
        return upper, lower
    def train(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):
        """ËÆ≠ÁªÉÊ®°Âûã"""
        if self.model is None:
            self.build_model()
        # ÂõûË∞ÉÂáΩÊï∞
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss', patience=10, restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6
            )
        ]
        # ËÆ≠ÁªÉÊ®°Âûã
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        return history
    def predict(self, X):
        """È¢ÑÊµã"""
        return self.model.predict(X)
    def evaluate_model(self, X_test, y_test):
        """ËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩ"""
        y_pred = self.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        # ÊñπÂêëÂáÜÁ°ÆÁéá
        direction_accuracy = self.calculate_direction_accuracy(y_test, y_pred)
        return {
            'MSE': mse,
            'MAE': mae,
            'RMSE': rmse,
            'Direction_Accuracy': direction_accuracy
        }
    def calculate_direction_accuracy(self, y_true, y_pred):
        """ËÆ°ÁÆóÊñπÂêëÈ¢ÑÊµãÂáÜÁ°ÆÁéá"""
        true_direction = np.diff(y_true) > 0
        pred_direction = np.diff(y_pred.flatten()) > 0
        return np.mean(true_direction == pred_direction)
# ‰ΩøÁî®Á§∫‰æã
def demo_mlp_stock_prediction():
    """MLPËÇ°‰ª∑È¢ÑÊµãÊºîÁ§∫"""
    # ÁîüÊàêÊ®°ÊãüÊï∞ÊçÆ
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    # Ê®°ÊãüËÇ°‰ª∑Êï∞ÊçÆ
    price = 100
    prices = [price]
    volumes = []
    for i in range(999):
        # ÈöèÊú∫Ê∏∏Ëµ∞ + Ë∂ãÂäø
        change = np.random.normal(0, 0.02) + 0.0001 * np.sin(i * 0.01)
        price *= (1 + change)
        prices.append(price)
        volumes.append(np.random.randint(1000000, 5000000))
    data = pd.DataFrame({
        'date': dates,
        'close': prices,
        'volume': volumes + [volumes[-1]]
    })
    # ÂàõÂª∫ÂíåËÆ≠ÁªÉÊ®°Âûã
    mlp = StockPriceMLP(input_dim=200)  # ÂÅáËÆæ200‰∏™ÁâπÂæÅ
    # ÂáÜÂ§áÊï∞ÊçÆ
    X, y = mlp.prepare_data(data)
    # ÂàÜÂâ≤Êï∞ÊçÆ
    train_size = int(0.7 * len(X))
    val_size = int(0.15 * len(X))
    X_train, y_train = X[:train_size], y[:train_size]
    X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]
    X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]
    # ËÆ≠ÁªÉÊ®°Âûã
    print("ÂºÄÂßãËÆ≠ÁªÉMLPÊ®°Âûã...")
    history = mlp.train(X_train, y_train, X_val, y_val, epochs=50)
    # ËØÑ‰º∞Ê®°Âûã
    metrics = mlp.evaluate_model(X_test, y_test)
    print("\nMLPÊ®°ÂûãÊÄßËÉΩ:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.4f}")
    return mlp, history, metrics
# ËøêË°åÊºîÁ§∫
if __name__ == "__main__":
    mlp_model, training_history, performance_metrics = demo_mlp_stock_prediction()
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- LSTMÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµã -->
                    <section id="lstm-models" class="content-section mb-5">
                        <h2>üîÑ LSTMÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµã</h2>
                        <div class="model-card">
                            <h4>ÈïøÁü≠ÊúüËÆ∞ÂøÜÁΩëÁªú (LSTM) <span class="badge bg-success complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬∑h¬≤)</span></h4>
                            <div class="concept-explanation">
                                <h4>üí° ‰∏∫‰ªÄ‰πàLSTMËÉΩËß£ÂÜ≥ÈïøÊúü‰æùËµñÈóÆÈ¢òÔºü</h4>
                                <p>‰º†ÁªüRNNÂ≠òÂú®Ê¢ØÂ∫¶Ê∂àÂ§±ÈóÆÈ¢òÔºåÊó†Ê≥ïÂ≠¶‰π†ÈïøÊúü‰æùËµñÂÖ≥Á≥ª„ÄÇLSTMÈÄöËøáÂºïÂÖ•Èó®ÊéßÊú∫Âà∂ÂíåÁªÜËÉûÁä∂ÊÄÅÔºåËÉΩÂ§üÈÄâÊã©ÊÄßÂú∞ËÆ∞‰ΩèÂíåÈÅóÂøò‰ø°ÊÅØ„ÄÇ</p>
                                <p><strong>ÈáëËûçÂ∫îÁî®Âú∫ÊôØÔºö</strong>ËÇ°‰ª∑‰∏ç‰ªÖÂèóËøëÊúüÊ∂àÊÅØÂΩ±ÂìçÔºå‰πüÂèóÈïøÊúüË∂ãÂäø„ÄÅÂ≠£ËäÇÊÄßÂõ†Á¥†ÂΩ±Âìç„ÄÇLSTMËÉΩÂ§üÂêåÊó∂ÊçïÊçâÁü≠ÊúüÊ≥¢Âä®ÂíåÈïøÊúüË∂ãÂäø„ÄÇ</p>
                                <p><strong>Èó®ÊéßÊú∫Âà∂Á±ªÊØîÔºö</strong>Â∞±ÂÉèÊäïËµÑÂÜ≥Á≠ñ‰∏ÄÊ†∑ÔºåÊàë‰ª¨ÈúÄË¶ÅÂÜ≥ÂÆöÂì™‰∫õÂéÜÂè≤‰ø°ÊÅØË¶ÅËÆ∞‰ΩèÔºàËæìÂÖ•Èó®ÔºâÔºåÂì™‰∫õË¶ÅÂøòËÆ∞ÔºàÈÅóÂøòÈó®ÔºâÔºå‰ª•ÂèäÂ¶Ç‰ΩïËæìÂá∫ÂΩìÂâçÂà§Êñ≠ÔºàËæìÂá∫Èó®Ôºâ„ÄÇ</p>
                            </div>
                            
                            <div class="math-formula">
                                <h5>LSTMÊ†∏ÂøÉÂÖ¨ÂºèÊé®ÂØº</h5>
                                
                                <div class="concept-explanation">
                                    <h4>üîç ÈÅóÂøòÈó®Êé®ÂØº</h4>
                                    <p><strong>‰ΩúÁî®Ôºö</strong>ÂÜ≥ÂÆö‰ªéÁªÜËÉûÁä∂ÊÄÅ‰∏≠‰∏¢ÂºÉ‰ªÄ‰πà‰ø°ÊÅØ</p>
                                    <p><strong>ËæìÂÖ•Ôºö</strong>Ââç‰∏ÄÊó∂ÂàªÈöêËóèÁä∂ÊÄÅh_{t-1}ÂíåÂΩìÂâçËæìÂÖ•x_t</p>
                                    <p><strong>ËæìÂá∫Ôºö</strong>0Âà∞1‰πãÈó¥ÁöÑÊï∞ÂÄºÔºå0Ë°®Á§∫ÂÆåÂÖ®ÈÅóÂøòÔºå1Ë°®Á§∫ÂÆåÂÖ®‰øùÁïô</p>
                                </div>
                                \[ f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \]
                                <div class="formula-explanation">
                                    <p><strong>ËÆ°ÁÆóÁ§∫‰æãÔºö</strong>ÂÅáËÆæÈöêËóèÁä∂ÊÄÅÁª¥Â∫¶=2ÔºåËæìÂÖ•Áª¥Â∫¶=3</p>
                                    <pre>
h_{t-1} = [0.5, 0.3]    x_t = [100, 1000, 0.6]  (‰ª∑Ê†º„ÄÅÊàê‰∫§Èáè„ÄÅÊäÄÊúØÊåáÊ†á)
[h_{t-1}, x_t] = [0.5, 0.3, 100, 1000, 0.6]  # ÊãºÊé•

W_f = [[0.1, 0.2, 0.01, 0.001, 0.5],    b_f = [0.1,
       [0.3, 0.1, 0.02, 0.002, 0.3]]            0.2]

f_t = œÉ(W_f √ó [h_{t-1}, x_t] + b_f)
    = œÉ([[0.1√ó0.5 + 0.2√ó0.3 + 0.01√ó100 + 0.001√ó1000 + 0.5√ó0.6 + 0.1],
         [0.3√ó0.5 + 0.1√ó0.3 + 0.02√ó100 + 0.002√ó1000 + 0.3√ó0.6 + 0.2]])
    = œÉ([2.41, 4.58]) = [0.92, 0.99]  # Â§ßÈÉ®ÂàÜ‰ø°ÊÅØ‰øùÁïô
                                    </pre>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h4>üîç ËæìÂÖ•Èó®Êé®ÂØº</h4>
                                    <p><strong>‰ΩúÁî®Ôºö</strong>ÂÜ≥ÂÆöÂú®ÁªÜËÉûÁä∂ÊÄÅ‰∏≠Â≠òÂÇ®‰ªÄ‰πàÊñ∞‰ø°ÊÅØ</p>
                                    <p><strong>‰∏§Ê≠•ËøáÁ®ãÔºö</strong>1) ÂÜ≥ÂÆöÊõ¥Êñ∞Âì™‰∫õÂÄº 2) ÂàõÂª∫ÂÄôÈÄâÂÄº</p>
                                </div>
                                \[ i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \]
                                <div class="formula-explanation">
                                    <p><strong>ËæìÂÖ•Èó®ËÆ°ÁÆóÔºö</strong>ÂÜ≥ÂÆöÂì™‰∫õÊñ∞‰ø°ÊÅØÈúÄË¶ÅÂ≠òÂÇ®</p>
                                    <pre>
i_t = œÉ(W_i √ó [h_{t-1}, x_t] + b_i) = [0.7, 0.8]  # Â§ßÈÉ®ÂàÜÊñ∞‰ø°ÊÅØË¢´Êé•Âèó
                                    </pre>
                                </div>
                                
                                \[ \tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C) \]
                                <div class="formula-explanation">
                                    <p><strong>ÂÄôÈÄâÂÄºËÆ°ÁÆóÔºö</strong>ÂàõÂª∫ÂèØËÉΩÊ∑ªÂä†Âà∞ÁªÜËÉûÁä∂ÊÄÅÁöÑÊñ∞ÂÄôÈÄâÂÄº</p>
                                    <pre>
CÃÉ_t = tanh(W_C √ó [h_{t-1}, x_t] + b_C) = [0.6, -0.4]  # ÂÄôÈÄâÊõ¥Êñ∞ÂÄº
                                    </pre>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h4>üîç ÁªÜËÉûÁä∂ÊÄÅÊõ¥Êñ∞Êé®ÂØº</h4>
                                    <p><strong>Ê†∏ÂøÉÊÄùÊÉ≥Ôºö</strong>ÁªìÂêàÈÅóÂøòÈó®ÂíåËæìÂÖ•Èó®ÁöÑÁªìÊûúÊõ¥Êñ∞ÁªÜËÉûÁä∂ÊÄÅ</p>
                                    <p><strong>Êõ¥Êñ∞ËßÑÂàôÔºö</strong>Êóß‰ø°ÊÅØ √ó ÈÅóÂøòÈó® + Êñ∞‰ø°ÊÅØ √ó ËæìÂÖ•Èó®</p>
                                </div>
                                \[ C_t = f_t * C_{t-1} + i_t * \tilde{C}_t \]
                                <div class="formula-explanation">
                                    <p><strong>ËÆ°ÁÆóÁ§∫‰æãÔºö</strong></p>
                                    <pre>
C_{t-1} = [0.8, 0.5]  # Ââç‰∏ÄÊó∂ÂàªÁöÑÁªÜËÉûÁä∂ÊÄÅ

C_t = f_t ‚äô C_{t-1} + i_t ‚äô CÃÉ_t  # ‚äôË°®Á§∫ÈÄêÂÖÉÁ¥†‰πòÊ≥ï
    = [0.92, 0.99] ‚äô [0.8, 0.5] + [0.7, 0.8] ‚äô [0.6, -0.4]
    = [0.736, 0.495] + [0.42, -0.32]
    = [1.156, 0.175]

# Ëß£ÈáäÔºöÁ¨¨‰∏Ä‰∏™Áª¥Â∫¶‰ø°ÊÅØÂ¢ûÂº∫ÔºåÁ¨¨‰∫å‰∏™Áª¥Â∫¶‰ø°ÊÅØÂáèÂº±
                                    </pre>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h4>üîç ËæìÂá∫Èó®Êé®ÂØº</h4>
                                    <p><strong>‰ΩúÁî®Ôºö</strong>ÂÜ≥ÂÆöÁªÜËÉûÁä∂ÊÄÅÁöÑÂì™‰∫õÈÉ®ÂàÜÂ∞ÜËæìÂá∫</p>
                                    <p><strong>‰∏§Ê≠•ËøáÁ®ãÔºö</strong>1) ÂÜ≥ÂÆöËæìÂá∫Âì™‰∫õÈÉ®ÂàÜ 2) ÂØπÁªÜËÉûÁä∂ÊÄÅËøõË°åtanhÂ§ÑÁêÜ</p>
                                </div>
                                \[ o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \]
                                <div class="formula-explanation">
                                    <p><strong>ËæìÂá∫Èó®ËÆ°ÁÆóÔºö</strong></p>
                                    <pre>
o_t = œÉ(W_o √ó [h_{t-1}, x_t] + b_o) = [0.85, 0.75]  # ËæìÂá∫ÊéßÂà∂
                                    </pre>
                                </div>
                                
                                \[ h_t = o_t * \tanh(C_t) \]
                                <div class="formula-explanation">
                                    <p><strong>ÈöêËóèÁä∂ÊÄÅËÆ°ÁÆóÔºö</strong></p>
                                    <pre>
h_t = o_t ‚äô tanh(C_t)
    = [0.85, 0.75] ‚äô tanh([1.156, 0.175])
    = [0.85, 0.75] ‚äô [0.82, 0.17]
    = [0.697, 0.128]

# ÊúÄÁªàËæìÂá∫Ôºöh_tÂèØÁî®‰∫é‰∏ã‰∏ÄÊó∂ÂàªËÆ°ÁÆóÊàñ‰Ωú‰∏∫ÂΩìÂâçÊó∂ÂàªÁöÑÈ¢ÑÊµãÂü∫Á°Ä
                                    </pre>
                                </div>
                            </div>
                            
<div class="code-example">
                                <h6>Â§öÂèòÈáèÊó∂Èó¥Â∫èÂàóLSTMÈ¢ÑÊµã</h6>
                                <pre><code class="language-python">
class MultivariateLSTM:
    """
    Â§öÂèòÈáèÊó∂Èó¥Â∫èÂàóLSTMÈ¢ÑÊµãÊ®°Âûã
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬∑h¬≤¬∑L) - T:Â∫èÂàóÈïøÂ∫¶, h:ÈöêËóèÂçïÂÖÉÊï∞, L:Â±ÇÊï∞
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(h¬∑L + T¬∑h)
    """
    def __init__(self, n_features, sequence_length=60, lstm_units=[50, 50]):
        self.n_features = n_features
        self.sequence_length = sequence_length
        self.lstm_units = lstm_units
        self.model = None
        self.scalers = {}
    def build_model(self, dropout_rate=0.2):
        """ÊûÑÂª∫Â§öÂ±ÇLSTMÊ®°Âûã"""
        model = tf.keras.Sequential()
        # Á¨¨‰∏ÄÂ±ÇLSTM
        model.add(tf.keras.layers.LSTM(
            self.lstm_units[0],
            return_sequences=len(self.lstm_units) > 1,
            input_shape=(self.sequence_length, self.n_features),
            dropout=dropout_rate,
            recurrent_dropout=dropout_rate
        ))
        # È¢ùÂ§ñÁöÑLSTMÂ±Ç
        for i, units in enumerate(self.lstm_units[1:]):
            return_seq = i < len(self.lstm_units) - 2
            model.add(tf.keras.layers.LSTM(
                units,
                return_sequences=return_seq,
                dropout=dropout_rate,
                recurrent_dropout=dropout_rate
            ))
        # ÂÖ®ËøûÊé•Â±Ç
        model.add(tf.keras.layers.Dense(25, activation='relu'))
        model.add(tf.keras.layers.Dropout(dropout_rate))
        model.add(tf.keras.layers.Dense(1))
        # ÁºñËØëÊ®°Âûã
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
    def prepare_sequences(self, data, target_column):
        """ÂáÜÂ§áLSTMÂ∫èÂàóÊï∞ÊçÆ"""
        # Êï∞ÊçÆÊ†áÂáÜÂåñ
        scaled_data = {}
        for column in data.columns:
            scaler = MinMaxScaler()
            scaled_data[column] = scaler.fit_transform(
                data[column].values.reshape(-1, 1)
            ).flatten()
            self.scalers[column] = scaler
        scaled_df = pd.DataFrame(scaled_data)
        # ÂàõÂª∫Â∫èÂàó
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_df)):
            X.append(scaled_df.iloc[i-self.sequence_length:i].values)
            y.append(scaled_df[target_column].iloc[i])
        return np.array(X), np.array(y)
    def train_with_attention(self, X_train, y_train, X_val, y_val, epochs=100):
        """Â∏¶Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑËÆ≠ÁªÉ"""
        # ÊûÑÂª∫Â∏¶Ê≥®ÊÑèÂäõÁöÑÊ®°Âûã
        inputs = tf.keras.layers.Input(shape=(self.sequence_length, self.n_features))
        # LSTMÂ±Ç
        lstm_out = tf.keras.layers.LSTM(
            self.lstm_units[0],
            return_sequences=True,
            dropout=0.2
        )(inputs)
        # Ê≥®ÊÑèÂäõÊú∫Âà∂
        attention = tf.keras.layers.Dense(1, activation='tanh')(lstm_out)
        attention = tf.keras.layers.Flatten()(attention)
        attention = tf.keras.layers.Activation('softmax')(attention)
        attention = tf.keras.layers.RepeatVector(self.lstm_units[0])(attention)
        attention = tf.keras.layers.Permute([2, 1])(attention)
        # Â∫îÁî®Ê≥®ÊÑèÂäõÊùÉÈáç
        sent_representation = tf.keras.layers.Multiply()([lstm_out, attention])
        sent_representation = tf.keras.layers.Lambda(
            lambda xin: tf.keras.backend.sum(xin, axis=1)
        )(sent_representation)
        # ËæìÂá∫Â±Ç
        outputs = tf.keras.layers.Dense(1)(sent_representation)
        model = tf.keras.Model(inputs=inputs, outputs=outputs)
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        # ËÆ≠ÁªÉ
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=32,
            verbose=1
        )
        self.model = model
        return history
    def predict_future(self, last_sequence, n_steps=30):
        """È¢ÑÊµãÊú™Êù•Â§öÊ≠•"""
        predictions = []
        current_sequence = last_sequence.copy()
        for _ in range(n_steps):
            # È¢ÑÊµã‰∏ã‰∏ÄÊ≠•
            next_pred = self.model.predict(
                current_sequence.reshape(1, self.sequence_length, self.n_features)
            )[0, 0]
            predictions.append(next_pred)
            # Êõ¥Êñ∞Â∫èÂàóÔºàÁÆÄÂåñÁâàÊú¨ÔºåÂÆûÈôÖÂ∫îÁî®‰∏≠ÈúÄË¶ÅÊõ¥Â§çÊùÇÁöÑÁâπÂæÅÊõ¥Êñ∞Ôºâ
            new_row = current_sequence[-1].copy()
            new_row[0] = next_pred  # ÂÅáËÆæÁ¨¨‰∏Ä‰∏™ÁâπÂæÅÊòØÁõÆÊ†áÂèòÈáè
            current_sequence = np.vstack([current_sequence[1:], new_row])
        return np.array(predictions)
    def calculate_volatility_forecast(self, predictions):
        """ËÆ°ÁÆóÊ≥¢Âä®ÁéáÈ¢ÑÊµã"""
        returns = np.diff(predictions) / predictions[:-1]
        volatility = np.std(returns) * np.sqrt(252)  # Âπ¥ÂåñÊ≥¢Âä®Áéá
        return volatility
# LSTMÂèò‰ΩìÔºöGRUÊ®°Âûã
class GRUModel:
    """
    Èó®ÊéßÂæ™ÁéØÂçïÂÖÉ(GRU)Ê®°Âûã
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬∑h¬≤) - ÊØîLSTMÁ®çÂø´
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(h¬∑L)
    """
    def __init__(self, n_features, sequence_length=60):
        self.n_features = n_features
        self.sequence_length = sequence_length
        self.model = None
    def build_model(self, gru_units=50):
        """ÊûÑÂª∫GRUÊ®°Âûã"""
        model = tf.keras.Sequential([
            tf.keras.layers.GRU(
                gru_units,
                return_sequences=True,
                input_shape=(self.sequence_length, self.n_features)
            ),
            tf.keras.layers.GRU(gru_units//2),
            tf.keras.layers.Dense(25, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
# ÂèåÂêëLSTMÊ®°Âûã
class BidirectionalLSTM:
    """
    ÂèåÂêëLSTMÊ®°Âûã
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(2¬∑T¬∑h¬≤) - ÂèåÂÄç‰∫éÂçïÂêëLSTM
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(2¬∑h¬∑L)
    """
    def build_model(self, n_features, sequence_length, lstm_units=50):
        """ÊûÑÂª∫ÂèåÂêëLSTMÊ®°Âûã"""
        model = tf.keras.Sequential([
            tf.keras.layers.Bidirectional(
                tf.keras.layers.LSTM(
                    lstm_units,
                    return_sequences=True
                ),
                input_shape=(sequence_length, n_features)
            ),
            tf.keras.layers.Bidirectional(
                tf.keras.layers.LSTM(lstm_units//2)
            ),
            tf.keras.layers.Dense(25, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        return model
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- CNNÊ®°Âûã -->
                    <section id="cnn-models" class="content-section mb-5">
                        <h2>üñºÔ∏è CNNÂõæÂÉèËØÜÂà´Âú®ÈáëËûç‰∏≠ÁöÑÂ∫îÁî®</h2>
                        <div class="model-card">
                            <h4>Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) <span class="badge bg-warning complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(K¬≤¬∑C¬∑H¬∑W¬∑F)</span></h4>
                            <div class="math-formula">
                                <h5>CNNÊï∞Â≠¶ÂéüÁêÜ</h5>
                                <p><strong>Âç∑ÁßØÊìç‰ΩúÔºö</strong></p>
                                \[ (f * g)(t) = \sum_{m=-\infty}^{\infty} f(m) \cdot g(t-m) \]
                                <p><strong>ÁâπÂæÅÂõæËÆ°ÁÆóÔºö</strong></p>
                                \[ Y_{i,j} = \sum_{m=0}^{K-1} \sum_{n=0}^{K-1} X_{i+m,j+n} \cdot W_{m,n} + b \]
                                <p><strong>Ê±†ÂåñÊìç‰ΩúÔºö</strong></p>
                                \[ \text{MaxPool}(X) = \max_{i,j \in \text{window}} X_{i,j} \]
                                \[ \text{AvgPool}(X) = \frac{1}{|\text{window}|} \sum_{i,j \in \text{window}} X_{i,j} \]
                            
<div class="code-example">
                                <h6>ÈáëËûçÂõæË°®Ê®°ÂºèËØÜÂà´CNN</h6>
                                <pre><code class="language-python">
class FinancialChartCNN:
    """
    ÈáëËûçÂõæË°®Ê®°ÂºèËØÜÂà´CNNÊ®°Âûã
    Áî®‰∫éËØÜÂà´KÁ∫øÂõæ‰∏≠ÁöÑÊäÄÊúØÂàÜÊûêÊ®°Âºè
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(K¬≤¬∑C¬∑H¬∑W¬∑F) - K:Âç∑ÁßØÊ†∏Â§ßÂ∞è, C:ÈÄöÈÅìÊï∞, H,W:ÂõæÂÉèÂ∞∫ÂØ∏, F:Êª§Ê≥¢Âô®Êï∞
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(H¬∑W¬∑C + F¬∑K¬≤¬∑C)
    """
    def __init__(self, input_shape=(64, 64, 3), num_classes=10):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
    def build_model(self):
        """ÊûÑÂª∫CNNÊ®°ÂûãÁî®‰∫éÂõæË°®Ê®°ÂºèËØÜÂà´"""
        model = tf.keras.Sequential([
            # Á¨¨‰∏Ä‰∏™Âç∑ÁßØÂùó
            tf.keras.layers.Conv2D(
                32, (3, 3),
                activation='relu',
                input_shape=self.input_shape
            ),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            # Á¨¨‰∫å‰∏™Âç∑ÁßØÂùó
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            # Á¨¨‰∏â‰∏™Âç∑ÁßØÂùó
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            # ÂÖ®ËøûÊé•Â±Ç
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(self.num_classes, activation='softmax')
        ])
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        self.model = model
        return model
    def generate_candlestick_image(self, ohlc_data, width=64, height=64):
        """Â∞ÜOHLCÊï∞ÊçÆËΩ¨Êç¢‰∏∫KÁ∫øÂõæÂõæÂÉè"""
        import matplotlib.pyplot as plt
        import matplotlib.patches as patches
        from io import BytesIO
        import PIL.Image as Image
        fig, ax = plt.subplots(figsize=(width/10, height/10))
        ax.set_xlim(0, len(ohlc_data))
        ax.set_ylim(ohlc_data['low'].min() * 0.99, ohlc_data['high'].max() * 1.01)
        for i, (idx, row) in enumerate(ohlc_data.iterrows()):
            # ÁªòÂà∂KÁ∫ø
            color = 'red' if row['close'] > row['open'] else 'green'
            # ÂΩ±Á∫ø
            ax.plot([i, i], [row['low'], row['high']], color='black', linewidth=1)
            # ÂÆû‰Ωì
            body_height = abs(row['close'] - row['open'])
            body_bottom = min(row['open'], row['close'])
            rect = patches.Rectangle(
                (i-0.3, body_bottom), 0.6, body_height,
                linewidth=1, edgecolor='black', facecolor=color, alpha=0.8
            )
            ax.add_patch(rect)
        ax.axis('off')
        plt.tight_layout()
        # ËΩ¨Êç¢‰∏∫ÂõæÂÉèÊï∞ÁªÑ
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=10, bbox_inches='tight', pad_inches=0)
        buf.seek(0)
        img = Image.open(buf)
        img_array = np.array(img.resize((width, height)))
        plt.close()
        return img_array[:, :, :3]  # ÂéªÈô§alphaÈÄöÈÅì
    def create_pattern_dataset(self, price_data, window_size=20):
        """ÂàõÂª∫ÂõæË°®Ê®°ÂºèÊï∞ÊçÆÈõÜ"""
        patterns = {
            'head_and_shoulders': 0,
            'double_top': 1,
            'double_bottom': 2,
            'triangle': 3,
            'flag': 4,
            'wedge': 5,
            'channel': 6,
            'support_resistance': 7,
            'breakout': 8,
            'reversal': 9
        }
        X, y = [], []
        for i in range(window_size, len(price_data) - window_size):
            window_data = price_data.iloc[i-window_size:i+window_size]
            # ÁîüÊàêKÁ∫øÂõæÂõæÂÉè
            img = self.generate_candlestick_image(window_data)
            # ËØÜÂà´Ê®°ÂºèÔºàÁÆÄÂåñÁâàÊú¨Ôºâ
            pattern_label = self.identify_pattern(window_data)
            X.append(img)
            y.append(pattern_label)
        return np.array(X), tf.keras.utils.to_categorical(y, self.num_classes)
    def identify_pattern(self, data):
        """ÁÆÄÂåñÁöÑÊ®°ÂºèËØÜÂà´ÈÄªËæë"""
        # ËøôÈáåÊòØÁÆÄÂåñÁöÑÊ®°ÂºèËØÜÂà´ÔºåÂÆûÈôÖÂ∫îÁî®‰∏≠ÈúÄË¶ÅÊõ¥Â§çÊùÇÁöÑÁÆóÊ≥ï
        high_points = data['high'].rolling(5).max()
        low_points = data['low'].rolling(5).min()
        # ÁÆÄÂçïÁöÑÊ®°ÂºèËØÜÂà´ËßÑÂàô
        if len(data) > 10:
            recent_trend = data['close'].iloc[-5:].mean() - data['close'].iloc[:5].mean()
            volatility = data['close'].std()
            if recent_trend > volatility:
                return 8  # breakout
            elif recent_trend < -volatility:
                return 9  # reversal
            else:
                return np.random.randint(0, 8)  # ÂÖ∂‰ªñÊ®°Âºè
        return 0
    def train_with_augmentation(self, X_train, y_train, X_val, y_val, epochs=50):
        """‰ΩøÁî®Êï∞ÊçÆÂ¢ûÂº∫ËÆ≠ÁªÉÊ®°Âûã"""
        # Êï∞ÊçÆÂ¢ûÂº∫
        datagen = tf.keras.preprocessing.image.ImageDataGenerator(
            rotation_range=10,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True,
            zoom_range=0.1,
            fill_mode='nearest'
        )
        # ËÆ≠ÁªÉ
        history = self.model.fit(
            datagen.flow(X_train, y_train, batch_size=32),
            validation_data=(X_val, y_val),
            epochs=epochs,
            steps_per_epoch=len(X_train) // 32,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_accuracy', patience=10, restore_best_weights=True
                ),
                tf.keras.callbacks.ReduceLROnPlateau(
                    monitor='val_loss', factor=0.5, patience=5
                )
            ]
        )
        return history
    def predict_pattern(self, ohlc_data):
        """È¢ÑÊµãÂõæË°®Ê®°Âºè"""
        img = self.generate_candlestick_image(ohlc_data)
        img_normalized = img.astype('float32') / 255.0
        prediction = self.model.predict(np.expand_dims(img_normalized, axis=0))
        pattern_names = [
            'Head and Shoulders', 'Double Top', 'Double Bottom', 'Triangle',
            'Flag', 'Wedge', 'Channel', 'Support/Resistance', 'Breakout', 'Reversal'
        ]
        predicted_class = np.argmax(prediction[0])
        confidence = prediction[0][predicted_class]
        return pattern_names[predicted_class], confidence
# 1D CNNÁî®‰∫éÊó∂Èó¥Â∫èÂàó
class TimeSeries1DCNN:
    """
    ‰∏ÄÁª¥CNNÁî®‰∫éÊó∂Èó¥Â∫èÂàóÂàÜÊûê
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬∑K¬∑F) - T:Â∫èÂàóÈïøÂ∫¶, K:Âç∑ÁßØÊ†∏Â§ßÂ∞è, F:Êª§Ê≥¢Âô®Êï∞
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(T¬∑F)
    """
    def __init__(self, sequence_length, n_features):
        self.sequence_length = sequence_length
        self.n_features = n_features
        self.model = None
    def build_model(self):
        """ÊûÑÂª∫1D CNNÊ®°Âûã"""
        model = tf.keras.Sequential([
            tf.keras.layers.Conv1D(
                filters=64, kernel_size=3, activation='relu',
                input_shape=(self.sequence_length, self.n_features)
            ),
            tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
            tf.keras.layers.MaxPooling1D(pool_size=2),
            tf.keras.layers.Dropout(0.25),
            tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),
            tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),
            tf.keras.layers.GlobalMaxPooling1D(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(50, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- TransformerÊ®°Âûã -->
                    <section id="transformer-models" class="content-section mb-5">
                        <h2>üîÑ TransformerÊ≥®ÊÑèÂäõÊú∫Âà∂</h2>
                        <div class="model-card">
                            <h4>TransformerÊ®°Âûã <span class="badge bg-primary complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬≤¬∑d)</span></h4>
                            <div class="math-formula">
                                <h5>Ê≥®ÊÑèÂäõÊú∫Âà∂Êï∞Â≠¶ÂéüÁêÜ</h5>
                                <p><strong>Ëá™Ê≥®ÊÑèÂäõËÆ°ÁÆóÔºö</strong></p>
                                \[ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \]
                                <p><strong>Â§öÂ§¥Ê≥®ÊÑèÂäõÔºö</strong></p>
                                \[ \text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O \]
                                \[ \text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \]
                                <p><strong>‰ΩçÁΩÆÁºñÁ†ÅÔºö</strong></p>
                                \[ PE_{(pos,2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right) \]
                                \[ PE_{(pos,2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right) \]
                            
<div class="code-example">
                                <h6>ÈáëËûçÊó∂Èó¥Â∫èÂàóTransformer</h6>
                                <pre><code class="language-python">
class FinancialTransformer:
    """
    ÈáëËûçÊó∂Èó¥Â∫èÂàóTransformerÊ®°Âûã
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬≤¬∑d + T¬∑d¬≤) - T:Â∫èÂàóÈïøÂ∫¶, d:Ê®°ÂûãÁª¥Â∫¶
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(T¬≤¬∑h + T¬∑d) - h:Ê≥®ÊÑèÂäõÂ§¥Êï∞
    """
    def __init__(self, seq_length, d_model=128, num_heads=8, num_layers=6):
        self.seq_length = seq_length
        self.d_model = d_model
        self.num_heads = num_heads
        self.num_layers = num_layers
        self.model = None
    def build_model(self, input_dim):
        """ÊûÑÂª∫TransformerÊ®°Âûã"""
        inputs = tf.keras.layers.Input(shape=(self.seq_length, input_dim))
        # ËæìÂÖ•ÂµåÂÖ•Âíå‰ΩçÁΩÆÁºñÁ†Å
        x = tf.keras.layers.Dense(self.d_model)(inputs)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        
        # Ê∑ªÂä†‰ΩçÁΩÆÁºñÁ†Å
        positions = tf.range(start=0, limit=self.seq_length, delta=1)
        positions = tf.expand_dims(positions, 0)
        position_encoding = self.positional_encoding(positions, self.d_model)
        x += position_encoding
        
        # TransformerÂ±Ç
        for _ in range(self.num_layers):
            # Â§öÂ§¥Ëá™Ê≥®ÊÑèÂäõ
            attention_output = tf.keras.layers.MultiHeadAttention(
                num_heads=self.num_heads,
                key_dim=self.d_model // self.num_heads
            )(x, x)
            # ÊÆãÂ∑ÆËøûÊé•ÂíåÂ±ÇÂΩí‰∏ÄÂåñ
            x = tf.keras.layers.LayerNormalization()(x + attention_output)
            # ÂâçÈ¶àÁΩëÁªú
            ffn_output = tf.keras.layers.Dense(
                self.d_model * 4, activation='relu'
            )(x)
            ffn_output = tf.keras.layers.Dense(self.d_model)(ffn_output)
            # ÊÆãÂ∑ÆËøûÊé•ÂíåÂ±ÇÂΩí‰∏ÄÂåñ
            x = tf.keras.layers.LayerNormalization()(x + ffn_output)
        # ÂÖ®Â±ÄÂπ≥ÂùáÊ±†Âåñ
        x = tf.keras.layers.GlobalAveragePooling1D()(x)
        # ËæìÂá∫Â±Ç
        outputs = tf.keras.layers.Dense(1)(x)
        model = tf.keras.Model(inputs=inputs, outputs=outputs)
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
    
    def positional_encoding(self, position, d_model):
        """‰ΩçÁΩÆÁºñÁ†Å"""
        angle_rads = self.get_angles(tf.range(position, dtype=tf.float32)[:, tf.newaxis],
                                   tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],
                                   d_model)
        # ÂØπÂÅ∂Êï∞Á¥¢ÂºïÂ∫îÁî®sin
        angle_rads = tf.cast(angle_rads, tf.float32)
        sines = tf.math.sin(angle_rads[:, :, 0::2])
        cosines = tf.math.cos(angle_rads[:, :, 1::2])
        pos_encoding = tf.concat([sines, cosines], axis=-1)
        pos_encoding = pos_encoding[tf.newaxis, ...]
        return tf.cast(pos_encoding, tf.float32)
    
    def get_angles(self, pos, i, d_model):
        """ËÆ°ÁÆóËßíÂ∫¶"""
        angle_rates = 1 / tf.pow(10000, (2 * (i//2)) / tf.cast(d_model, tf.float32))
        return pos * angle_rates
    
    def train_model(self, X_train, y_train, X_val, y_val, epochs=100):
        """ËÆ≠ÁªÉÊ®°Âûã"""
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_loss', patience=10, restore_best_weights=True
        )
        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7
        )
        
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )
        return history
    
    def predict(self, X):
        """È¢ÑÊµã"""
        return self.model.predict(X)

# ËôöÊãüÊï∞ÊçÆÁîüÊàêÂáΩÊï∞
def generate_financial_data(n_samples=10000, seq_length=60, n_features=5):
    """ÁîüÊàêËôöÊãüÈáëËûçÊó∂Èó¥Â∫èÂàóÊï∞ÊçÆ"""
    import numpy as np
    
    # ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê
    np.random.seed(42)
    
    # ÁîüÊàêÂü∫Á°Ä‰ª∑Ê†ºÂ∫èÂàó
    base_price = 100
    prices = [base_price]
    
    for i in range(n_samples + seq_length):
        # Ê∑ªÂä†Ë∂ãÂäø„ÄÅÂ≠£ËäÇÊÄßÂíåÈöèÊú∫Ê≥¢Âä®
        trend = 0.0001 * i
        seasonal = 0.02 * np.sin(2 * np.pi * i / 252)  # Âπ¥Â∫¶Â≠£ËäÇÊÄß
        noise = np.random.normal(0, 0.02)
        
        # ‰ª∑Ê†ºÂèòÂåñ
        price_change = trend + seasonal + noise
        new_price = prices[-1] * (1 + price_change)
        prices.append(new_price)
    
    prices = np.array(prices)
    
    # ËÆ°ÁÆóÊäÄÊúØÊåáÊ†á
    def calculate_rsi(prices, window=14):
        """ËÆ°ÁÆóRSIÊåáÊ†á"""
        deltas = np.diff(prices)
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)
        
        avg_gains = np.convolve(gains, np.ones(window)/window, mode='valid')
        avg_losses = np.convolve(losses, np.ones(window)/window, mode='valid')
        
        rs = avg_gains / (avg_losses + 1e-8)
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def calculate_macd(prices, fast=12, slow=26, signal=9):
        """ËÆ°ÁÆóMACDÊåáÊ†á"""
        ema_fast = pd.Series(prices).ewm(span=fast).mean()
        ema_slow = pd.Series(prices).ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        signal_line = macd.ewm(span=signal).mean()
        return macd.values, signal_line.values
    
    # ÂàõÂª∫ÁâπÂæÅÁü©Èòµ
    features = []
    targets = []
    
    for i in range(seq_length, len(prices) - 1):
        # ‰ª∑Ê†ºÂ∫èÂàó
        price_seq = prices[i-seq_length:i]
        
        # ËÆ°ÁÆóÊî∂ÁõäÁéá
        returns = np.diff(price_seq) / price_seq[:-1]
        returns = np.append(returns, 0)  # Ë°•ÈΩêÈïøÂ∫¶
        
        # ËÆ°ÁÆóÁßªÂä®Âπ≥Âùá
        ma_5 = np.mean(price_seq[-5:])
        ma_20 = np.mean(price_seq[-20:]) if len(price_seq) >= 20 else np.mean(price_seq)
        
        # ËÆ°ÁÆóÊ≥¢Âä®Áéá
        volatility = np.std(returns[-20:]) if len(returns) >= 20 else np.std(returns)
        
        # RSI
        if i >= seq_length + 14:
            rsi = calculate_rsi(prices[i-seq_length-14:i])[-1]
        else:
            rsi = 50  # ÈªòËÆ§ÂÄº
        
        # ÁªÑÂêàÁâπÂæÅ
        feature_vector = np.array([
            price_seq[-1],  # ÂΩìÂâç‰ª∑Ê†º
            returns[-1],    # ÂΩìÂâçÊî∂ÁõäÁéá
            ma_5 / price_seq[-1],  # MA5ÊØîÁéá
            ma_20 / price_seq[-1], # MA20ÊØîÁéá
            volatility,     # Ê≥¢Âä®Áéá
            rsi / 100       # Ê†áÂáÜÂåñRSI
        ])
        
        # ÂàõÂª∫Â∫èÂàóÁâπÂæÅ
        seq_features = np.column_stack([
            price_seq,
            np.append(np.diff(price_seq) / price_seq[:-1], 0),
            np.full(seq_length, ma_5 / price_seq[-1]),
            np.full(seq_length, ma_20 / price_seq[-1]),
            np.full(seq_length, volatility)
        ])
        
        features.append(seq_features)
        
        # ÁõÆÊ†áÔºö‰∏ã‰∏ÄÊúüÊî∂ÁõäÁéá
        next_return = (prices[i+1] - prices[i]) / prices[i]
        targets.append(next_return)
        
        if len(features) >= n_samples:
            break
    
    return np.array(features), np.array(targets)

# ‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    # ÁîüÊàêËôöÊãüÊï∞ÊçÆ
    X, y = generate_financial_data(n_samples=5000, seq_length=60, n_features=5)
    
    # Êï∞ÊçÆÂàÜÂâ≤
    train_size = int(0.8 * len(X))
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    # ÂàõÂª∫ÂíåËÆ≠ÁªÉTransformerÊ®°Âûã
    transformer = FinancialTransformer(seq_length=60, d_model=128, num_heads=8, num_layers=4)
    model = transformer.build_model(input_dim=5)
    
    # ËÆ≠ÁªÉÊ®°Âûã
    history = transformer.train_model(X_train, y_train, X_test, y_test, epochs=50)
    
    # È¢ÑÊµã
    predictions = transformer.predict(X_test)
    
    # ËØÑ‰º∞
    mse = np.mean((predictions.flatten() - y_test) ** 2)
    mae = np.mean(np.abs(predictions.flatten() - y_test))
    
    print(f"ÊµãËØïÈõÜMSE: {mse:.6f}")
    print(f"ÊµãËØïÈõÜMAE: {mae:.6f}")
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- GANÊ®°Âûã -->
                    <section id="gan-models" class="content-section mb-5">
                        <h2>üé≠ ÁîüÊàêÂØπÊäóÁΩëÁªú(GAN)</h2>
                        <div class="model-card">
                            <h4>ÈáëËûçÊï∞ÊçÆÁîüÊàêGAN <span class="badge bg-danger complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(G + D)</span></h4>
                            <div class="math-formula">
                                <h5>GANÊï∞Â≠¶ÂéüÁêÜ</h5>
                                <p><strong>ÁõÆÊ†áÂáΩÊï∞Ôºö</strong></p>
                                \[ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] \]
                                <p><strong>ÁîüÊàêÂô®ÊçüÂ§±Ôºö</strong></p>
                                \[ L_G = -\mathbb{E}_{z \sim p_z(z)}[\log D(G(z))] \]
                                <p><strong>Âà§Âà´Âô®ÊçüÂ§±Ôºö</strong></p>
                                \[ L_D = -\mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] - \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] \]
                            
<div class="code-example">
                                <h6>ËÇ°‰ª∑Êï∞ÊçÆÁîüÊàêGAN</h6>
                                <pre><code class="language-python">
class FinancialGAN:
    """
    ÈáëËûçÊó∂Èó¥Â∫èÂàóÁîüÊàêÂØπÊäóÁΩëÁªú
    Áî®‰∫éÁîüÊàêÂêàÊàêÁöÑËÇ°‰ª∑Êï∞ÊçÆ
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(G + D) - G:ÁîüÊàêÂô®Â§çÊùÇÂ∫¶, D:Âà§Âà´Âô®Â§çÊùÇÂ∫¶
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(|Œ∏_G| + |Œ∏_D|) - Ê®°ÂûãÂèÇÊï∞Êï∞Èáè
    """
    def __init__(self, seq_length=100, latent_dim=100):
        self.seq_length = seq_length
        self.latent_dim = latent_dim
        self.generator = None
        self.discriminator = None
        self.gan = None
    def build_generator(self):
        """ÊûÑÂª∫ÁîüÊàêÂô®"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(256, input_dim=self.latent_dim),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(512),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(1024),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(self.seq_length, activation='tanh'),
            tf.keras.layers.Reshape((self.seq_length, 1))
        ])
        self.generator = model
        return model
    
    def build_discriminator(self):
        """ÊûÑÂª∫Âà§Âà´Âô®"""
        model = tf.keras.Sequential([
            tf.keras.layers.Flatten(input_shape=(self.seq_length, 1)),
            tf.keras.layers.Dense(1024),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(512),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(256),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        self.discriminator = model
        return model
    
    def build_gan(self):
        """ÊûÑÂª∫ÂÆåÊï¥ÁöÑGANÊ®°Âûã"""
        # ÊûÑÂª∫ÁîüÊàêÂô®ÂíåÂà§Âà´Âô®
        self.generator = self.build_generator()
        self.discriminator = self.build_discriminator()
        
        # ÁºñËØëÂà§Âà´Âô®
        self.discriminator.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        # ÊûÑÂª∫GANÊ®°Âûã
        self.discriminator.trainable = False
        gan_input = tf.keras.layers.Input(shape=(self.latent_dim,))
        generated_data = self.generator(gan_input)
        gan_output = self.discriminator(generated_data)
        
        self.gan = tf.keras.Model(gan_input, gan_output)
        self.gan.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
            loss='binary_crossentropy'
        )
        
        return self.gan
    
    def train_gan(self, real_data, epochs=10000, batch_size=32, save_interval=1000):
        """ËÆ≠ÁªÉGANÊ®°Âûã"""
        # Ê†áÁ≠æ
        real_labels = np.ones((batch_size, 1))
        fake_labels = np.zeros((batch_size, 1))
        
        d_losses = []
        g_losses = []
        
        for epoch in range(epochs):
            # ËÆ≠ÁªÉÂà§Âà´Âô®
            # ÁúüÂÆûÊï∞ÊçÆ
            idx = np.random.randint(0, real_data.shape[0], batch_size)
            real_batch = real_data[idx]
            
            # ÁîüÊàêÂÅáÊï∞ÊçÆ
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
            fake_batch = self.generator.predict(noise, verbose=0)
            
            # ËÆ≠ÁªÉÂà§Âà´Âô®
            d_loss_real = self.discriminator.train_on_batch(real_batch, real_labels)
            d_loss_fake = self.discriminator.train_on_batch(fake_batch, fake_labels)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
            
            # ËÆ≠ÁªÉÁîüÊàêÂô®
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
            g_loss = self.gan.train_on_batch(noise, real_labels)
            
            d_losses.append(d_loss[0])
            g_losses.append(g_loss)
            
            # ÊâìÂç∞ËøõÂ∫¶
            if epoch % save_interval == 0:
                print(f"Epoch {epoch}, D Loss: {d_loss[0]:.4f}, G Loss: {g_loss:.4f}")
        
        return d_losses, g_losses
    
    def generate_samples(self, n_samples):
        """ÁîüÊàêÊ†∑Êú¨"""
        noise = np.random.normal(0, 1, (n_samples, self.latent_dim))
        generated_data = self.generator.predict(noise, verbose=0)
        return generated_data

# GANËôöÊãüÊï∞ÊçÆÁîüÊàêÁ§∫‰æã
def generate_gan_training_data(n_samples=5000, seq_length=100):
    """‰∏∫GANËÆ≠ÁªÉÁîüÊàêÁúüÂÆûËÇ°‰ª∑Êï∞ÊçÆ"""
    import numpy as np
    
    np.random.seed(42)
    
    # ÁîüÊàêÂ§ö‰∏™ËÇ°Á•®ÁöÑ‰ª∑Ê†ºÂ∫èÂàó
    all_sequences = []
    
    for stock in range(10):  # ÁîüÊàê10Âè™ËÇ°Á•®ÁöÑÊï∞ÊçÆ
        base_price = np.random.uniform(50, 200)
        prices = [base_price]
        
        # ËÇ°Á•®ÁâπÂÆöÂèÇÊï∞
        volatility = np.random.uniform(0.01, 0.05)
        drift = np.random.uniform(-0.001, 0.001)
        
        for i in range(n_samples):
            # Âá†‰ΩïÂ∏ÉÊúóËøêÂä®
            dt = 1/252  # Êó•È¢ëÊï∞ÊçÆ
            dW = np.random.normal(0, np.sqrt(dt))
            
            # ‰ª∑Ê†ºÂèòÂåñ
            price_change = drift * dt + volatility * dW
            new_price = prices[-1] * np.exp(price_change)
            prices.append(new_price)
        
        # Ê†áÂáÜÂåñ‰ª∑Ê†ºÂ∫èÂàó
        prices = np.array(prices)
        normalized_prices = (prices - np.mean(prices)) / np.std(prices)
        
        # ÂàõÂª∫Â∫èÂàó
        for i in range(len(normalized_prices) - seq_length):
            sequence = normalized_prices[i:i+seq_length]
            all_sequences.append(sequence.reshape(-1, 1))
    
    return np.array(all_sequences)

# GAN‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    # ÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆ
    real_data = generate_gan_training_data(n_samples=1000, seq_length=100)
    
    # ÂàõÂª∫GANÊ®°Âûã
    gan = FinancialGAN(seq_length=100, latent_dim=100)
    gan.build_gan()
    
    # ËÆ≠ÁªÉGAN
    d_losses, g_losses = gan.train_gan(real_data, epochs=5000, batch_size=32)
    
    # ÁîüÊàêÊñ∞ÁöÑËÇ°‰ª∑Â∫èÂàó
    generated_data = gan.generate_samples(100)
    
    print(f"ÁîüÊàê‰∫Ü {generated_data.shape[0]} ‰∏™ÈïøÂ∫¶‰∏∫ {generated_data.shape[1]} ÁöÑËÇ°‰ª∑Â∫èÂàó")
    print(f"Âà§Âà´Âô®ÊúÄÁªàÊçüÂ§±: {d_losses[-1]:.4f}")
    print(f"ÁîüÊàêÂô®ÊúÄÁªàÊçüÂ§±: {g_losses[-1]:.4f}")
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- Âº∫ÂåñÂ≠¶‰π† -->
                    <section id="reinforcement-learning" class="content-section mb-5">
                        <h2>üéØ Âº∫ÂåñÂ≠¶‰π†‰∫§ÊòìÁ≠ñÁï•</h2>
                        <div class="model-card">
                            <h4>Ê∑±Â∫¶QÁΩëÁªú(DQN)‰∫§Êòì <span class="badge bg-success complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬∑A)</span></h4>
                            <div class="math-formula">
                                <h5>Âº∫ÂåñÂ≠¶‰π†Êï∞Â≠¶ÂéüÁêÜ</h5>
                                <p><strong>QÂáΩÊï∞Êõ¥Êñ∞Ôºö</strong></p>
                                \[ Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha[r_{t+1} + \gamma \max_a Q(s_{t+1}, a) - Q(s_t, a_t)] \]
                                <p><strong>Á≠ñÁï•Ê¢ØÂ∫¶Ôºö</strong></p>
                                \[ \nabla_\theta J(\theta) = \mathbb{E}[\nabla_\theta \log \pi_\theta(a|s) \cdot A(s,a)] \]
                                <p><strong>‰ºòÂäøÂáΩÊï∞Ôºö</strong></p>
                                \[ A(s,a) = Q(s,a) - V(s) \]
                            
<div class="code-example">
                                <h6>DQN‰∫§ÊòìÊô∫ËÉΩ‰Ωì</h6>
                                <pre><code class="language-python">
class TradingDQN:
    """
    Ê∑±Â∫¶QÁΩëÁªú‰∫§ÊòìÊô∫ËÉΩ‰Ωì
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(T¬∑A¬∑|Œ∏|) - T:Êó∂Èó¥Ê≠•, A:Âä®‰ΩúÊï∞, |Œ∏|:ÁΩëÁªúÂèÇÊï∞
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(|Œ∏| + |M|) - M:ÁªèÈ™åÂõûÊîæÁºìÂÜ≤Âå∫Â§ßÂ∞è
    """
    def __init__(self, state_size, action_size, learning_rate=0.001):
        self.state_size = state_size
        self.action_size = action_size  # 0: hold, 1: buy, 2: sell
        self.memory = []
        self.memory_size = 10000
        self.epsilon = 1.0  # Êé¢Á¥¢Áéá
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = learning_rate
        self.gamma = 0.95  # ÊäòÊâ£Âõ†Â≠ê
        self.q_network = self.build_model()
        self.target_network = self.build_model()
        self.update_target_network()
        
    def build_model(self):
        """ÊûÑÂª∫DQNÁΩëÁªú"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, input_dim=self.state_size, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(self.action_size, activation='linear')
        ])
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),
            loss='mse'
        )
        return model
    
    def update_target_network(self):
        """Êõ¥Êñ∞ÁõÆÊ†áÁΩëÁªú"""
        self.target_network.set_weights(self.q_network.get_weights())
    
    def remember(self, state, action, reward, next_state, done):
        """Â≠òÂÇ®ÁªèÈ™å"""
        self.memory.append((state, action, reward, next_state, done))
        if len(self.memory) > self.memory_size:
            self.memory.pop(0)
    
    def act(self, state):
        """ÈÄâÊã©Âä®‰Ωú"""
        if np.random.random() <= self.epsilon:
            return np.random.choice(self.action_size)
        
        q_values = self.q_network.predict(state.reshape(1, -1), verbose=0)
        return np.argmax(q_values[0])
    
    def replay(self, batch_size=32):
        """ÁªèÈ™åÂõûÊîæËÆ≠ÁªÉ"""
        if len(self.memory) < batch_size:
            return
        
        batch = random.sample(self.memory, batch_size)
        states = np.array([e[0] for e in batch])
        actions = np.array([e[1] for e in batch])
        rewards = np.array([e[2] for e in batch])
        next_states = np.array([e[3] for e in batch])
        dones = np.array([e[4] for e in batch])
        
        # ËÆ°ÁÆóÁõÆÊ†áQÂÄº
        target_q_values = self.target_network.predict(next_states, verbose=0)
        max_target_q_values = np.max(target_q_values, axis=1)
        
        targets = rewards + (self.gamma * max_target_q_values * (1 - dones))
        
        # ÂΩìÂâçQÂÄº
        current_q_values = self.q_network.predict(states, verbose=0)
        
        # Êõ¥Êñ∞ÁõÆÊ†á
        for i in range(batch_size):
            current_q_values[i][actions[i]] = targets[i]
        
        # ËÆ≠ÁªÉÁΩëÁªú
        self.q_network.fit(states, current_q_values, epochs=1, verbose=0)
        
        # Ë°∞ÂáèÊé¢Á¥¢Áéá
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# ‰∫§ÊòìÁéØÂ¢ÉÁ±ª
class TradingEnvironment:
    """ËÇ°Á•®‰∫§ÊòìÁéØÂ¢É"""
    def __init__(self, data, initial_balance=10000, transaction_cost=0.001):
        self.data = data
        self.initial_balance = initial_balance
        self.transaction_cost = transaction_cost
        self.reset()
    
    def reset(self):
        """ÈáçÁΩÆÁéØÂ¢É"""
        self.current_step = 0
        self.balance = self.initial_balance
        self.shares_held = 0
        self.net_worth = self.initial_balance
        self.max_net_worth = self.initial_balance
        return self._get_state()
    
    def _get_state(self):
        """Ëé∑ÂèñÂΩìÂâçÁä∂ÊÄÅ"""
        if self.current_step >= len(self.data) - 1:
            return np.zeros(10)  # ËøîÂõûÈõ∂Áä∂ÊÄÅ
        
        # ÊäÄÊúØÊåáÊ†áÁä∂ÊÄÅ
        current_price = self.data.iloc[self.current_step]['close']
        
        # ÁÆÄÂåñÁöÑÁä∂ÊÄÅÁâπÂæÅ
        state = np.array([
            current_price / 100,  # Ê†áÂáÜÂåñ‰ª∑Ê†º
            self.balance / self.initial_balance,  # ‰ΩôÈ¢ùÊØî‰æã
            self.shares_held / 100,  # ÊåÅËÇ°Êï∞Èáè
            self.net_worth / self.initial_balance,  # ÂáÄÂÄºÊØî‰æã
            # Ê∑ªÂä†Êõ¥Â§öÊäÄÊúØÊåáÊ†á...
            0, 0, 0, 0, 0, 0  # Âç†‰ΩçÁ¨¶
        ])
        return state
    
    def step(self, action):
        """ÊâßË°åÂä®‰Ωú"""
        if self.current_step >= len(self.data) - 1:
            return self._get_state(), 0, True, {}
        
        current_price = self.data.iloc[self.current_step]['close']
        
        # ÊâßË°åÂä®‰Ωú
        if action == 1:  # ‰π∞ÂÖ•
            shares_to_buy = self.balance // (current_price * (1 + self.transaction_cost))
            if shares_to_buy > 0:
                cost = shares_to_buy * current_price * (1 + self.transaction_cost)
                self.balance -= cost
                self.shares_held += shares_to_buy
        
        elif action == 2:  # ÂçñÂá∫
            if self.shares_held > 0:
                revenue = self.shares_held * current_price * (1 - self.transaction_cost)
                self.balance += revenue
                self.shares_held = 0
        
        # Êõ¥Êñ∞ÂáÄÂÄº
        self.net_worth = self.balance + self.shares_held * current_price
        
        # ËÆ°ÁÆóÂ•ñÂä±
        reward = (self.net_worth - self.initial_balance) / self.initial_balance
        
        # Êõ¥Êñ∞ÊúÄÂ§ßÂáÄÂÄº
        if self.net_worth > self.max_net_worth:
            self.max_net_worth = self.net_worth
        
        self.current_step += 1
        done = self.current_step >= len(self.data) - 1
        
        return self._get_state(), reward, done, {'net_worth': self.net_worth}

# DQN‰∫§ÊòìÁ§∫‰æã
def demo_dqn_trading():
    """DQN‰∫§ÊòìÊºîÁ§∫"""
    # ÁîüÊàêËôöÊãüËÇ°‰ª∑Êï∞ÊçÆ
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    
    price = 100
    prices = []
    for i in range(1000):
        # ÈöèÊú∫Ê∏∏Ëµ∞ + Ë∂ãÂäø
        change = np.random.normal(0, 0.02) + 0.0001 * np.sin(i * 0.01)
        price *= (1 + change)
        prices.append(price)
    
    data = pd.DataFrame({
        'date': dates,
        'close': prices
    })
    
    # ÂàõÂª∫ÁéØÂ¢ÉÂíåÊô∫ËÉΩ‰Ωì
    env = TradingEnvironment(data)
    agent = TradingDQN(state_size=10, action_size=3)
    
    # ËÆ≠ÁªÉ
    episodes = 100
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        
        while True:
            action = agent.act(state)
            next_state, reward, done, info = env.step(action)
            agent.remember(state, action, reward, next_state, done)
            
            state = next_state
            total_reward += reward
            
            if done:
                break
        
        # ÁªèÈ™åÂõûÊîæ
        if len(agent.memory) > 32:
            agent.replay()
        
        # Êõ¥Êñ∞ÁõÆÊ†áÁΩëÁªú
        if episode % 10 == 0:
            agent.update_target_network()
        
        if episode % 20 == 0:
            print(f"Episode {episode}, Total Reward: {total_reward:.4f}, Net Worth: {info.get('net_worth', 0):.2f}")
    
    return agent, env

# ËøêË°åDQN‰∫§ÊòìÊºîÁ§∫
if __name__ == "__main__":
    import random
    dqn_agent, trading_env = demo_dqn_trading()
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- Ëá™ÁºñÁ†ÅÂô® -->
                    <section id="autoencoder" class="content-section mb-5">
                        <h2>üîÑ Ëá™ÁºñÁ†ÅÂô®ÂºÇÂ∏∏Ê£ÄÊµã</h2>
                        <div class="model-card">
                            <h4>ÂèòÂàÜËá™ÁºñÁ†ÅÂô®(VAE) <span class="badge bg-info complexity-badge">Êó∂Èó¥Â§çÊùÇÂ∫¶: O(E + D)</span></h4>
                            <div class="math-formula">
                                <h5>VAEÊï∞Â≠¶ÂéüÁêÜ</h5>
                                <p><strong>ELBOÊçüÂ§±Ôºö</strong></p>
                                \[ \mathcal{L} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z|x) || p(z)) \]
                                <p><strong>ÈáçÂèÇÊï∞ÂåñÊäÄÂ∑ßÔºö</strong></p>
                                \[ z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I) \]
                                <p><strong>KLÊï£Â∫¶Ôºö</strong></p>
                                \[ D_{KL} = \frac{1}{2} \sum_{i=1}^{d} (1 + \log(\sigma_i^2) - \mu_i^2 - \sigma_i^2) \]
                            
<div class="code-example">
                                <h6>ÈáëËûçÂºÇÂ∏∏Ê£ÄÊµãVAE</h6>
                                <pre><code class="language-python">
class FinancialVAE:
    """
    ÈáëËûçÊï∞ÊçÆÂèòÂàÜËá™ÁºñÁ†ÅÂô®
    Áî®‰∫éÂºÇÂ∏∏‰∫§ÊòìÊ£ÄÊµãÂíåÊï∞ÊçÆÈôçÁª¥
    Êó∂Èó¥Â§çÊùÇÂ∫¶: O(E + D) - E:ÁºñÁ†ÅÂô®, D:Ëß£Á†ÅÂô®
    Á©∫Èó¥Â§çÊùÇÂ∫¶: O(|Œ∏_E| + |Œ∏_D| + d) - d:ÊΩúÂú®Á©∫Èó¥Áª¥Â∫¶
    """
    def __init__(self, input_dim, latent_dim=20):
        self.input_dim = input_dim
        self.latent_dim = latent_dim
        self.encoder = None
        self.decoder = None
        self.vae = None
    def build_encoder(self):
        """ÊûÑÂª∫ÁºñÁ†ÅÂô®"""
        inputs = tf.keras.layers.Input(shape=(self.input_dim,))
        x = tf.keras.layers.Dense(128, activation='relu')(inputs)
        x = tf.keras.layers.Dense(64, activation='relu')(x)
        # ÊΩúÂú®Á©∫Èó¥ÂèÇÊï∞
        z_mean = tf.keras.layers.Dense(self.latent_dim)(x)
        z_log_var = tf.keras.layers.Dense(self.latent_dim)(x)
        self.encoder = tf.keras.Model(inputs, [z_mean, z_log_var])
        return self.encoder
    
    def build_decoder(self):
        """ÊûÑÂª∫Ëß£Á†ÅÂô®"""
        latent_inputs = tf.keras.layers.Input(shape=(self.latent_dim,))
        x = tf.keras.layers.Dense(64, activation='relu')(latent_inputs)
        x = tf.keras.layers.Dense(128, activation='relu')(x)
        outputs = tf.keras.layers.Dense(self.input_dim, activation='sigmoid')(x)
        self.decoder = tf.keras.Model(latent_inputs, outputs)
        return self.decoder
    
    def sampling(self, args):
        """ÈáçÂèÇÊï∞ÂåñÈááÊ†∑"""
        z_mean, z_log_var = args
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon
    
    def build_vae(self):
        """ÊûÑÂª∫ÂÆåÊï¥VAEÊ®°Âûã"""
        # ÊûÑÂª∫ÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®
        self.build_encoder()
        self.build_decoder()
        
        # VAEËæìÂÖ•
        inputs = tf.keras.layers.Input(shape=(self.input_dim,))
        z_mean, z_log_var = self.encoder(inputs)
        
        # ÈááÊ†∑Â±Ç
        z = tf.keras.layers.Lambda(self.sampling)([z_mean, z_log_var])
        
        # Ëß£Á†ÅÂô®ËæìÂá∫
        outputs = self.decoder(z)
        
        # ÊûÑÂª∫VAEÊ®°Âûã
        self.vae = tf.keras.Model(inputs, outputs)
        
        # Ëá™ÂÆö‰πâÊçüÂ§±ÂáΩÊï∞
        def vae_loss(y_true, y_pred):
            # ÈáçÊûÑÊçüÂ§±
            reconstruction_loss = tf.keras.losses.mse(y_true, y_pred)
            reconstruction_loss *= self.input_dim
            
            # KLÊï£Â∫¶ÊçüÂ§±
            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
            kl_loss = tf.reduce_mean(kl_loss)
            kl_loss *= -0.5
            
            return tf.reduce_mean(reconstruction_loss + kl_loss)
        
        self.vae.compile(
            optimizer='adam',
            loss=vae_loss
        )
        
        return self.vae
    
    def train(self, X_train, epochs=100, batch_size=32):
        """ËÆ≠ÁªÉVAEÊ®°Âûã"""
        # Êï∞ÊçÆÊ†áÂáÜÂåñ
        from sklearn.preprocessing import MinMaxScaler
        self.scaler = MinMaxScaler()
        X_scaled = self.scaler.fit_transform(X_train)
        
        # ËÆ≠ÁªÉÊ®°Âûã
        history = self.vae.fit(
            X_scaled, X_scaled,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.2,
            verbose=1
        )
        
        return history
    
    def detect_anomalies(self, X_test, threshold_percentile=95):
        """ÂºÇÂ∏∏Ê£ÄÊµã"""
        # Ê†áÂáÜÂåñÊï∞ÊçÆ
        X_scaled = self.scaler.transform(X_test)
        
        # ÈáçÊûÑÊï∞ÊçÆ
        X_reconstructed = self.vae.predict(X_scaled)
        
        # ËÆ°ÁÆóÈáçÊûÑËØØÂ∑Æ
        reconstruction_errors = np.mean(np.square(X_scaled - X_reconstructed), axis=1)
        
        # ËÆæÂÆöÈòàÂÄº
        threshold = np.percentile(reconstruction_errors, threshold_percentile)
        
        # Ê†áËÆ∞ÂºÇÂ∏∏
        anomalies = reconstruction_errors > threshold
        
        return anomalies, reconstruction_errors, threshold

# ÁîüÊàêÈáëËûçÂºÇÂ∏∏Êï∞ÊçÆ
def generate_financial_anomaly_data(n_samples=1000, n_features=10):
    """ÁîüÊàêÂåÖÂê´ÂºÇÂ∏∏ÁöÑÈáëËûçÊï∞ÊçÆ"""
    np.random.seed(42)
    
    # Ê≠£Â∏∏Êï∞ÊçÆ
    normal_data = []
    for i in range(int(n_samples * 0.9)):
        sample = []
        for j in range(n_features):
            # Ê®°ÊãüÊ≠£Â∏∏ÁöÑÈáëËûçÊåáÊ†á
            value = 50 + 10 * np.sin(i * 0.1) + np.random.normal(0, 2)
            sample.append(value)
        normal_data.append(sample)
    
    # ÂºÇÂ∏∏Êï∞ÊçÆ
    anomaly_data = []
    for i in range(int(n_samples * 0.1)):
        sample = []
        for j in range(n_features):
            # ÂºÇÂ∏∏ÂÄºÔºöÊûÅÁ´ØÊ≥¢Âä®
            if np.random.random() < 0.5:
                value = np.random.choice([20, 80]) + np.random.normal(0, 5)
            else:
                value = 50 + np.random.normal(0, 15)
            sample.append(value)
        anomaly_data.append(sample)
    
    # ÂêàÂπ∂Âπ∂Êâì‰π±Êï∞ÊçÆ
    all_data = normal_data + anomaly_data
    labels = [0] * len(normal_data) + [1] * len(anomaly_data)
    
    indices = np.random.permutation(len(all_data))
    data = np.array(all_data)[indices]
    labels = np.array(labels)[indices]
    
    return data, labels

# VAEÂºÇÂ∏∏Ê£ÄÊµãÊºîÁ§∫
def demo_vae_anomaly_detection():
    """VAEÂºÇÂ∏∏Ê£ÄÊµãÊºîÁ§∫"""
    # ÁîüÊàêÊï∞ÊçÆ
    data, true_labels = generate_financial_anomaly_data()
    
    # ÂàÜÂâ≤Êï∞ÊçÆ
    split_idx = int(0.8 * len(data))
    X_train = data[:split_idx]
    X_test = data[split_idx:]
    y_test = true_labels[split_idx:]
    
    # ÂàõÂª∫ÂíåËÆ≠ÁªÉVAE
    vae = FinancialVAE(input_dim=10, latent_dim=5)
    vae.build_vae()
    
    print("ËÆ≠ÁªÉVAEÊ®°Âûã...")
    history = vae.train(X_train, epochs=50)
    
    # ÂºÇÂ∏∏Ê£ÄÊµã
    anomalies, errors, threshold = vae.detect_anomalies(X_test)
    
    # ËØÑ‰º∞ÁªìÊûú
    from sklearn.metrics import classification_report
    print(f"\nÊ£ÄÊµãÂà∞ {np.sum(anomalies)} ‰∏™ÂºÇÂ∏∏ÁÇπ")
    print(f"ÁúüÂÆûÂºÇÂ∏∏ÁÇπ: {np.sum(y_test)} ‰∏™")
    print("\nÂàÜÁ±ªÊä•Âëä:")
    print(classification_report(y_test, anomalies.astype(int)))
    
    return vae, anomalies, errors

# ËøêË°åVAEÊºîÁ§∫
if __name__ == "__main__":
    vae_model, detected_anomalies, reconstruction_errors = demo_vae_anomaly_detection()
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- ÂÆûÈôÖÂ∫îÁî®Ê°à‰æã -->
                    <section id="practical-applications" class="content-section mb-5">
                        <h2>üíº ÂÆûÈôÖÂ∫îÁî®Ê°à‰æã</h2>
                        
                        <div class="model-card">
                            <h5>üìà Êô∫ËÉΩÈáèÂåñ‰∫§ÊòìÁ≥ªÁªü</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÈáèÂåñ‰∫§ÊòìÁ≥ªÁªü
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
import yfinance as yf
from datetime import datetime, timedelta

class DeepTradingSystem:
    def __init__(self, symbols, lookback_window=60):
        self.symbols = symbols
        self.lookback_window = lookback_window
        self.models = {}
        self.scalers = {}
        self.positions = {symbol: 0 for symbol in symbols}
        self.portfolio_value = 100000  # ÂàùÂßãËµÑÈáë
        
    def fetch_data(self, symbol, period="2y"):
        """Ëé∑ÂèñËÇ°Á•®Êï∞ÊçÆ"""
        stock = yf.Ticker(symbol)
        data = stock.history(period=period)
        
        # ËÆ°ÁÆóÊäÄÊúØÊåáÊ†á
        data['SMA_20'] = data['Close'].rolling(window=20).mean()
        data['SMA_50'] = data['Close'].rolling(window=50).mean()
        data['RSI'] = self.calculate_rsi(data['Close'])
        data['MACD'] = self.calculate_macd(data['Close'])
        data['Volatility'] = data['Close'].rolling(window=20).std()
        
        return data.dropna()
    
    def calculate_rsi(self, prices, window=14):
        """ËÆ°ÁÆóRSIÊåáÊ†á"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    def calculate_macd(self, prices, fast=12, slow=26):
        """ËÆ°ÁÆóMACDÊåáÊ†á"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        return ema_fast - ema_slow
    
    def prepare_features(self, data):
        """ÂáÜÂ§áÊ®°ÂûãÁâπÂæÅ"""
        features = ['Close', 'Volume', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Volatility']
        feature_data = data[features].values
        
        # Ê†áÂáÜÂåñÁâπÂæÅ
        scaler = MinMaxScaler()
        scaled_features = scaler.fit_transform(feature_data)
        
        return scaled_features, scaler
    
    def create_sequences(self, data, target):
        """ÂàõÂª∫Êó∂Èó¥Â∫èÂàóÊï∞ÊçÆ"""
        X, y = [], []
        for i in range(self.lookback_window, len(data)):
            X.append(data[i-self.lookback_window:i])
            y.append(target[i])
        return np.array(X), np.array(y)
    
    def build_model(self, input_shape):
        """ÊûÑÂª∫LSTMÊ®°Âûã"""
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(50, return_sequences=True, input_shape=input_shape),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.LSTM(50, return_sequences=True),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.LSTM(50),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(25),
            tf.keras.layers.Dense(1, activation='sigmoid')  # 0-1‰πãÈó¥ÁöÑ‰ø°Âè∑Âº∫Â∫¶
        ])
        
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model
    
    def train_model(self, symbol):
        """ËÆ≠ÁªÉÂçï‰∏™ËÇ°Á•®ÁöÑÊ®°Âûã"""
        print(f"ËÆ≠ÁªÉ {symbol} ÁöÑÊ®°Âûã...")
        
        # Ëé∑ÂèñÊï∞ÊçÆ
        data = self.fetch_data(symbol)
        
        # ÂáÜÂ§áÁâπÂæÅ
        features, scaler = self.prepare_features(data)
        self.scalers[symbol] = scaler
        
        # ÂàõÂª∫ÁõÆÊ†áÂèòÈáèÔºàÊú™Êù•Êî∂ÁõäÁéáÁöÑÊñπÂêëÔºâ
        future_returns = data['Close'].pct_change().shift(-1)
        target = (future_returns > 0).astype(int).values[:-1]  # 1Ë°®Á§∫‰∏äÊ∂®Ôºå0Ë°®Á§∫‰∏ãË∑å
        
        # ÂàõÂª∫Â∫èÂàó
        X, y = self.create_sequences(features[:-1], target)
        
        # ÂàÜÂâ≤ËÆ≠ÁªÉÂíåÊµãËØïÈõÜ
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # ÊûÑÂª∫ÂíåËÆ≠ÁªÉÊ®°Âûã
        model = self.build_model((self.lookback_window, features.shape[1]))
        
        # Êó©ÂÅúÂíåÊ®°ÂûãÊ£ÄÊü•ÁÇπ
        callbacks = [
            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)
        ]
        
        history = model.fit(
            X_train, y_train,
            epochs=100,
            batch_size=32,
            validation_data=(X_test, y_test),
            callbacks=callbacks,
            verbose=0
        )
        
        self.models[symbol] = model
        
        # ËØÑ‰º∞Ê®°Âûã
        test_pred = model.predict(X_test)
        accuracy = np.mean((test_pred.flatten() > 0.5) == y_test)
        print(f"{symbol} Ê®°ÂûãÂáÜÁ°ÆÁéá: {accuracy:.3f}")
        
        return history
    
    def generate_signal(self, symbol, current_data):
        """ÁîüÊàê‰∫§Êòì‰ø°Âè∑"""
        if symbol not in self.models:
            return 0
        
        model = self.models[symbol]
        scaler = self.scalers[symbol]
        
        # ÂáÜÂ§áÂΩìÂâçÊï∞ÊçÆ
        features = ['Close', 'Volume', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Volatility']
        feature_data = current_data[features].values
        scaled_data = scaler.transform(feature_data)
        
        # Ëé∑ÂèñÊúÄËøëÁöÑÂ∫èÂàó
        if len(scaled_data) >= self.lookback_window:
            sequence = scaled_data[-self.lookback_window:].reshape(1, self.lookback_window, -1)
            prediction = model.predict(sequence, verbose=0)[0][0]
            
            # ËΩ¨Êç¢‰∏∫‰∫§Êòì‰ø°Âè∑
            if prediction > 0.7:  # Âº∫ÁÉàÁúãÊ∂®
                return 1
            elif prediction < 0.3:  # Âº∫ÁÉàÁúãË∑å
                return -1
            else:
                return 0  # ÊåÅÊúâ
        
        return 0
    
    def execute_trade(self, symbol, signal, current_price):
        """ÊâßË°å‰∫§Êòì"""
        position_size = self.portfolio_value * 0.1  # ÊØèÊ¨°‰∫§Êòì‰ΩøÁî®10%ÁöÑËµÑÈáë
        
        if signal == 1 and self.positions[symbol] <= 0:  # ‰π∞ÂÖ•‰ø°Âè∑
            shares = position_size / current_price
            self.positions[symbol] += shares
            self.portfolio_value -= shares * current_price
            print(f"‰π∞ÂÖ• {symbol}: {shares:.2f} ËÇ°Ôºå‰ª∑Ê†º: ${current_price:.2f}")
            
        elif signal == -1 and self.positions[symbol] > 0:  # ÂçñÂá∫‰ø°Âè∑
            shares = self.positions[symbol]
            self.positions[symbol] = 0
            self.portfolio_value += shares * current_price
            print(f"ÂçñÂá∫ {symbol}: {shares:.2f} ËÇ°Ôºå‰ª∑Ê†º: ${current_price:.2f}")
    
    def backtest(self, start_date, end_date):
        """ÂõûÊµãÁ≠ñÁï•"""
        print(f"\nÂºÄÂßãÂõûÊµã: {start_date} Âà∞ {end_date}")
        
        portfolio_values = []
        dates = []
        
        # Ëé∑ÂèñÂõûÊµãÊúüÈó¥ÁöÑÊï∞ÊçÆ
        for symbol in self.symbols:
            data = self.fetch_data(symbol, period="1y")
            data = data[start_date:end_date]
            
            for date, row in data.iterrows():
                signal = self.generate_signal(symbol, data.loc[:date])
                self.execute_trade(symbol, signal, row['Close'])
                
                # ËÆ°ÁÆóÂΩìÂâçÁªÑÂêà‰ª∑ÂÄº
                total_value = self.portfolio_value
                for sym, pos in self.positions.items():
                    if pos > 0:
                        current_data = self.fetch_data(sym, period="1d")
                        if not current_data.empty:
                            total_value += pos * current_data['Close'].iloc[-1]
                
                portfolio_values.append(total_value)
                dates.append(date)
        
        # ËÆ°ÁÆóÂõûÊµãÁªìÊûú
        initial_value = 100000
        final_value = portfolio_values[-1] if portfolio_values else initial_value
        total_return = (final_value - initial_value) / initial_value
        
        print(f"\nÂõûÊµãÁªìÊûú:")
        print(f"ÂàùÂßãËµÑÈáë: ${initial_value:,.2f}")
        print(f"ÊúÄÁªà‰ª∑ÂÄº: ${final_value:,.2f}")
        print(f"ÊÄªÊî∂ÁõäÁéá: {total_return:.2%}")
        
        return portfolio_values, dates

# ‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    # ÂàõÂª∫‰∫§ÊòìÁ≥ªÁªü
    symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA']
    trading_system = DeepTradingSystem(symbols)
    
    # ËÆ≠ÁªÉÊ®°Âûã
    for symbol in symbols:
        trading_system.train_model(symbol)
    
    # ÂõûÊµãÁ≠ñÁï•
    start_date = '2023-01-01'
    end_date = '2023-12-31'
    portfolio_values, dates = trading_system.backtest(start_date, end_date)
    
    print("\nüöÄ Ê∑±Â∫¶Â≠¶‰π†ÈáèÂåñ‰∫§ÊòìÁ≥ªÁªüÈÉ®ÁΩ≤ÂÆåÊàêÔºÅ")
</code></pre>
                            </div>
                        </div>
                        
                        <div class="row mt-4">
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h5>üõ°Ô∏è Êô∫ËÉΩÈ£éÈô©ÁÆ°ÁêÜÁ≥ªÁªü</h5>
                                    <div class="code-example">
                                        <pre><code class="language-python"># Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÈ£éÈô©ÁÆ°ÁêÜÁ≥ªÁªü
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

class RiskManagementSystem:
    def __init__(self):
        self.anomaly_detector = None
        self.var_model = None
        self.stress_test_model = None
        self.scaler = StandardScaler()
        
    def detect_anomalies(self, transaction_data):
        """ÂºÇÂ∏∏‰∫§ÊòìÊ£ÄÊµã"""
        features = ['amount', 'frequency', 'time_of_day', 'location_risk']
        X = transaction_data[features]
        
        # Ê†áÂáÜÂåñÁâπÂæÅ
        X_scaled = self.scaler.fit_transform(X)
        
        # ‰ΩøÁî®Isolation ForestÊ£ÄÊµãÂºÇÂ∏∏
        self.anomaly_detector = IsolationForest(
            contamination=0.1, random_state=42
        )
        anomalies = self.anomaly_detector.fit_predict(X_scaled)
        
        # ËøîÂõûÂºÇÂ∏∏‰∫§Êòì
        return transaction_data[anomalies == -1]
    
    def calculate_var(self, returns, confidence_level=0.05):
        """ËÆ°ÁÆóÈ£éÈô©‰ª∑ÂÄº(VaR)"""
        # ‰ΩøÁî®LSTMÈ¢ÑÊµãÊî∂ÁõäÁéáÂàÜÂ∏É
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(50, input_shape=(30, 1)),
            tf.keras.layers.Dense(25),
            tf.keras.layers.Dense(1)
        ])
        
        model.compile(optimizer='adam', loss='mse')
        
        # ËÆ≠ÁªÉÊ®°ÂûãÈ¢ÑÊµãÊî∂ÁõäÁéá
        # ... ËÆ≠ÁªÉ‰ª£Á†Å ...
        
        # ËÆ°ÁÆóVaR
        var = np.percentile(returns, confidence_level * 100)
        return var

# ‰ΩøÁî®Á§∫‰æã
risk_system = RiskManagementSystem()
print("È£éÈô©ÁÆ°ÁêÜÁ≥ªÁªüÂ∑≤ÂêØÂä®")
</code></pre>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h5>üîç ÂèçÊ¨∫ËØàÊ£ÄÊµãÁ≥ªÁªü</h5>
                                    <div class="code-example">
                                        <pre><code class="language-python"># Ê∑±Â∫¶Â≠¶‰π†ÂèçÊ¨∫ËØàÊ£ÄÊµãÁ≥ªÁªü
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

class FraudDetectionSystem:
    def __init__(self):
        self.model = None
        self.feature_encoders = {}
        
    def preprocess_data(self, data):
        """Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"""
        # ÁºñÁ†ÅÂàÜÁ±ªÁâπÂæÅ
        categorical_features = ['merchant_category', 'card_type', 'location']
        
        for feature in categorical_features:
            if feature in data.columns:
                le = LabelEncoder()
                data[feature] = le.fit_transform(data[feature])
                self.feature_encoders[feature] = le
        
        return data
    
    def build_model(self, input_dim):
        """ÊûÑÂª∫Ê∑±Â∫¶Â≠¶‰π†Ê®°Âûã"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu', input_dim=input_dim),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return model
    
    def train(self, transaction_data, labels):
        """ËÆ≠ÁªÉÊ®°Âûã"""
        # È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ
        processed_data = self.preprocess_data(transaction_data)
        
        # ÂàÜÂâ≤Êï∞ÊçÆ
        X_train, X_test, y_train, y_test = train_test_split(
            processed_data, labels, test_size=0.2, random_state=42
        )
        
        # ÊûÑÂª∫Ê®°Âûã
        self.model = self.build_model(X_train.shape[1])
        
        # ËÆ≠ÁªÉÊ®°Âûã
        history = self.model.fit(
            X_train, y_train,
            epochs=50,
            batch_size=32,
            validation_data=(X_test, y_test),
            verbose=1
        )
        
        return history
    
    def predict_fraud(self, transaction):
        """È¢ÑÊµãÊ¨∫ËØàÊ¶ÇÁéá"""
        if self.model is None:
            raise ValueError("Ê®°ÂûãÊú™ËÆ≠ÁªÉ")
        
        # È¢ÑÂ§ÑÁêÜÂçï‰∏™‰∫§Êòì
        processed_transaction = self.preprocess_data(transaction)
        
        # È¢ÑÊµã
        fraud_probability = self.model.predict(processed_transaction)[0][0]
        
        return {
            'fraud_probability': fraud_probability,
            'is_fraud': fraud_probability > 0.5,
            'risk_level': 'High' if fraud_probability > 0.8 else 
                         'Medium' if fraud_probability > 0.5 else 'Low'
        }

# ‰ΩøÁî®Á§∫‰æã
fraud_detector = FraudDetectionSystem()
print("ÂèçÊ¨∫ËØàÁ≥ªÁªüÂ∑≤ÂàùÂßãÂåñ")
</code></pre>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="model-card mt-4">
                            <h5>üìä Êô∫ËÉΩÊäïËµÑÁªÑÂêà‰ºòÂåñ</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># Âü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑÊäïËµÑÁªÑÂêà‰ºòÂåñ
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
import gym
from collections import deque
import random

class PortfolioOptimizationAgent:
    def __init__(self, state_size, action_size, learning_rate=0.001):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = deque(maxlen=2000)
        self.epsilon = 1.0  # Êé¢Á¥¢Áéá
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = learning_rate
        self.model = self._build_model()
        self.target_model = self._build_model()
        self.update_target_model()
        
    def _build_model(self):
        """ÊûÑÂª∫Ê∑±Â∫¶QÁΩëÁªú"""
        model = tf.keras.Sequential([
            layers.Dense(128, activation='relu', input_dim=self.state_size),
            layers.Dropout(0.2),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(32, activation='relu'),
            layers.Dense(self.action_size, activation='linear')
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate),
            loss='mse'
        )
        
        return model
    
    def update_target_model(self):
        """Êõ¥Êñ∞ÁõÆÊ†áÁΩëÁªú"""
        self.target_model.set_weights(self.model.get_weights())
    
    def remember(self, state, action, reward, next_state, done):
        """Â≠òÂÇ®ÁªèÈ™å"""
        self.memory.append((state, action, reward, next_state, done))
    
    def act(self, state):
        """ÈÄâÊã©Âä®‰Ωú"""
        if np.random.random() <= self.epsilon:
            return random.randrange(self.action_size)
        
        q_values = self.model.predict(state, verbose=0)
        return np.argmax(q_values[0])
    
    def replay(self, batch_size=32):
        """ÁªèÈ™åÂõûÊîæËÆ≠ÁªÉ"""
        if len(self.memory) < batch_size:
            return
        
        batch = random.sample(self.memory, batch_size)
        states = np.array([e[0] for e in batch])
        actions = np.array([e[1] for e in batch])
        rewards = np.array([e[2] for e in batch])
        next_states = np.array([e[3] for e in batch])
        dones = np.array([e[4] for e in batch])
        
        states = np.squeeze(states)
        next_states = np.squeeze(next_states)
        
        targets = rewards + 0.95 * np.amax(self.target_model.predict(next_states, verbose=0), axis=1) * (1 - dones)
        targets_full = self.model.predict(states, verbose=0)
        
        ind = np.array([i for i in range(batch_size)])
        targets_full[[ind], [actions]] = targets
        
        self.model.fit(states, targets_full, epochs=1, verbose=0)
        
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

class PortfolioEnvironment:
    def __init__(self, data, initial_balance=10000):
        self.data = data
        self.initial_balance = initial_balance
        self.current_step = 0
        self.balance = initial_balance
        self.shares_held = np.zeros(len(data.columns))
        self.net_worth = initial_balance
        self.max_net_worth = initial_balance
        
    def reset(self):
        """ÈáçÁΩÆÁéØÂ¢É"""
        self.current_step = 0
        self.balance = self.initial_balance
        self.shares_held = np.zeros(len(self.data.columns))
        self.net_worth = self.initial_balance
        self.max_net_worth = self.initial_balance
        
        return self._get_observation()
    
    def _get_observation(self):
        """Ëé∑ÂèñÂΩìÂâçÁä∂ÊÄÅ"""
        frame = np.array([
            self.balance,
            self.net_worth,
            *self.shares_held,
            *self.data.iloc[self.current_step].values
        ])
        
        return frame
    
    def step(self, action):
        """ÊâßË°åÂä®‰Ωú"""
        current_price = self.data.iloc[self.current_step]
        
        # Âä®‰ΩúÊò†Â∞ÑÔºö0=ÊåÅÊúâÔºå1=‰π∞ÂÖ•Ôºå2=ÂçñÂá∫
        if action == 1:  # ‰π∞ÂÖ•
            # Âπ≥ÂùáÂàÜÈÖçËµÑÈáëË¥≠‰π∞ÊâÄÊúâËµÑ‰∫ß
            total_possible = self.balance // len(current_price)
            for i, price in enumerate(current_price):
                if price > 0:
                    shares_bought = total_possible // price
                    self.shares_held[i] += shares_bought
                    self.balance -= shares_bought * price
                    
        elif action == 2:  # ÂçñÂá∫
            # ÂçñÂá∫ÊâÄÊúâÊåÅ‰ªì
            for i, price in enumerate(current_price):
                if self.shares_held[i] > 0:
                    self.balance += self.shares_held[i] * price
                    self.shares_held[i] = 0
        
        # ËÆ°ÁÆóÂΩìÂâçÂáÄÂÄº
        self.net_worth = self.balance + np.sum(self.shares_held * current_price)
        
        # ËÆ°ÁÆóÂ•ñÂä±
        reward = self.net_worth - self.max_net_worth
        if self.net_worth > self.max_net_worth:
            self.max_net_worth = self.net_worth
        
        # Ê£ÄÊü•ÊòØÂê¶ÁªìÊùü
        self.current_step += 1
        done = self.current_step >= len(self.data) - 1
        
        return self._get_observation(), reward, done, {}

# ‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    # ÂàõÂª∫Ê®°ÊãüÊï∞ÊçÆ
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    stock_data = pd.DataFrame({
        'AAPL': 100 * np.cumprod(1 + np.random.normal(0.001, 0.02, 1000)),
        'GOOGL': 1000 * np.cumprod(1 + np.random.normal(0.001, 0.025, 1000)),
        'MSFT': 200 * np.cumprod(1 + np.random.normal(0.001, 0.02, 1000))
    }, index=dates)
    
    # ÂàõÂª∫ÁéØÂ¢ÉÂíåÊô∫ËÉΩ‰Ωì
    env = PortfolioEnvironment(stock_data)
    state_size = len(env._get_observation())
    action_size = 3  # ÊåÅÊúâ„ÄÅ‰π∞ÂÖ•„ÄÅÂçñÂá∫
    
    agent = PortfolioOptimizationAgent(state_size, action_size)
    
    # ËÆ≠ÁªÉÊô∫ËÉΩ‰Ωì
    episodes = 100
    for episode in range(episodes):
        state = env.reset()
        state = np.reshape(state, [1, state_size])
        total_reward = 0
        
        for time in range(500):
            action = agent.act(state)
            next_state, reward, done, _ = env.step(action)
            next_state = np.reshape(next_state, [1, state_size])
            
            agent.remember(state, action, reward, next_state, done)
            state = next_state
            total_reward += reward
            
            if done:
                agent.update_target_model()
                print(f"Episode: {episode+1}, Total Reward: {total_reward:.2f}, Net Worth: {env.net_worth:.2f}")
                break
            
            if len(agent.memory) > 32:
                agent.replay(32)
    
    print("\nüéØ Êô∫ËÉΩÊäïËµÑÁªÑÂêà‰ºòÂåñÁ≥ªÁªüËÆ≠ÁªÉÂÆåÊàêÔºÅ")
</code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- ÊÄßËÉΩÂØπÊØî -->
                    <section id="performance-comparison" class="content-section mb-5">
                        <h2>üìä Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÊÄßËÉΩÂØπÊØî</h2>
                        
                        <div class="performance-metrics">
                            <h5>üìà Ê®°ÂûãÂáÜÁ°ÆÁéáÂØπÊØî</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># ‰∏çÂêåÊ®°ÂûãÁöÑÊÄßËÉΩÂØπÊØî
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Ê®°ÂûãÊÄßËÉΩÊï∞ÊçÆ
performance_data = {
    'Ê®°Âûã': ['Á∫øÊÄßÂõûÂΩí', 'SVM', 'ÈöèÊú∫Ê£ÆÊûó', 'LSTM', 'CNN', 'Transformer'],
    'ÂáÜÁ°ÆÁéá': [0.72, 0.78, 0.82, 0.85, 0.87, 0.91],
    'ËÆ≠ÁªÉÊó∂Èó¥(ÂàÜÈíü)': [2, 15, 8, 45, 30, 120],
    'ÂÜÖÂ≠ò‰ΩøÁî®(GB)': [0.5, 1.2, 2.1, 4.5, 3.8, 8.2],
    'Êé®ÁêÜÈÄüÂ∫¶(ms)': [1, 5, 3, 15, 12, 25]
}

df = pd.DataFrame(performance_data)
print("Ê®°ÂûãÊÄßËÉΩÂØπÊØîË°®Ôºö")
print(df)

# ÂèØËßÜÂåñÊÄßËÉΩÂØπÊØî
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# ÂáÜÁ°ÆÁéáÂØπÊØî
axes[0,0].bar(df['Ê®°Âûã'], df['ÂáÜÁ°ÆÁéá'], color='skyblue')
axes[0,0].set_title('Ê®°ÂûãÂáÜÁ°ÆÁéáÂØπÊØî')
axes[0,0].set_ylabel('ÂáÜÁ°ÆÁéá')
axes[0,0].tick_params(axis='x', rotation=45)

# ËÆ≠ÁªÉÊó∂Èó¥ÂØπÊØî
axes[0,1].bar(df['Ê®°Âûã'], df['ËÆ≠ÁªÉÊó∂Èó¥(ÂàÜÈíü)'], color='lightcoral')
axes[0,1].set_title('ËÆ≠ÁªÉÊó∂Èó¥ÂØπÊØî')
axes[0,1].set_ylabel('Êó∂Èó¥(ÂàÜÈíü)')
axes[0,1].tick_params(axis='x', rotation=45)

# ÂÜÖÂ≠ò‰ΩøÁî®ÂØπÊØî
axes[1,0].bar(df['Ê®°Âûã'], df['ÂÜÖÂ≠ò‰ΩøÁî®(GB)'], color='lightgreen')
axes[1,0].set_title('ÂÜÖÂ≠ò‰ΩøÁî®ÂØπÊØî')
axes[1,0].set_ylabel('ÂÜÖÂ≠ò(GB)')
axes[1,0].tick_params(axis='x', rotation=45)

# Êé®ÁêÜÈÄüÂ∫¶ÂØπÊØî
axes[1,1].bar(df['Ê®°Âûã'], df['Êé®ÁêÜÈÄüÂ∫¶(ms)'], color='gold')
axes[1,1].set_title('Êé®ÁêÜÈÄüÂ∫¶ÂØπÊØî')
axes[1,1].set_ylabel('Êó∂Èó¥(ms)')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
</code></pre>
                            </div>
                        </div>
                        
                        <div class="performance-metrics">
                            <h5>üéØ ÂÆûÈôÖ‰∫§ÊòìÁ≠ñÁï•ÂõûÊµãÂØπÊØî</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># ‰∏çÂêåÊ®°ÂûãÁöÑ‰∫§ÊòìÁ≠ñÁï•ÂõûÊµã
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

class StrategyBacktest:
    def __init__(self, model_name, predictions, actual_prices):
        self.model_name = model_name
        self.predictions = predictions
        self.actual_prices = actual_prices
        self.returns = []
        self.positions = []
        
    def generate_signals(self):
        """Ê†πÊçÆÈ¢ÑÊµãÁîüÊàê‰∫§Êòì‰ø°Âè∑"""
        signals = []
        for i in range(1, len(self.predictions)):
            if self.predictions[i] > self.predictions[i-1] * 1.02:  # È¢ÑÊµã‰∏äÊ∂®2%‰ª•‰∏ä
                signals.append(1)  # ‰π∞ÂÖ•
            elif self.predictions[i] < self.predictions[i-1] * 0.98:  # È¢ÑÊµã‰∏ãË∑å2%‰ª•‰∏ä
                signals.append(-1)  # ÂçñÂá∫
            else:
                signals.append(0)  # ÊåÅÊúâ
        return signals
    
    def calculate_returns(self):
        """ËÆ°ÁÆóÁ≠ñÁï•Êî∂Áõä"""
        signals = self.generate_signals()
        portfolio_value = 10000  # ÂàùÂßãËµÑÈáë
        position = 0
        
        for i, signal in enumerate(signals):
            current_price = self.actual_prices[i+1]
            prev_price = self.actual_prices[i]
            
            if signal == 1 and position == 0:  # ‰π∞ÂÖ•
                position = portfolio_value / current_price
                portfolio_value = 0
            elif signal == -1 and position > 0:  # ÂçñÂá∫
                portfolio_value = position * current_price
                position = 0
            
            # ËÆ°ÁÆóÂΩìÂâçÁªÑÂêà‰ª∑ÂÄº
            current_value = portfolio_value + position * current_price
            self.returns.append(current_value)
            
        return self.returns
    
    def get_metrics(self):
        """ËÆ°ÁÆóÊÄßËÉΩÊåáÊ†á"""
        returns = self.calculate_returns()
        if len(returns) == 0:
            return {}
            
        total_return = (returns[-1] - 10000) / 10000
        daily_returns = np.diff(returns) / returns[:-1]
        sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252)
        max_drawdown = self.calculate_max_drawdown(returns)
        
        return {
            'ÊÄªÊî∂ÁõäÁéá': f"{total_return:.2%}",
            'Â§èÊôÆÊØîÁéá': f"{sharpe_ratio:.2f}",
            'ÊúÄÂ§ßÂõûÊí§': f"{max_drawdown:.2%}",
            'ËÉúÁéá': f"{self.calculate_win_rate():.1%}"
        }
    
    def calculate_max_drawdown(self, returns):
        """ËÆ°ÁÆóÊúÄÂ§ßÂõûÊí§"""
        peak = returns[0]
        max_dd = 0
        for value in returns:
            if value > peak:
                peak = value
            dd = (peak - value) / peak
            if dd > max_dd:
                max_dd = dd
        return max_dd
    
    def calculate_win_rate(self):
        """ËÆ°ÁÆóËÉúÁéá"""
        signals = self.generate_signals()
        wins = 0
        total_trades = 0
        
        for i, signal in enumerate(signals):
            if signal != 0:
                total_trades += 1
                if i < len(self.actual_prices) - 2:
                    future_return = (self.actual_prices[i+2] - self.actual_prices[i+1]) / self.actual_prices[i+1]
                    if (signal == 1 and future_return > 0) or (signal == -1 and future_return < 0):
                        wins += 1
        
        return wins / total_trades if total_trades > 0 else 0

# Ê®°Êãü‰∏çÂêåÊ®°ÂûãÁöÑÈ¢ÑÊµãÁªìÊûú
np.random.seed(42)
days = 252  # ‰∏ÄÂπ¥‰∫§ÊòìÊó•
actual_prices = 100 * np.cumprod(1 + np.random.normal(0.001, 0.02, days))

# ‰∏çÂêåÊ®°ÂûãÁöÑÈ¢ÑÊµãÂáÜÁ°ÆÊÄß
models = {
    'LSTM': np.random.normal(0.85, 0.1, days),
    'CNN': np.random.normal(0.82, 0.12, days),
    'Transformer': np.random.normal(0.88, 0.08, days),
    'ÈöèÊú∫Ê£ÆÊûó': np.random.normal(0.75, 0.15, days)
}

# ÁîüÊàêÈ¢ÑÊµã‰ª∑Ê†ºÔºàÂü∫‰∫éÂáÜÁ°ÆÊÄßÔºâ
results = {}
for model_name, accuracy in models.items():
    # Ê†πÊçÆÂáÜÁ°ÆÊÄßÁîüÊàêÈ¢ÑÊµã
    noise = np.random.normal(0, 0.05, days)
    predictions = actual_prices * (1 + noise * (1 - accuracy))
    
    # ÂõûÊµãÁ≠ñÁï•
    backtest = StrategyBacktest(model_name, predictions, actual_prices)
    metrics = backtest.get_metrics()
    results[model_name] = metrics

# ÊòæÁ§∫ÁªìÊûú
print("\nüìä ‰∏çÂêåÊ®°Âûã‰∫§ÊòìÁ≠ñÁï•ÊÄßËÉΩÂØπÊØîÔºö")
print("=" * 60)
for model, metrics in results.items():
    print(f"\nü§ñ {model}:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value}")
</code></pre>
                            </div>
                        </div>
                        
                        <div class="row mt-4">
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h6>‚ö° ËÆ°ÁÆóÊïàÁéáÂØπÊØî</h6>
                                    <ul>
                                        <li><strong>Á∫øÊÄßÊ®°Âûã</strong>: ËÆ≠ÁªÉÂø´ÔºåÊé®ÁêÜÂø´ÔºåÂÜÖÂ≠òÂ∞è</li>
                                        <li><strong>Ê†ëÊ®°Âûã</strong>: ËÆ≠ÁªÉ‰∏≠Á≠âÔºåÊé®ÁêÜÂø´ÔºåËß£ÈáäÊÄßÂ•Ω</li>
                                        <li><strong>Á•ûÁªèÁΩëÁªú</strong>: ËÆ≠ÁªÉÊÖ¢ÔºåÊé®ÁêÜ‰∏≠Á≠âÔºåÁ≤æÂ∫¶È´ò</li>
                                        <li><strong>Ê∑±Â∫¶Â≠¶‰π†</strong>: ËÆ≠ÁªÉÂæàÊÖ¢ÔºåÊé®ÁêÜÊÖ¢ÔºåÁ≤æÂ∫¶ÊúÄÈ´ò</li>
                                    </ul>
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h6>üéØ Â∫îÁî®Âú∫ÊôØÂª∫ËÆÆ</h6>
                                    <ul>
                                        <li><strong>È´òÈ¢ë‰∫§Êòì</strong>: ÈÄâÊã©Êé®ÁêÜÈÄüÂ∫¶Âø´ÁöÑÊ®°Âûã</li>
                                        <li><strong>È£éÈô©ÁÆ°ÁêÜ</strong>: ÈÄâÊã©Á®≥ÂÆöÊÄßÂ•ΩÁöÑÊ®°Âûã</li>
                                        <li><strong>ÈïøÊúüÊäïËµÑ</strong>: ÈÄâÊã©ÂáÜÁ°ÆÁéáÈ´òÁöÑÊ®°Âûã</li>
                                        <li><strong>ÂÆûÊó∂ÂÜ≥Á≠ñ</strong>: Âπ≥Ë°°Á≤æÂ∫¶ÂíåÈÄüÂ∫¶</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </section>
                        </div>
                    </section>
    </main>
                </div>
            </div>
        </div>
    </div>
    <!-- ÁßªÂä®Á´ØËèúÂçïÊåâÈíÆ -->
    
    
    <!-- JavaScript -->
    <script>
        // È°∂ÈÉ®ÂØºËà™ÂäüËÉΩ
        document.addEventListener('DOMContentLoaded', function() {
            const navButtons = document.querySelectorAll('.nav-btn');
            const contentSections = document.querySelectorAll('.content-section');
            
            // ÈªòËÆ§ÊòæÁ§∫Á¨¨‰∏Ä‰∏™Á´†ËäÇ
            if (contentSections.length > 0) {
                contentSections[0].classList.add('active');
            }
            if (navButtons.length > 0) {
                navButtons[0].classList.add('active');
            }
            
            // ÂØºËà™ÊåâÈíÆÁÇπÂáª‰∫ã‰ª∂
            navButtons.forEach(button => {
                button.addEventListener('click', function(e) {
                    e.preventDefault();
                    
                    // ÁßªÈô§ÊâÄÊúâÊ¥ªÂä®Áä∂ÊÄÅ
                    navButtons.forEach(btn => btn.classList.remove('active'));
                    contentSections.forEach(section => section.classList.remove('active'));
                    
                    // Ê∑ªÂä†ÂΩìÂâçÊ¥ªÂä®Áä∂ÊÄÅ
                    this.classList.add('active');
                    
                    // ÊòæÁ§∫ÂØπÂ∫îÁöÑÂÜÖÂÆπÁ´†ËäÇ
                    const targetSection = this.getAttribute('data-section');
                    const targetElement = document.getElementById(targetSection);
                    if (targetElement) {
                        targetElement.classList.add('active');
                        
                        // ÊªöÂä®Âà∞ÂÜÖÂÆπÂå∫Âüü
                        targetElement.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                });
            });
            
            // ÈîÆÁõòÂØºËà™ÊîØÊåÅ
            document.addEventListener('keydown', function(e) {
                const activeIndex = Array.from(navButtons).findIndex(button => 
                    button.classList.contains('active'));
                
                if (e.key === 'ArrowRight' && activeIndex < navButtons.length - 1) {
                    e.preventDefault();
                    navButtons[activeIndex + 1].click();
                } else if (e.key === 'ArrowLeft' && activeIndex > 0) {
                    e.preventDefault();
                    navButtons[activeIndex - 1].click();
                }
            });
        });
        
        // Ê∑ªÂä†ËøõÂ∫¶ÊåáÁ§∫Âô®
        function updateProgress() {
            const activeIndex = Array.from(document.querySelectorAll('.nav-btn'))
                .findIndex(button => button.classList.contains('active'));
            const totalSections = document.querySelectorAll('.nav-btn').length;
            const progress = ((activeIndex + 1) / totalSections) * 100;
            
            console.log(`Â≠¶‰π†ËøõÂ∫¶: ${Math.round(progress)}%`);
        }
    </script>
</body>
</html>