<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é¡µé¢æ ‡é¢˜</title>
    <link rel="stylesheet" href="css/style.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <style>
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            text-align: left;
        }
        
        .code-example pre {
            text-align: left;
            margin: 0;
        }
        
        .code-example code {
            text-align: left;
        }
        
        pre {
            text-align: left !important;
        }
        
        code {
            text-align: left !important;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        
        /* æ¦‚å¿µè§£é‡Šæ ·å¼ */
        .concept-explanation {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 12px;
            margin: 20px 0;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
            position: relative;
            overflow: hidden;
        }
        
        .concept-explanation::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #ffd700, #ff6b6b, #4ecdc4, #45b7d1);
        }
        
        .concept-explanation h4 {
            margin: 0 0 15px 0;
            font-size: 1.2em;
            font-weight: bold;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .concept-explanation p {
            margin: 10px 0;
            line-height: 1.6;
            font-size: 0.95em;
        }
        
        .concept-explanation strong {
            color: #ffd700;
            font-weight: bold;
        }
        
        /* å…¬å¼è§£é‡Šæ ·å¼ */
        .formula-explanation {
            background-color: #f8f9ff;
            color: #4a5568;
            padding: 8px 12px;
            border-left: 3px solid #667eea;
            margin: 5px 0 15px 20px;
            font-style: italic;
            font-size: 0.9em;
            border-radius: 0 6px 6px 0;
        }
        
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
            position: relative;
        }
        
        .math-formula::before {
            content: 'ğŸ“';
            position: absolute;
            top: 10px;
            right: 15px;
            font-size: 1.2em;
            opacity: 0.6;
        }
        
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
        
        /* é¡¶éƒ¨å¯¼èˆªæŒ‰é”®æ ·å¼ */
        .top-navigation {
            margin: 20px 0;
            padding: 20px;
            background: rgba(248, 249, 250, 0.8);
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
        
        .nav-btn {
            background: linear-gradient(135deg, #007bff, #0056b3);
            color: white;
            border: none;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.9em;
            box-shadow: 0 2px 8px rgba(0, 123, 255, 0.3);
        }
        
        .nav-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0, 123, 255, 0.4);
            background: linear-gradient(135deg, #0056b3, #004085);
        }
        
        .nav-btn.active {
            background: linear-gradient(135deg, #28a745, #1e7e34);
            box-shadow: 0 4px 15px rgba(40, 167, 69, 0.4);
            transform: translateY(-1px);
        }
        
        .nav-btn.active:hover {
            background: linear-gradient(135deg, #1e7e34, #155724);
        }
        
        /* å†…å®¹åˆ†é¡µæ ·å¼ */
        .content-section {
            display: none;
            animation: fadeIn 0.5s ease-in;
        }
        
        .content-section.active {
            display: block;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 768px) {
            .nav-btn {
                padding: 8px 12px;
                margin: 3px;
                font-size: 0.8em;
            }
            
            .top-navigation {
                padding: 15px;
            }
        }
        
        @media (max-width: 480px) {
            .nav-btn {
                padding: 6px 10px;
                margin: 2px;
                font-size: 0.75em;
                display: block;
                width: 100%;
                margin-bottom: 8px;
            }
            
            .top-navigation {
                padding: 10px;
            }
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="navigation-container"></div>



<script>
// åŠ¨æ€åŠ è½½å¯¼èˆªæ¡
function loadNavigation() {
    fetch('nav.html')
        .then(response => response.text())
        .then(html => {
            // æ›´æ–°å¯¼èˆªä¸­çš„é“¾æ¥è·¯å¾„
            let updatedHtml = html;
            
            // å¤„ç†æ ¹ç›®å½•æ–‡ä»¶é“¾æ¥ï¼ˆindex.html, syllabus.htmlç­‰ï¼‰
            updatedHtml = updatedHtml.replace(/href="index\.html"/g, 'href="index.html"');
            updatedHtml = updatedHtml.replace(/href="\.\/([^/]*\.html)"/g, 'href="$1"');
            
            // å¤„ç†æ¨¡å—è·¯å¾„é“¾æ¥ï¼ˆå·²ç»æ˜¯å®Œæ•´ç›¸å¯¹è·¯å¾„ï¼Œåªéœ€è¦æ·»åŠ æ ¹è·¯å¾„å‰ç¼€ï¼‰
            updatedHtml = updatedHtml.replace(/href="\.\/part([^"]*)"/g, 'href="part$1"');
            
            document.getElementById('navigation-container').innerHTML = updatedHtml;
            
            // æ·»åŠ ç§»åŠ¨ç«¯èœå•åˆ‡æ¢åŠŸèƒ½
            const menuToggle = document.getElementById('menuToggle');
            const navMenu = document.querySelector('.nav-menu');
            if (menuToggle && navMenu) {
                menuToggle.addEventListener('click', function() {
                    navMenu.classList.toggle('active');
                });
            }
        })
        .catch(error => console.error('å¯¼èˆªåŠ è½½å¤±è´¥:', error));
}

// é¡µé¢åŠ è½½å®ŒæˆååŠ è½½å¯¼èˆª
document.addEventListener('DOMContentLoaded', loadNavigation);
</script>



    
    <style>
        .math-formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #007bff;
            margin: 15px 0;
            border-radius: 5px;
        }
        .code-example {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
        }
        .complexity-badge {
            font-size: 0.8em;
            margin-left: 10px;
        }
        .model-card {
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        }
        .performance-metrics {
            background-color: #e7f3ff;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .neural-network-viz {
            text-align: center;
            margin: 20px 0;
        }
        .layer-node {
            display: inline-block;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(45deg, #007bff, #0056b3);
            color: white;
            line-height: 40px;
            margin: 5px;
            font-size: 12px;
        }
        .connection-line {
            stroke: #6c757d;
            stroke-width: 1;
            opacity: 0.6;
        }
    </style>
    

                </div>
            
<!-- ä¸»å†…å®¹åŒºåŸŸ -->
            <div class="container">
                <h1 class="text-center mb-4">æ·±åº¦å­¦ä¹ åœ¨é‡‘èä¸­çš„åº”ç”¨</h1>
                
                <!-- é¡¶éƒ¨å¯¼èˆªæŒ‰é”® -->
                <div class="top-navigation text-center mb-4">
                    <button class="nav-btn active" data-section="overview">ğŸ§  æ·±åº¦å­¦ä¹ æ¦‚è¿°</button>
                    <button class="nav-btn" data-section="neural-networks">ğŸ”— ç¥ç»ç½‘ç»œåŸºç¡€</button>
                    <button class="nav-btn" data-section="lstm-models">ğŸ”„ LSTMæ—¶é—´åºåˆ—</button>
                    <button class="nav-btn" data-section="cnn-models">ğŸ–¼ï¸ CNNå›¾åƒè¯†åˆ«</button>
                    <button class="nav-btn" data-section="transformer-models">ğŸ”„ Transformeræ³¨æ„åŠ›</button>
                    <button class="nav-btn" data-section="gan-models">ğŸ­ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ</button>
                    <button class="nav-btn" data-section="reinforcement-learning">ğŸ¯ å¼ºåŒ–å­¦ä¹ </button>
                    <button class="nav-btn" data-section="autoencoder">ğŸ”„ è‡ªç¼–ç å™¨</button>
                    <button class="nav-btn" data-section="practical-applications">ğŸ’¼ å®é™…åº”ç”¨</button>
                    <button class="nav-btn" data-section="performance-comparison">ğŸ“Š æ€§èƒ½å¯¹æ¯”</button>
                </div>
                    <!-- æ¦‚è¿° -->
    <main class="container">
                    <section id="overview" class="content-section mb-5">
                        <h2>ğŸ§  æ·±åº¦å­¦ä¹ æ¦‚è¿°</h2>
                        <p>æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡æ„å»ºå¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œæ·±åº¦å­¦ä¹ è¢«å¹¿æ³›åº”ç”¨äºä»·æ ¼é¢„æµ‹ã€é£é™©ç®¡ç†ã€ç®—æ³•äº¤æ˜“ã€æ¬ºè¯ˆæ£€æµ‹ç­‰åœºæ™¯ã€‚</p>
                        <div class="math-formula">
                            <h5>æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µ</h5>
                            <div class="concept-explanation">
                                <h4>ğŸ’¡ ä¸ºä»€ä¹ˆéœ€è¦è¿™äº›ç¥ç»ç½‘ç»œå…¬å¼ï¼Ÿ</h4>
                                <p>ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒæ€æƒ³æ˜¯æ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒçš„å·¥ä½œæ–¹å¼ã€‚åœ¨é‡‘èé¢„æµ‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä»å¤æ‚çš„å¸‚åœºæ•°æ®ä¸­æ‰¾åˆ°éšè—çš„æ¨¡å¼ï¼Œè€Œä¼ ç»Ÿçš„çº¿æ€§æ¨¡å‹å¾€å¾€æ— æ³•æ•æ‰è¿™äº›éçº¿æ€§å…³ç³»ã€‚</p>
                                <p><strong>ç”Ÿæ´»åŒ–ç†è§£ï¼š</strong>å°±åƒäººç±»å­¦ä¹ æŠ•èµ„ä¸€æ ·ï¼Œæˆ‘ä»¬å…ˆè§‚å¯Ÿå¸‚åœºæ•°æ®ï¼ˆå‰å‘ä¼ æ’­ï¼‰ï¼Œç„¶åæ ¹æ®ç»“æœçš„å¥½åè°ƒæ•´æˆ‘ä»¬çš„åˆ¤æ–­æ ‡å‡†ï¼ˆåå‘ä¼ æ’­ï¼‰ï¼Œä¸æ–­é‡å¤è¿™ä¸ªè¿‡ç¨‹ç›´åˆ°åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚</p>
                                <p><strong>å®é™…åº”ç”¨ï¼š</strong>åœ¨è‚¡ä»·é¢„æµ‹ä¸­ï¼Œç¥ç»ç½‘ç»œå¯ä»¥åŒæ—¶è€ƒè™‘æŠ€æœ¯æŒ‡æ ‡ã€åŸºæœ¬é¢æ•°æ®ã€å¸‚åœºæƒ…ç»ªç­‰å¤šä¸ªå› ç´ ï¼Œå¹¶è‡ªåŠ¨å‘ç°å®ƒä»¬ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚</p>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>ğŸ” å‰å‘ä¼ æ’­å…¬å¼æ¨å¯¼</h4>
                                <p><strong>æ­¥éª¤1ï¼šçº¿æ€§å˜æ¢</strong></p>
                                <p>å¯¹äºç¬¬lå±‚ï¼Œæˆ‘ä»¬éœ€è¦å°†å‰ä¸€å±‚çš„è¾“å‡ºa^[l-1]è½¬æ¢ä¸ºå½“å‰å±‚çš„è¾“å…¥z^[l]ï¼š</p>
                            </div>
                            \[ z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]} \]
                            <div class="formula-explanation">
                                <p><strong>å…¬å¼å«ä¹‰ï¼š</strong></p>
                                <ul>
                                    <li>W^[l]ï¼šç¬¬lå±‚çš„æƒé‡çŸ©é˜µï¼Œç»´åº¦ä¸º(n^[l], n^[l-1])</li>
                                    <li>a^[l-1]ï¼šå‰ä¸€å±‚çš„æ¿€æ´»è¾“å‡ºï¼Œç»´åº¦ä¸º(n^[l-1], 1)</li>
                                    <li>b^[l]ï¼šç¬¬lå±‚çš„åç½®å‘é‡ï¼Œç»´åº¦ä¸º(n^[l], 1)</li>
                                    <li>z^[l]ï¼šç¬¬lå±‚çš„çº¿æ€§è¾“å‡ºï¼Œç»´åº¦ä¸º(n^[l], 1)</li>
                                </ul>
                                <p><strong>è®¡ç®—ç¤ºä¾‹ï¼š</strong>å‡è®¾è¾“å…¥å±‚æœ‰3ä¸ªç‰¹å¾ï¼ˆå¼€ç›˜ä»·ã€æˆäº¤é‡ã€æŠ€æœ¯æŒ‡æ ‡ï¼‰ï¼Œéšè—å±‚æœ‰4ä¸ªç¥ç»å…ƒï¼š</p>
                                <pre>
W^[1] = [[0.2, 0.3, -0.1],    a^[0] = [[100],     b^[1] = [[0.1],
         [0.1, -0.2, 0.4],              [1000],              [0.2],
         [-0.3, 0.5, 0.2],              [0.6]]               [0.0],
         [0.4, 0.1, -0.2]]                                   [-0.1]]

z^[1] = W^[1] Ã— a^[0] + b^[1] = [[0.2Ã—100 + 0.3Ã—1000 - 0.1Ã—0.6 + 0.1],
                                 [0.1Ã—100 - 0.2Ã—1000 + 0.4Ã—0.6 + 0.2],
                                 [-0.3Ã—100 + 0.5Ã—1000 + 0.2Ã—0.6 + 0.0],
                                 [0.4Ã—100 + 0.1Ã—1000 - 0.2Ã—0.6 - 0.1]]
      = [[319.84], [-179.56], [470.12], [49.78]]
                                </pre>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>ğŸ” æ¿€æ´»å‡½æ•°æ¨å¯¼</h4>
                                <p><strong>æ­¥éª¤2ï¼šéçº¿æ€§æ¿€æ´»</strong></p>
                                <p>çº¿æ€§å˜æ¢åï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡æ¿€æ´»å‡½æ•°å¼•å…¥éçº¿æ€§ï¼š</p>
                            </div>
                            \[ a^{[l]} = g^{[l]}(z^{[l]}) \]
                            <div class="formula-explanation">
                                <p><strong>æ¿€æ´»å‡½æ•°é€‰æ‹©åŸç†ï¼š</strong></p>
                                <ul>
                                    <li><strong>ReLUï¼š</strong>g(z) = max(0, z)ï¼Œè®¡ç®—ç®€å•ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±</li>
                                    <li><strong>Sigmoidï¼š</strong>g(z) = 1/(1+e^(-z))ï¼Œè¾“å‡º[0,1]ï¼Œé€‚åˆæ¦‚ç‡</li>
                                    <li><strong>Tanhï¼š</strong>g(z) = (e^z - e^(-z))/(e^z + e^(-z))ï¼Œè¾“å‡º[-1,1]ï¼Œé›¶ä¸­å¿ƒ</li>
                                </ul>
                                <p><strong>è®¡ç®—ç¤ºä¾‹ï¼ˆä½¿ç”¨ReLUï¼‰ï¼š</strong></p>
                                <pre>
z^[1] = [[319.84], [-179.56], [470.12], [49.78]]
a^[1] = ReLU(z^[1]) = [[319.84], [0], [470.12], [49.78]]
                                </pre>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>ğŸ” åå‘ä¼ æ’­æ¨å¯¼</h4>
                                <p><strong>æ ¸å¿ƒæ€æƒ³ï¼š</strong>ä½¿ç”¨é“¾å¼æ³•åˆ™è®¡ç®—æŸå¤±å‡½æ•°å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦</p>
                                <p><strong>æ¨å¯¼è¿‡ç¨‹ï¼š</strong></p>
                                <p>1. æ ¹æ®é“¾å¼æ³•åˆ™ï¼šâˆ‚L/âˆ‚W^[l] = (âˆ‚L/âˆ‚z^[l]) Ã— (âˆ‚z^[l]/âˆ‚W^[l])</p>
                                <p>2. ç”±äºz^[l] = W^[l]a^[l-1] + b^[l]ï¼Œæ‰€ä»¥âˆ‚z^[l]/âˆ‚W^[l] = a^[l-1]</p>
                                <p>3. å› æ­¤å¾—åˆ°æƒé‡æ¢¯åº¦å…¬å¼</p>
                            </div>
                            \[ \frac{\partial L}{\partial W^{[l]}} = \frac{\partial L}{\partial z^{[l]}} \cdot a^{[l-1]T} \]
                            <div class="formula-explanation">
                                <p><strong>è®¡ç®—ç¤ºä¾‹ï¼š</strong>å‡è®¾âˆ‚L/âˆ‚z^[1] = [[0.1], [0], [0.2], [0.05]]</p>
                                <pre>
âˆ‚L/âˆ‚W^[1] = âˆ‚L/âˆ‚z^[1] Ã— a^[0]^T
          = [[0.1],  Ã— [[100, 1000, 0.6]]
             [0],
             [0.2],
             [0.05]]
          = [[10, 100, 0.06],
             [0, 0, 0],
             [20, 200, 0.12],
             [5, 50, 0.03]]
                                </pre>
                            </div>
                            
                            \[ \frac{\partial L}{\partial b^{[l]}} = \frac{\partial L}{\partial z^{[l]}} \]
                            <div class="formula-explanation">
                                <p><strong>åç½®æ¢¯åº¦ï¼š</strong>ç”±äºz^[l] = W^[l]a^[l-1] + b^[l]ï¼Œâˆ‚z^[l]/âˆ‚b^[l] = 1</p>
                                <p><strong>è®¡ç®—ç¤ºä¾‹ï¼š</strong>âˆ‚L/âˆ‚b^[1] = [[0.1], [0], [0.2], [0.05]]</p>
                            </div>
                            
                            <div class="concept-explanation">
                                <h4>ğŸ” æ¢¯åº¦ä¸‹é™æ›´æ–°</h4>
                                <p><strong>æ›´æ–°åŸç†ï¼š</strong>æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘ç§»åŠ¨ï¼Œå¯»æ‰¾æŸå¤±å‡½æ•°çš„æœ€å°å€¼</p>
                                <p><strong>å­¦ä¹ ç‡é€‰æ‹©ï¼š</strong>å¤ªå¤§å¯èƒ½è·³è¿‡æœ€ä¼˜è§£ï¼Œå¤ªå°æ”¶æ•›å¤ªæ…¢</p>
                            </div>
                            \[ W^{[l]} := W^{[l]} - \alpha \frac{\partial L}{\partial W^{[l]}} \]
                            <div class="formula-explanation">
                                <p><strong>å‚æ•°æ›´æ–°ç¤ºä¾‹ï¼š</strong>å‡è®¾å­¦ä¹ ç‡Î± = 0.01</p>
                                <pre>
W^[1]_new = W^[1]_old - 0.01 Ã— âˆ‚L/âˆ‚W^[1]
          = [[0.2, 0.3, -0.1],     [[10, 100, 0.06],
             [0.1, -0.2, 0.4],  - 0.01 Ã— [0, 0, 0],
             [-0.3, 0.5, 0.2],       [20, 200, 0.12],
             [0.4, 0.1, -0.2]]       [5, 50, 0.03]]
          = [[0.1, -0.7, -0.1006],
             [0.1, -0.2, 0.4],
             [-0.5, -1.5, 0.0788],
             [0.35, -0.4, -0.2003]]
                                </pre>
                                <p><strong>æ”¶æ•›åˆ¤æ–­ï¼š</strong>å½“æ¢¯åº¦æ¥è¿‘é›¶æˆ–æŸå¤±å‡½æ•°å˜åŒ–å¾ˆå°æ—¶åœæ­¢è®­ç»ƒ</p>
                            </div>
                        
<div class="row">
                            <div class="col-md-6">
                                <h5>æ·±åº¦å­¦ä¹ åœ¨é‡‘èä¸­çš„ä¼˜åŠ¿</h5>
                                <ul>
                                    <li>è‡ªåŠ¨ç‰¹å¾æå–</li>
                                    <li>å¤„ç†éçº¿æ€§å…³ç³»</li>
                                    <li>é€‚åº”å¤§è§„æ¨¡æ•°æ®</li>
                                    <li>ç«¯åˆ°ç«¯å­¦ä¹ </li>
                                    <li>å®æ—¶é¢„æµ‹èƒ½åŠ›</li>
                                </ul>
                            
<div class="col-md-6">
                                <h5>ä¸»è¦åº”ç”¨åœºæ™¯</h5>
                                <ul>
                                    <li>è‚¡ä»·é¢„æµ‹ä¸è¶‹åŠ¿åˆ†æ</li>
                                    <li>ä¿¡ç”¨é£é™©è¯„ä¼°</li>
                                    <li>é«˜é¢‘äº¤æ˜“ç­–ç•¥</li>
                                    <li>æ¬ºè¯ˆæ£€æµ‹</li>
                                    <li>æŠ•èµ„ç»„åˆä¼˜åŒ–</li>
                                </ul>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- ç¥ç»ç½‘ç»œåŸºç¡€ -->
                    <section id="neural-networks" class="content-section mb-5">
                        <h2>ğŸ”— ç¥ç»ç½‘ç»œåŸºç¡€</h2>
                        <div class="model-card">
                            <h4>å¤šå±‚æ„ŸçŸ¥æœº (MLP) <span class="badge bg-info complexity-badge">æ—¶é—´å¤æ‚åº¦: O(nÂ·mÂ·hÂ·e)</span></h4>
                            <div class="concept-explanation">
                                <h4>ğŸ’¡ ä¸ºä»€ä¹ˆéœ€è¦æ¿€æ´»å‡½æ•°å’ŒæŸå¤±å‡½æ•°ï¼Ÿ</h4>
                                <p>æ¿€æ´»å‡½æ•°æ˜¯ç¥ç»ç½‘ç»œçš„"å¼€å…³"ï¼Œå†³å®šç¥ç»å…ƒæ˜¯å¦è¢«æ¿€æ´»ã€‚åœ¨é‡‘èå»ºæ¨¡ä¸­ï¼Œå¸‚åœºååº”å¾€å¾€æ˜¯éçº¿æ€§çš„â€”â€”å°çš„å˜åŒ–å¯èƒ½å¼•èµ·å¤§çš„æ³¢åŠ¨ï¼Œæˆ–è€…åœ¨æŸä¸ªé˜ˆå€¼ä¹‹å‰æ¯«æ— ååº”ã€‚</p>
                                <p><strong>æ¿€æ´»å‡½æ•°é€‰æ‹©ï¼š</strong>ReLUé€‚åˆæ·±å±‚ç½‘ç»œï¼ˆé¿å…æ¢¯åº¦æ¶ˆå¤±ï¼‰ï¼ŒSigmoidé€‚åˆæ¦‚ç‡è¾“å‡ºï¼ˆå¦‚æ¶¨è·Œæ¦‚ç‡ï¼‰ï¼ŒTanhé€‚åˆéœ€è¦è´Ÿå€¼çš„åœºæ™¯ã€‚</p>
                                <p><strong>æŸå¤±å‡½æ•°ä½œç”¨ï¼š</strong>è¡¡é‡é¢„æµ‹ä¸å®é™…çš„å·®è·ï¼ŒæŒ‡å¯¼æ¨¡å‹å­¦ä¹ æ–¹å‘ã€‚MSEé€‚åˆå›å½’ä»»åŠ¡ï¼ˆå¦‚ä»·æ ¼é¢„æµ‹ï¼‰ï¼Œäº¤å‰ç†µé€‚åˆåˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚æ¶¨è·Œåˆ¤æ–­ï¼‰ã€‚</p>
                            </div>
                            <div class="math-formula">
                                <h5>æ•°å­¦åŸç†</h5>
                                <p><strong>æ¿€æ´»å‡½æ•°ï¼š</strong></p>
                                \[ \text{ReLU}(x) = \max(0, x) \]
                                <p class="formula-explanation">ä¿®æ­£çº¿æ€§å•å…ƒï¼šä¿ç•™æ­£å€¼ï¼ŒæŠ‘åˆ¶è´Ÿå€¼ï¼Œè®¡ç®—ç®€å•ä¸”æœ‰æ•ˆé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±</p>
                                \[ \text{Sigmoid}(x) = \frac{1}{1 + e^{-x}} \]
                                <p class="formula-explanation">Så‹å‡½æ•°ï¼šè¾“å‡ºèŒƒå›´[0,1]ï¼Œé€‚åˆæ¦‚ç‡é¢„æµ‹ï¼Œå¦‚è‚¡ç¥¨ä¸Šæ¶¨æ¦‚ç‡</p>
                                \[ \text{Tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \]
                                <p class="formula-explanation">åŒæ›²æ­£åˆ‡ï¼šè¾“å‡ºèŒƒå›´[-1,1]ï¼Œé›¶ä¸­å¿ƒåŒ–ï¼Œæ”¶æ•›æ›´å¿«</p>
                                <p><strong>æŸå¤±å‡½æ•°ï¼š</strong></p>
                                \[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \]
                                <p class="formula-explanation">å‡æ–¹è¯¯å·®ï¼šè¡¡é‡é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¹³æ–¹å·®ï¼Œé€‚åˆå›å½’ä»»åŠ¡å¦‚è‚¡ä»·é¢„æµ‹</p>
                                \[ \text{Cross-Entropy} = -\sum_{i=1}^{n} y_i \log(\hat{y}_i) \]
                                <p class="formula-explanation">äº¤å‰ç†µï¼šè¡¡é‡æ¦‚ç‡åˆ†å¸ƒå·®å¼‚ï¼Œé€‚åˆåˆ†ç±»ä»»åŠ¡å¦‚æ¶¨è·Œæ–¹å‘é¢„æµ‹</p>
                            
<div class="neural-network-viz" id="mlp-visualization">
                                <h6>MLPç½‘ç»œç»“æ„å¯è§†åŒ–</h6>
                                <!-- è¿™é‡Œå°†é€šè¿‡JavaScriptåŠ¨æ€ç”Ÿæˆç½‘ç»œå›¾ -->
                            
<div class="code-example">
                                <h6>è‚¡ä»·é¢„æµ‹MLPå®ç°</h6>
                                <pre><code class="language-python">
import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
class StockPriceMLP:
    """
    è‚¡ä»·é¢„æµ‹å¤šå±‚æ„ŸçŸ¥æœº
    æ—¶é—´å¤æ‚åº¦: O(nÂ·mÂ·hÂ·e) - n:æ ·æœ¬æ•°, m:ç‰¹å¾æ•°, h:éšè—å±‚ç¥ç»å…ƒæ•°, e:è®­ç»ƒè½®æ•°
    ç©ºé—´å¤æ‚åº¦: O(mÂ·h + hÂ·o) - o:è¾“å‡ºå±‚ç¥ç»å…ƒæ•°
    """
    def __init__(self, input_dim, hidden_layers=[64, 32], dropout_rate=0.2):
        self.input_dim = input_dim
        self.hidden_layers = hidden_layers
        self.dropout_rate = dropout_rate
        self.model = None
        self.scaler = MinMaxScaler()
    def build_model(self):
        """æ„å»ºMLPæ¨¡å‹"""
        model = tf.keras.Sequential()
        # è¾“å…¥å±‚
        model.add(tf.keras.layers.Dense(
            self.hidden_layers[0],
            input_dim=self.input_dim,
            activation='relu',
            kernel_regularizer=tf.keras.regularizers.l2(0.001)
        ))
        model.add(tf.keras.layers.Dropout(self.dropout_rate))
        # éšè—å±‚
        for units in self.hidden_layers[1:]:
            model.add(tf.keras.layers.Dense(
                units,
                activation='relu',
                kernel_regularizer=tf.keras.regularizers.l2(0.001)
            ))
            model.add(tf.keras.layers.Dropout(self.dropout_rate))
        # è¾“å‡ºå±‚
        model.add(tf.keras.layers.Dense(1, activation='linear'))
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
    def prepare_data(self, data, target_col='close', lookback=30):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # ç‰¹å¾å·¥ç¨‹
        features = self.create_features(data)
        # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
        X, y = [], []
        for i in range(lookback, len(features)):
            X.append(features.iloc[i-lookback:i].values.flatten())
            y.append(data[target_col].iloc[i])
        X = np.array(X)
        y = np.array(y)
        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        return X_scaled, y
    def create_features(self, data):
        """åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾"""
        df = data.copy()
        # ä»·æ ¼ç‰¹å¾
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        # ç§»åŠ¨å¹³å‡
        for period in [5, 10, 20, 50]:
            df[f'sma_{period}'] = df['close'].rolling(period).mean()
            df[f'ema_{period}'] = df['close'].ewm(span=period).mean()
        # æŠ€æœ¯æŒ‡æ ‡
        df['rsi'] = self.calculate_rsi(df['close'])
        df['macd'], df['macd_signal'] = self.calculate_macd(df['close'])
        df['bb_upper'], df['bb_lower'] = self.calculate_bollinger_bands(df['close'])
        # æ³¢åŠ¨ç‡ç‰¹å¾
        df['volatility'] = df['returns'].rolling(20).std()
        df['volume_sma'] = df['volume'].rolling(20).mean()
        return df.dropna()
    def calculate_rsi(self, prices, period=14):
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    def calculate_macd(self, prices, fast=12, slow=26, signal=9):
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal
    def calculate_bollinger_bands(self, prices, period=20, std_dev=2):
        """è®¡ç®—å¸ƒæ—å¸¦"""
        sma = prices.rolling(period).mean()
        std = prices.rolling(period).std()
        upper = sma + (std * std_dev)
        lower = sma - (std * std_dev)
        return upper, lower
    def train(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):
        """è®­ç»ƒæ¨¡å‹"""
        if self.model is None:
            self.build_model()
        # å›è°ƒå‡½æ•°
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss', patience=10, restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6
            )
        ]
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        return history
    def predict(self, X):
        """é¢„æµ‹"""
        return self.model.predict(X)
    def evaluate_model(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        y_pred = self.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        # æ–¹å‘å‡†ç¡®ç‡
        direction_accuracy = self.calculate_direction_accuracy(y_test, y_pred)
        return {
            'MSE': mse,
            'MAE': mae,
            'RMSE': rmse,
            'Direction_Accuracy': direction_accuracy
        }
    def calculate_direction_accuracy(self, y_true, y_pred):
        """è®¡ç®—æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡"""
        true_direction = np.diff(y_true) > 0
        pred_direction = np.diff(y_pred.flatten()) > 0
        return np.mean(true_direction == pred_direction)
# ä½¿ç”¨ç¤ºä¾‹
def demo_mlp_stock_prediction():
    """MLPè‚¡ä»·é¢„æµ‹æ¼”ç¤º"""
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    # æ¨¡æ‹Ÿè‚¡ä»·æ•°æ®
    price = 100
    prices = [price]
    volumes = []
    for i in range(999):
        # éšæœºæ¸¸èµ° + è¶‹åŠ¿
        change = np.random.normal(0, 0.02) + 0.0001 * np.sin(i * 0.01)
        price *= (1 + change)
        prices.append(price)
        volumes.append(np.random.randint(1000000, 5000000))
    data = pd.DataFrame({
        'date': dates,
        'close': prices,
        'volume': volumes + [volumes[-1]]
    })
    # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
    mlp = StockPriceMLP(input_dim=200)  # å‡è®¾200ä¸ªç‰¹å¾
    # å‡†å¤‡æ•°æ®
    X, y = mlp.prepare_data(data)
    # åˆ†å‰²æ•°æ®
    train_size = int(0.7 * len(X))
    val_size = int(0.15 * len(X))
    X_train, y_train = X[:train_size], y[:train_size]
    X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]
    X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]
    # è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹è®­ç»ƒMLPæ¨¡å‹...")
    history = mlp.train(X_train, y_train, X_val, y_val, epochs=50)
    # è¯„ä¼°æ¨¡å‹
    metrics = mlp.evaluate_model(X_test, y_test)
    print("\nMLPæ¨¡å‹æ€§èƒ½:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.4f}")
    return mlp, history, metrics
# è¿è¡Œæ¼”ç¤º
if __name__ == "__main__":
    mlp_model, training_history, performance_metrics = demo_mlp_stock_prediction()
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- LSTMæ—¶é—´åºåˆ—é¢„æµ‹ -->
                    <section id="lstm-models" class="content-section mb-5">
                        <h2>ğŸ”„ LSTMæ—¶é—´åºåˆ—é¢„æµ‹</h2>
                        <div class="model-card">
                            <h4>é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM) <span class="badge bg-success complexity-badge">æ—¶é—´å¤æ‚åº¦: O(TÂ·hÂ²)</span></h4>
                            <div class="concept-explanation">
                                <h4>ğŸ’¡ ä¸ºä»€ä¹ˆLSTMèƒ½è§£å†³é•¿æœŸä¾èµ–é—®é¢˜ï¼Ÿ</h4>
                                <p>ä¼ ç»ŸRNNå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæ— æ³•å­¦ä¹ é•¿æœŸä¾èµ–å…³ç³»ã€‚LSTMé€šè¿‡å¼•å…¥é—¨æ§æœºåˆ¶å’Œç»†èƒçŠ¶æ€ï¼Œèƒ½å¤Ÿé€‰æ‹©æ€§åœ°è®°ä½å’Œé—å¿˜ä¿¡æ¯ã€‚</p>
                                <p><strong>é‡‘èåº”ç”¨åœºæ™¯ï¼š</strong>è‚¡ä»·ä¸ä»…å—è¿‘æœŸæ¶ˆæ¯å½±å“ï¼Œä¹Ÿå—é•¿æœŸè¶‹åŠ¿ã€å­£èŠ‚æ€§å› ç´ å½±å“ã€‚LSTMèƒ½å¤ŸåŒæ—¶æ•æ‰çŸ­æœŸæ³¢åŠ¨å’Œé•¿æœŸè¶‹åŠ¿ã€‚</p>
                                <p><strong>é—¨æ§æœºåˆ¶ç±»æ¯”ï¼š</strong>å°±åƒæŠ•èµ„å†³ç­–ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦å†³å®šå“ªäº›å†å²ä¿¡æ¯è¦è®°ä½ï¼ˆè¾“å…¥é—¨ï¼‰ï¼Œå“ªäº›è¦å¿˜è®°ï¼ˆé—å¿˜é—¨ï¼‰ï¼Œä»¥åŠå¦‚ä½•è¾“å‡ºå½“å‰åˆ¤æ–­ï¼ˆè¾“å‡ºé—¨ï¼‰ã€‚</p>
                            </div>
                            
                            <div class="math-formula">
                                <h5>LSTMæ ¸å¿ƒå…¬å¼æ¨å¯¼</h5>
                                
                                <div class="concept-explanation">
                                    <h4>ğŸ” é—å¿˜é—¨æ¨å¯¼</h4>
                                    <p><strong>ä½œç”¨ï¼š</strong>å†³å®šä»ç»†èƒçŠ¶æ€ä¸­ä¸¢å¼ƒä»€ä¹ˆä¿¡æ¯</p>
                                    <p><strong>è¾“å…¥ï¼š</strong>å‰ä¸€æ—¶åˆ»éšè—çŠ¶æ€h_{t-1}å’Œå½“å‰è¾“å…¥x_t</p>
                                    <p><strong>è¾“å‡ºï¼š</strong>0åˆ°1ä¹‹é—´çš„æ•°å€¼ï¼Œ0è¡¨ç¤ºå®Œå…¨é—å¿˜ï¼Œ1è¡¨ç¤ºå®Œå…¨ä¿ç•™</p>
                                </div>
                                \[ f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \]
                                <div class="formula-explanation">
                                    <p><strong>è®¡ç®—ç¤ºä¾‹ï¼š</strong>å‡è®¾éšè—çŠ¶æ€ç»´åº¦=2ï¼Œè¾“å…¥ç»´åº¦=3</p>
                                    <pre>
h_{t-1} = [0.5, 0.3]    x_t = [100, 1000, 0.6]  (ä»·æ ¼ã€æˆäº¤é‡ã€æŠ€æœ¯æŒ‡æ ‡)
[h_{t-1}, x_t] = [0.5, 0.3, 100, 1000, 0.6]  # æ‹¼æ¥

W_f = [[0.1, 0.2, 0.01, 0.001, 0.5],    b_f = [0.1,
       [0.3, 0.1, 0.02, 0.002, 0.3]]            0.2]

f_t = Ïƒ(W_f Ã— [h_{t-1}, x_t] + b_f)
    = Ïƒ([[0.1Ã—0.5 + 0.2Ã—0.3 + 0.01Ã—100 + 0.001Ã—1000 + 0.5Ã—0.6 + 0.1],
         [0.3Ã—0.5 + 0.1Ã—0.3 + 0.02Ã—100 + 0.002Ã—1000 + 0.3Ã—0.6 + 0.2]])
    = Ïƒ([2.41, 4.58]) = [0.92, 0.99]  # å¤§éƒ¨åˆ†ä¿¡æ¯ä¿ç•™
                                    </pre>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h4>ğŸ” è¾“å…¥é—¨æ¨å¯¼</h4>
                                    <p><strong>ä½œç”¨ï¼š</strong>å†³å®šåœ¨ç»†èƒçŠ¶æ€ä¸­å­˜å‚¨ä»€ä¹ˆæ–°ä¿¡æ¯</p>
                                    <p><strong>ä¸¤æ­¥è¿‡ç¨‹ï¼š</strong>1) å†³å®šæ›´æ–°å“ªäº›å€¼ 2) åˆ›å»ºå€™é€‰å€¼</p>
                                </div>
                                \[ i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \]
                                <div class="formula-explanation">
                                    <p><strong>è¾“å…¥é—¨è®¡ç®—ï¼š</strong>å†³å®šå“ªäº›æ–°ä¿¡æ¯éœ€è¦å­˜å‚¨</p>
                                    <pre>
i_t = Ïƒ(W_i Ã— [h_{t-1}, x_t] + b_i) = [0.7, 0.8]  # å¤§éƒ¨åˆ†æ–°ä¿¡æ¯è¢«æ¥å—
                                    </pre>
                                </div>
                                
                                \[ \tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C) \]
                                <div class="formula-explanation">
                                    <p><strong>å€™é€‰å€¼è®¡ç®—ï¼š</strong>åˆ›å»ºå¯èƒ½æ·»åŠ åˆ°ç»†èƒçŠ¶æ€çš„æ–°å€™é€‰å€¼</p>
                                    <pre>
CÌƒ_t = tanh(W_C Ã— [h_{t-1}, x_t] + b_C) = [0.6, -0.4]  # å€™é€‰æ›´æ–°å€¼
                                    </pre>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h4>ğŸ” ç»†èƒçŠ¶æ€æ›´æ–°æ¨å¯¼</h4>
                                    <p><strong>æ ¸å¿ƒæ€æƒ³ï¼š</strong>ç»“åˆé—å¿˜é—¨å’Œè¾“å…¥é—¨çš„ç»“æœæ›´æ–°ç»†èƒçŠ¶æ€</p>
                                    <p><strong>æ›´æ–°è§„åˆ™ï¼š</strong>æ—§ä¿¡æ¯ Ã— é—å¿˜é—¨ + æ–°ä¿¡æ¯ Ã— è¾“å…¥é—¨</p>
                                </div>
                                \[ C_t = f_t * C_{t-1} + i_t * \tilde{C}_t \]
                                <div class="formula-explanation">
                                    <p><strong>è®¡ç®—ç¤ºä¾‹ï¼š</strong></p>
                                    <pre>
C_{t-1} = [0.8, 0.5]  # å‰ä¸€æ—¶åˆ»çš„ç»†èƒçŠ¶æ€

C_t = f_t âŠ™ C_{t-1} + i_t âŠ™ CÌƒ_t  # âŠ™è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•
    = [0.92, 0.99] âŠ™ [0.8, 0.5] + [0.7, 0.8] âŠ™ [0.6, -0.4]
    = [0.736, 0.495] + [0.42, -0.32]
    = [1.156, 0.175]

# è§£é‡Šï¼šç¬¬ä¸€ä¸ªç»´åº¦ä¿¡æ¯å¢å¼ºï¼Œç¬¬äºŒä¸ªç»´åº¦ä¿¡æ¯å‡å¼±
                                    </pre>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h4>ğŸ” è¾“å‡ºé—¨æ¨å¯¼</h4>
                                    <p><strong>ä½œç”¨ï¼š</strong>å†³å®šç»†èƒçŠ¶æ€çš„å“ªäº›éƒ¨åˆ†å°†è¾“å‡º</p>
                                    <p><strong>ä¸¤æ­¥è¿‡ç¨‹ï¼š</strong>1) å†³å®šè¾“å‡ºå“ªäº›éƒ¨åˆ† 2) å¯¹ç»†èƒçŠ¶æ€è¿›è¡Œtanhå¤„ç†</p>
                                </div>
                                \[ o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \]
                                <div class="formula-explanation">
                                    <p><strong>è¾“å‡ºé—¨è®¡ç®—ï¼š</strong></p>
                                    <pre>
o_t = Ïƒ(W_o Ã— [h_{t-1}, x_t] + b_o) = [0.85, 0.75]  # è¾“å‡ºæ§åˆ¶
                                    </pre>
                                </div>
                                
                                \[ h_t = o_t * \tanh(C_t) \]
                                <div class="formula-explanation">
                                    <p><strong>éšè—çŠ¶æ€è®¡ç®—ï¼š</strong></p>
                                    <pre>
h_t = o_t âŠ™ tanh(C_t)
    = [0.85, 0.75] âŠ™ tanh([1.156, 0.175])
    = [0.85, 0.75] âŠ™ [0.82, 0.17]
    = [0.697, 0.128]

# æœ€ç»ˆè¾“å‡ºï¼šh_tå¯ç”¨äºä¸‹ä¸€æ—¶åˆ»è®¡ç®—æˆ–ä½œä¸ºå½“å‰æ—¶åˆ»çš„é¢„æµ‹åŸºç¡€
                                    </pre>
                                </div>
                            </div>
                            
<div class="code-example">
                                <h6>å¤šå˜é‡æ—¶é—´åºåˆ—LSTMé¢„æµ‹</h6>
                                <pre><code class="language-python">
class MultivariateLSTM:
    """
    å¤šå˜é‡æ—¶é—´åºåˆ—LSTMé¢„æµ‹æ¨¡å‹
    æ—¶é—´å¤æ‚åº¦: O(TÂ·hÂ²Â·L) - T:åºåˆ—é•¿åº¦, h:éšè—å•å…ƒæ•°, L:å±‚æ•°
    ç©ºé—´å¤æ‚åº¦: O(hÂ·L + TÂ·h)
    """
    def __init__(self, n_features, sequence_length=60, lstm_units=[50, 50]):
        self.n_features = n_features
        self.sequence_length = sequence_length
        self.lstm_units = lstm_units
        self.model = None
        self.scalers = {}
    def build_model(self, dropout_rate=0.2):
        """æ„å»ºå¤šå±‚LSTMæ¨¡å‹"""
        model = tf.keras.Sequential()
        # ç¬¬ä¸€å±‚LSTM
        model.add(tf.keras.layers.LSTM(
            self.lstm_units[0],
            return_sequences=len(self.lstm_units) > 1,
            input_shape=(self.sequence_length, self.n_features),
            dropout=dropout_rate,
            recurrent_dropout=dropout_rate
        ))
        # é¢å¤–çš„LSTMå±‚
        for i, units in enumerate(self.lstm_units[1:]):
            return_seq = i < len(self.lstm_units) - 2
            model.add(tf.keras.layers.LSTM(
                units,
                return_sequences=return_seq,
                dropout=dropout_rate,
                recurrent_dropout=dropout_rate
            ))
        # å…¨è¿æ¥å±‚
        model.add(tf.keras.layers.Dense(25, activation='relu'))
        model.add(tf.keras.layers.Dropout(dropout_rate))
        model.add(tf.keras.layers.Dense(1))
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
    def prepare_sequences(self, data, target_column):
        """å‡†å¤‡LSTMåºåˆ—æ•°æ®"""
        # æ•°æ®æ ‡å‡†åŒ–
        scaled_data = {}
        for column in data.columns:
            scaler = MinMaxScaler()
            scaled_data[column] = scaler.fit_transform(
                data[column].values.reshape(-1, 1)
            ).flatten()
            self.scalers[column] = scaler
        scaled_df = pd.DataFrame(scaled_data)
        # åˆ›å»ºåºåˆ—
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_df)):
            X.append(scaled_df.iloc[i-self.sequence_length:i].values)
            y.append(scaled_df[target_column].iloc[i])
        return np.array(X), np.array(y)
    def train_with_attention(self, X_train, y_train, X_val, y_val, epochs=100):
        """å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„è®­ç»ƒ"""
        # æ„å»ºå¸¦æ³¨æ„åŠ›çš„æ¨¡å‹
        inputs = tf.keras.layers.Input(shape=(self.sequence_length, self.n_features))
        # LSTMå±‚
        lstm_out = tf.keras.layers.LSTM(
            self.lstm_units[0],
            return_sequences=True,
            dropout=0.2
        )(inputs)
        # æ³¨æ„åŠ›æœºåˆ¶
        attention = tf.keras.layers.Dense(1, activation='tanh')(lstm_out)
        attention = tf.keras.layers.Flatten()(attention)
        attention = tf.keras.layers.Activation('softmax')(attention)
        attention = tf.keras.layers.RepeatVector(self.lstm_units[0])(attention)
        attention = tf.keras.layers.Permute([2, 1])(attention)
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        sent_representation = tf.keras.layers.Multiply()([lstm_out, attention])
        sent_representation = tf.keras.layers.Lambda(
            lambda xin: tf.keras.backend.sum(xin, axis=1)
        )(sent_representation)
        # è¾“å‡ºå±‚
        outputs = tf.keras.layers.Dense(1)(sent_representation)
        model = tf.keras.Model(inputs=inputs, outputs=outputs)
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        # è®­ç»ƒ
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=32,
            verbose=1
        )
        self.model = model
        return history
    def predict_future(self, last_sequence, n_steps=30):
        """é¢„æµ‹æœªæ¥å¤šæ­¥"""
        predictions = []
        current_sequence = last_sequence.copy()
        for _ in range(n_steps):
            # é¢„æµ‹ä¸‹ä¸€æ­¥
            next_pred = self.model.predict(
                current_sequence.reshape(1, self.sequence_length, self.n_features)
            )[0, 0]
            predictions.append(next_pred)
            # æ›´æ–°åºåˆ—ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„ç‰¹å¾æ›´æ–°ï¼‰
            new_row = current_sequence[-1].copy()
            new_row[0] = next_pred  # å‡è®¾ç¬¬ä¸€ä¸ªç‰¹å¾æ˜¯ç›®æ ‡å˜é‡
            current_sequence = np.vstack([current_sequence[1:], new_row])
        return np.array(predictions)
    def calculate_volatility_forecast(self, predictions):
        """è®¡ç®—æ³¢åŠ¨ç‡é¢„æµ‹"""
        returns = np.diff(predictions) / predictions[:-1]
        volatility = np.std(returns) * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
        return volatility
# LSTMå˜ä½“ï¼šGRUæ¨¡å‹
class GRUModel:
    """
    é—¨æ§å¾ªç¯å•å…ƒ(GRU)æ¨¡å‹
    æ—¶é—´å¤æ‚åº¦: O(TÂ·hÂ²) - æ¯”LSTMç¨å¿«
    ç©ºé—´å¤æ‚åº¦: O(hÂ·L)
    """
    def __init__(self, n_features, sequence_length=60):
        self.n_features = n_features
        self.sequence_length = sequence_length
        self.model = None
    def build_model(self, gru_units=50):
        """æ„å»ºGRUæ¨¡å‹"""
        model = tf.keras.Sequential([
            tf.keras.layers.GRU(
                gru_units,
                return_sequences=True,
                input_shape=(self.sequence_length, self.n_features)
            ),
            tf.keras.layers.GRU(gru_units//2),
            tf.keras.layers.Dense(25, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
# åŒå‘LSTMæ¨¡å‹
class BidirectionalLSTM:
    """
    åŒå‘LSTMæ¨¡å‹
    æ—¶é—´å¤æ‚åº¦: O(2Â·TÂ·hÂ²) - åŒå€äºå•å‘LSTM
    ç©ºé—´å¤æ‚åº¦: O(2Â·hÂ·L)
    """
    def build_model(self, n_features, sequence_length, lstm_units=50):
        """æ„å»ºåŒå‘LSTMæ¨¡å‹"""
        model = tf.keras.Sequential([
            tf.keras.layers.Bidirectional(
                tf.keras.layers.LSTM(
                    lstm_units,
                    return_sequences=True
                ),
                input_shape=(sequence_length, n_features)
            ),
            tf.keras.layers.Bidirectional(
                tf.keras.layers.LSTM(lstm_units//2)
            ),
            tf.keras.layers.Dense(25, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        return model
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- CNNæ¨¡å‹ -->
                    <section id="cnn-models" class="content-section mb-5">
                        <h2>ğŸ–¼ï¸ CNNå›¾åƒè¯†åˆ«åœ¨é‡‘èä¸­çš„åº”ç”¨</h2>
                        <div class="model-card">
                            <h4>å·ç§¯ç¥ç»ç½‘ç»œ (CNN) <span class="badge bg-warning complexity-badge">æ—¶é—´å¤æ‚åº¦: O(KÂ²Â·CÂ·HÂ·WÂ·F)</span></h4>
                            <div class="math-formula">
                                <h5>CNNæ•°å­¦åŸç†</h5>
                                <p><strong>å·ç§¯æ“ä½œï¼š</strong></p>
                                \[ (f * g)(t) = \sum_{m=-\infty}^{\infty} f(m) \cdot g(t-m) \]
                                <p><strong>ç‰¹å¾å›¾è®¡ç®—ï¼š</strong></p>
                                \[ Y_{i,j} = \sum_{m=0}^{K-1} \sum_{n=0}^{K-1} X_{i+m,j+n} \cdot W_{m,n} + b \]
                                <p><strong>æ± åŒ–æ“ä½œï¼š</strong></p>
                                \[ \text{MaxPool}(X) = \max_{i,j \in \text{window}} X_{i,j} \]
                                \[ \text{AvgPool}(X) = \frac{1}{|\text{window}|} \sum_{i,j \in \text{window}} X_{i,j} \]
                            
<div class="code-example">
                                <h6>é‡‘èå›¾è¡¨æ¨¡å¼è¯†åˆ«CNN</h6>
                                <pre><code class="language-python">
class FinancialChartCNN:
    """
    é‡‘èå›¾è¡¨æ¨¡å¼è¯†åˆ«CNNæ¨¡å‹
    ç”¨äºè¯†åˆ«Kçº¿å›¾ä¸­çš„æŠ€æœ¯åˆ†ææ¨¡å¼
    æ—¶é—´å¤æ‚åº¦: O(KÂ²Â·CÂ·HÂ·WÂ·F) - K:å·ç§¯æ ¸å¤§å°, C:é€šé“æ•°, H,W:å›¾åƒå°ºå¯¸, F:æ»¤æ³¢å™¨æ•°
    ç©ºé—´å¤æ‚åº¦: O(HÂ·WÂ·C + FÂ·KÂ²Â·C)
    """
    def __init__(self, input_shape=(64, 64, 3), num_classes=10):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
    def build_model(self):
        """æ„å»ºCNNæ¨¡å‹ç”¨äºå›¾è¡¨æ¨¡å¼è¯†åˆ«"""
        model = tf.keras.Sequential([
            # ç¬¬ä¸€ä¸ªå·ç§¯å—
            tf.keras.layers.Conv2D(
                32, (3, 3),
                activation='relu',
                input_shape=self.input_shape
            ),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            # ç¬¬äºŒä¸ªå·ç§¯å—
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            # ç¬¬ä¸‰ä¸ªå·ç§¯å—
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Dropout(0.25),
            # å…¨è¿æ¥å±‚
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(self.num_classes, activation='softmax')
        ])
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        self.model = model
        return model
    def generate_candlestick_image(self, ohlc_data, width=64, height=64):
        """å°†OHLCæ•°æ®è½¬æ¢ä¸ºKçº¿å›¾å›¾åƒ"""
        import matplotlib.pyplot as plt
        import matplotlib.patches as patches
        from io import BytesIO
        import PIL.Image as Image
        fig, ax = plt.subplots(figsize=(width/10, height/10))
        ax.set_xlim(0, len(ohlc_data))
        ax.set_ylim(ohlc_data['low'].min() * 0.99, ohlc_data['high'].max() * 1.01)
        for i, (idx, row) in enumerate(ohlc_data.iterrows()):
            # ç»˜åˆ¶Kçº¿
            color = 'red' if row['close'] > row['open'] else 'green'
            # å½±çº¿
            ax.plot([i, i], [row['low'], row['high']], color='black', linewidth=1)
            # å®ä½“
            body_height = abs(row['close'] - row['open'])
            body_bottom = min(row['open'], row['close'])
            rect = patches.Rectangle(
                (i-0.3, body_bottom), 0.6, body_height,
                linewidth=1, edgecolor='black', facecolor=color, alpha=0.8
            )
            ax.add_patch(rect)
        ax.axis('off')
        plt.tight_layout()
        # è½¬æ¢ä¸ºå›¾åƒæ•°ç»„
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=10, bbox_inches='tight', pad_inches=0)
        buf.seek(0)
        img = Image.open(buf)
        img_array = np.array(img.resize((width, height)))
        plt.close()
        return img_array[:, :, :3]  # å»é™¤alphaé€šé“
    def create_pattern_dataset(self, price_data, window_size=20):
        """åˆ›å»ºå›¾è¡¨æ¨¡å¼æ•°æ®é›†"""
        patterns = {
            'head_and_shoulders': 0,
            'double_top': 1,
            'double_bottom': 2,
            'triangle': 3,
            'flag': 4,
            'wedge': 5,
            'channel': 6,
            'support_resistance': 7,
            'breakout': 8,
            'reversal': 9
        }
        X, y = [], []
        for i in range(window_size, len(price_data) - window_size):
            window_data = price_data.iloc[i-window_size:i+window_size]
            # ç”ŸæˆKçº¿å›¾å›¾åƒ
            img = self.generate_candlestick_image(window_data)
            # è¯†åˆ«æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            pattern_label = self.identify_pattern(window_data)
            X.append(img)
            y.append(pattern_label)
        return np.array(X), tf.keras.utils.to_categorical(y, self.num_classes)
    def identify_pattern(self, data):
        """ç®€åŒ–çš„æ¨¡å¼è¯†åˆ«é€»è¾‘"""
        # è¿™é‡Œæ˜¯ç®€åŒ–çš„æ¨¡å¼è¯†åˆ«ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„ç®—æ³•
        high_points = data['high'].rolling(5).max()
        low_points = data['low'].rolling(5).min()
        # ç®€å•çš„æ¨¡å¼è¯†åˆ«è§„åˆ™
        if len(data) > 10:
            recent_trend = data['close'].iloc[-5:].mean() - data['close'].iloc[:5].mean()
            volatility = data['close'].std()
            if recent_trend > volatility:
                return 8  # breakout
            elif recent_trend < -volatility:
                return 9  # reversal
            else:
                return np.random.randint(0, 8)  # å…¶ä»–æ¨¡å¼
        return 0
    def train_with_augmentation(self, X_train, y_train, X_val, y_val, epochs=50):
        """ä½¿ç”¨æ•°æ®å¢å¼ºè®­ç»ƒæ¨¡å‹"""
        # æ•°æ®å¢å¼º
        datagen = tf.keras.preprocessing.image.ImageDataGenerator(
            rotation_range=10,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True,
            zoom_range=0.1,
            fill_mode='nearest'
        )
        # è®­ç»ƒ
        history = self.model.fit(
            datagen.flow(X_train, y_train, batch_size=32),
            validation_data=(X_val, y_val),
            epochs=epochs,
            steps_per_epoch=len(X_train) // 32,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_accuracy', patience=10, restore_best_weights=True
                ),
                tf.keras.callbacks.ReduceLROnPlateau(
                    monitor='val_loss', factor=0.5, patience=5
                )
            ]
        )
        return history
    def predict_pattern(self, ohlc_data):
        """é¢„æµ‹å›¾è¡¨æ¨¡å¼"""
        img = self.generate_candlestick_image(ohlc_data)
        img_normalized = img.astype('float32') / 255.0
        prediction = self.model.predict(np.expand_dims(img_normalized, axis=0))
        pattern_names = [
            'Head and Shoulders', 'Double Top', 'Double Bottom', 'Triangle',
            'Flag', 'Wedge', 'Channel', 'Support/Resistance', 'Breakout', 'Reversal'
        ]
        predicted_class = np.argmax(prediction[0])
        confidence = prediction[0][predicted_class]
        return pattern_names[predicted_class], confidence
# 1D CNNç”¨äºæ—¶é—´åºåˆ—
class TimeSeries1DCNN:
    """
    ä¸€ç»´CNNç”¨äºæ—¶é—´åºåˆ—åˆ†æ
    æ—¶é—´å¤æ‚åº¦: O(TÂ·KÂ·F) - T:åºåˆ—é•¿åº¦, K:å·ç§¯æ ¸å¤§å°, F:æ»¤æ³¢å™¨æ•°
    ç©ºé—´å¤æ‚åº¦: O(TÂ·F)
    """
    def __init__(self, sequence_length, n_features):
        self.sequence_length = sequence_length
        self.n_features = n_features
        self.model = None
    def build_model(self):
        """æ„å»º1D CNNæ¨¡å‹"""
        model = tf.keras.Sequential([
            tf.keras.layers.Conv1D(
                filters=64, kernel_size=3, activation='relu',
                input_shape=(self.sequence_length, self.n_features)
            ),
            tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
            tf.keras.layers.MaxPooling1D(pool_size=2),
            tf.keras.layers.Dropout(0.25),
            tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),
            tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),
            tf.keras.layers.GlobalMaxPooling1D(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(50, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- Transformeræ¨¡å‹ -->
                    <section id="transformer-models" class="content-section mb-5">
                        <h2>ğŸ”„ Transformeræ³¨æ„åŠ›æœºåˆ¶</h2>
                        <div class="model-card">
                            <h4>Transformeræ¨¡å‹ <span class="badge bg-primary complexity-badge">æ—¶é—´å¤æ‚åº¦: O(TÂ²Â·d)</span></h4>
                            <div class="math-formula">
                                <h5>æ³¨æ„åŠ›æœºåˆ¶æ•°å­¦åŸç†</h5>
                                <p><strong>è‡ªæ³¨æ„åŠ›è®¡ç®—ï¼š</strong></p>
                                \[ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \]
                                <p><strong>å¤šå¤´æ³¨æ„åŠ›ï¼š</strong></p>
                                \[ \text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O \]
                                \[ \text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \]
                                <p><strong>ä½ç½®ç¼–ç ï¼š</strong></p>
                                \[ PE_{(pos,2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right) \]
                                \[ PE_{(pos,2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right) \]
                            
<div class="code-example">
                                <h6>é‡‘èæ—¶é—´åºåˆ—Transformer</h6>
                                <pre><code class="language-python">
class FinancialTransformer:
    """
    é‡‘èæ—¶é—´åºåˆ—Transformeræ¨¡å‹
    æ—¶é—´å¤æ‚åº¦: O(TÂ²Â·d + TÂ·dÂ²) - T:åºåˆ—é•¿åº¦, d:æ¨¡å‹ç»´åº¦
    ç©ºé—´å¤æ‚åº¦: O(TÂ²Â·h + TÂ·d) - h:æ³¨æ„åŠ›å¤´æ•°
    """
    def __init__(self, seq_length, d_model=128, num_heads=8, num_layers=6):
        self.seq_length = seq_length
        self.d_model = d_model
        self.num_heads = num_heads
        self.num_layers = num_layers
        self.model = None
    def build_model(self, input_dim):
        """æ„å»ºTransformeræ¨¡å‹"""
        inputs = tf.keras.layers.Input(shape=(self.seq_length, input_dim))
        # è¾“å…¥åµŒå…¥å’Œä½ç½®ç¼–ç 
        x = tf.keras.layers.Dense(self.d_model)(inputs)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        positions = tf.range(start=0, limit=self.seq_length, delta=1)
        positions = tf.expand_dims(positions, 0)
        position_encoding = self.positional_encoding(positions, self.d_model)
        x += position_encoding
        
        # Transformerå±‚
        for _ in range(self.num_layers):
            # å¤šå¤´è‡ªæ³¨æ„åŠ›
            attention_output = tf.keras.layers.MultiHeadAttention(
                num_heads=self.num_heads,
                key_dim=self.d_model // self.num_heads
            )(x, x)
            # æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
            x = tf.keras.layers.LayerNormalization()(x + attention_output)
            # å‰é¦ˆç½‘ç»œ
            ffn_output = tf.keras.layers.Dense(
                self.d_model * 4, activation='relu'
            )(x)
            ffn_output = tf.keras.layers.Dense(self.d_model)(ffn_output)
            # æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
            x = tf.keras.layers.LayerNormalization()(x + ffn_output)
        # å…¨å±€å¹³å‡æ± åŒ–
        x = tf.keras.layers.GlobalAveragePooling1D()(x)
        # è¾“å‡ºå±‚
        outputs = tf.keras.layers.Dense(1)(x)
        model = tf.keras.Model(inputs=inputs, outputs=outputs)
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
            loss='mse',
            metrics=['mae']
        )
        self.model = model
        return model
    
    def positional_encoding(self, position, d_model):
        """ä½ç½®ç¼–ç """
        angle_rads = self.get_angles(tf.range(position, dtype=tf.float32)[:, tf.newaxis],
                                   tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],
                                   d_model)
        # å¯¹å¶æ•°ç´¢å¼•åº”ç”¨sin
        angle_rads = tf.cast(angle_rads, tf.float32)
        sines = tf.math.sin(angle_rads[:, :, 0::2])
        cosines = tf.math.cos(angle_rads[:, :, 1::2])
        pos_encoding = tf.concat([sines, cosines], axis=-1)
        pos_encoding = pos_encoding[tf.newaxis, ...]
        return tf.cast(pos_encoding, tf.float32)
    
    def get_angles(self, pos, i, d_model):
        """è®¡ç®—è§’åº¦"""
        angle_rates = 1 / tf.pow(10000, (2 * (i//2)) / tf.cast(d_model, tf.float32))
        return pos * angle_rates
    
    def train_model(self, X_train, y_train, X_val, y_val, epochs=100):
        """è®­ç»ƒæ¨¡å‹"""
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_loss', patience=10, restore_best_weights=True
        )
        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7
        )
        
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )
        return history
    
    def predict(self, X):
        """é¢„æµ‹"""
        return self.model.predict(X)

# è™šæ‹Ÿæ•°æ®ç”Ÿæˆå‡½æ•°
def generate_financial_data(n_samples=10000, seq_length=60, n_features=5):
    """ç”Ÿæˆè™šæ‹Ÿé‡‘èæ—¶é—´åºåˆ—æ•°æ®"""
    import numpy as np
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    
    # ç”ŸæˆåŸºç¡€ä»·æ ¼åºåˆ—
    base_price = 100
    prices = [base_price]
    
    for i in range(n_samples + seq_length):
        # æ·»åŠ è¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œéšæœºæ³¢åŠ¨
        trend = 0.0001 * i
        seasonal = 0.02 * np.sin(2 * np.pi * i / 252)  # å¹´åº¦å­£èŠ‚æ€§
        noise = np.random.normal(0, 0.02)
        
        # ä»·æ ¼å˜åŒ–
        price_change = trend + seasonal + noise
        new_price = prices[-1] * (1 + price_change)
        prices.append(new_price)
    
    prices = np.array(prices)
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    def calculate_rsi(prices, window=14):
        """è®¡ç®—RSIæŒ‡æ ‡"""
        deltas = np.diff(prices)
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)
        
        avg_gains = np.convolve(gains, np.ones(window)/window, mode='valid')
        avg_losses = np.convolve(losses, np.ones(window)/window, mode='valid')
        
        rs = avg_gains / (avg_losses + 1e-8)
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def calculate_macd(prices, fast=12, slow=26, signal=9):
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = pd.Series(prices).ewm(span=fast).mean()
        ema_slow = pd.Series(prices).ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        signal_line = macd.ewm(span=signal).mean()
        return macd.values, signal_line.values
    
    # åˆ›å»ºç‰¹å¾çŸ©é˜µ
    features = []
    targets = []
    
    for i in range(seq_length, len(prices) - 1):
        # ä»·æ ¼åºåˆ—
        price_seq = prices[i-seq_length:i]
        
        # è®¡ç®—æ”¶ç›Šç‡
        returns = np.diff(price_seq) / price_seq[:-1]
        returns = np.append(returns, 0)  # è¡¥é½é•¿åº¦
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        ma_5 = np.mean(price_seq[-5:])
        ma_20 = np.mean(price_seq[-20:]) if len(price_seq) >= 20 else np.mean(price_seq)
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        volatility = np.std(returns[-20:]) if len(returns) >= 20 else np.std(returns)
        
        # RSI
        if i >= seq_length + 14:
            rsi = calculate_rsi(prices[i-seq_length-14:i])[-1]
        else:
            rsi = 50  # é»˜è®¤å€¼
        
        # ç»„åˆç‰¹å¾
        feature_vector = np.array([
            price_seq[-1],  # å½“å‰ä»·æ ¼
            returns[-1],    # å½“å‰æ”¶ç›Šç‡
            ma_5 / price_seq[-1],  # MA5æ¯”ç‡
            ma_20 / price_seq[-1], # MA20æ¯”ç‡
            volatility,     # æ³¢åŠ¨ç‡
            rsi / 100       # æ ‡å‡†åŒ–RSI
        ])
        
        # åˆ›å»ºåºåˆ—ç‰¹å¾
        seq_features = np.column_stack([
            price_seq,
            np.append(np.diff(price_seq) / price_seq[:-1], 0),
            np.full(seq_length, ma_5 / price_seq[-1]),
            np.full(seq_length, ma_20 / price_seq[-1]),
            np.full(seq_length, volatility)
        ])
        
        features.append(seq_features)
        
        # ç›®æ ‡ï¼šä¸‹ä¸€æœŸæ”¶ç›Šç‡
        next_return = (prices[i+1] - prices[i]) / prices[i]
        targets.append(next_return)
        
        if len(features) >= n_samples:
            break
    
    return np.array(features), np.array(targets)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
    X, y = generate_financial_data(n_samples=5000, seq_length=60, n_features=5)
    
    # æ•°æ®åˆ†å‰²
    train_size = int(0.8 * len(X))
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    # åˆ›å»ºå’Œè®­ç»ƒTransformeræ¨¡å‹
    transformer = FinancialTransformer(seq_length=60, d_model=128, num_heads=8, num_layers=4)
    model = transformer.build_model(input_dim=5)
    
    # è®­ç»ƒæ¨¡å‹
    history = transformer.train_model(X_train, y_train, X_test, y_test, epochs=50)
    
    # é¢„æµ‹
    predictions = transformer.predict(X_test)
    
    # è¯„ä¼°
    mse = np.mean((predictions.flatten() - y_test) ** 2)
    mae = np.mean(np.abs(predictions.flatten() - y_test))
    
    print(f"æµ‹è¯•é›†MSE: {mse:.6f}")
    print(f"æµ‹è¯•é›†MAE: {mae:.6f}")
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- GANæ¨¡å‹ -->
                    <section id="gan-models" class="content-section mb-5">
                        <h2>ğŸ­ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)</h2>
                        <div class="model-card">
                            <h4>é‡‘èæ•°æ®ç”ŸæˆGAN <span class="badge bg-danger complexity-badge">æ—¶é—´å¤æ‚åº¦: O(G + D)</span></h4>
                            <div class="math-formula">
                                <h5>GANæ•°å­¦åŸç†</h5>
                                <p><strong>ç›®æ ‡å‡½æ•°ï¼š</strong></p>
                                \[ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] \]
                                <p><strong>ç”Ÿæˆå™¨æŸå¤±ï¼š</strong></p>
                                \[ L_G = -\mathbb{E}_{z \sim p_z(z)}[\log D(G(z))] \]
                                <p><strong>åˆ¤åˆ«å™¨æŸå¤±ï¼š</strong></p>
                                \[ L_D = -\mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] - \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] \]
                            
<div class="code-example">
                                <h6>è‚¡ä»·æ•°æ®ç”ŸæˆGAN</h6>
                                <pre><code class="language-python">
class FinancialGAN:
    """
    é‡‘èæ—¶é—´åºåˆ—ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
    ç”¨äºç”Ÿæˆåˆæˆçš„è‚¡ä»·æ•°æ®
    æ—¶é—´å¤æ‚åº¦: O(G + D) - G:ç”Ÿæˆå™¨å¤æ‚åº¦, D:åˆ¤åˆ«å™¨å¤æ‚åº¦
    ç©ºé—´å¤æ‚åº¦: O(|Î¸_G| + |Î¸_D|) - æ¨¡å‹å‚æ•°æ•°é‡
    """
    def __init__(self, seq_length=100, latent_dim=100):
        self.seq_length = seq_length
        self.latent_dim = latent_dim
        self.generator = None
        self.discriminator = None
        self.gan = None
    def build_generator(self):
        """æ„å»ºç”Ÿæˆå™¨"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(256, input_dim=self.latent_dim),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(512),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(1024),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(self.seq_length, activation='tanh'),
            tf.keras.layers.Reshape((self.seq_length, 1))
        ])
        self.generator = model
        return model
    
    def build_discriminator(self):
        """æ„å»ºåˆ¤åˆ«å™¨"""
        model = tf.keras.Sequential([
            tf.keras.layers.Flatten(input_shape=(self.seq_length, 1)),
            tf.keras.layers.Dense(1024),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(512),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(256),
            tf.keras.layers.LeakyReLU(alpha=0.2),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        self.discriminator = model
        return model
    
    def build_gan(self):
        """æ„å»ºå®Œæ•´çš„GANæ¨¡å‹"""
        # æ„å»ºç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨
        self.generator = self.build_generator()
        self.discriminator = self.build_discriminator()
        
        # ç¼–è¯‘åˆ¤åˆ«å™¨
        self.discriminator.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        # æ„å»ºGANæ¨¡å‹
        self.discriminator.trainable = False
        gan_input = tf.keras.layers.Input(shape=(self.latent_dim,))
        generated_data = self.generator(gan_input)
        gan_output = self.discriminator(generated_data)
        
        self.gan = tf.keras.Model(gan_input, gan_output)
        self.gan.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
            loss='binary_crossentropy'
        )
        
        return self.gan
    
    def train_gan(self, real_data, epochs=10000, batch_size=32, save_interval=1000):
        """è®­ç»ƒGANæ¨¡å‹"""
        # æ ‡ç­¾
        real_labels = np.ones((batch_size, 1))
        fake_labels = np.zeros((batch_size, 1))
        
        d_losses = []
        g_losses = []
        
        for epoch in range(epochs):
            # è®­ç»ƒåˆ¤åˆ«å™¨
            # çœŸå®æ•°æ®
            idx = np.random.randint(0, real_data.shape[0], batch_size)
            real_batch = real_data[idx]
            
            # ç”Ÿæˆå‡æ•°æ®
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
            fake_batch = self.generator.predict(noise, verbose=0)
            
            # è®­ç»ƒåˆ¤åˆ«å™¨
            d_loss_real = self.discriminator.train_on_batch(real_batch, real_labels)
            d_loss_fake = self.discriminator.train_on_batch(fake_batch, fake_labels)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
            
            # è®­ç»ƒç”Ÿæˆå™¨
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
            g_loss = self.gan.train_on_batch(noise, real_labels)
            
            d_losses.append(d_loss[0])
            g_losses.append(g_loss)
            
            # æ‰“å°è¿›åº¦
            if epoch % save_interval == 0:
                print(f"Epoch {epoch}, D Loss: {d_loss[0]:.4f}, G Loss: {g_loss:.4f}")
        
        return d_losses, g_losses
    
    def generate_samples(self, n_samples):
        """ç”Ÿæˆæ ·æœ¬"""
        noise = np.random.normal(0, 1, (n_samples, self.latent_dim))
        generated_data = self.generator.predict(noise, verbose=0)
        return generated_data

# GANè™šæ‹Ÿæ•°æ®ç”Ÿæˆç¤ºä¾‹
def generate_gan_training_data(n_samples=5000, seq_length=100):
    """ä¸ºGANè®­ç»ƒç”ŸæˆçœŸå®è‚¡ä»·æ•°æ®"""
    import numpy as np
    
    np.random.seed(42)
    
    # ç”Ÿæˆå¤šä¸ªè‚¡ç¥¨çš„ä»·æ ¼åºåˆ—
    all_sequences = []
    
    for stock in range(10):  # ç”Ÿæˆ10åªè‚¡ç¥¨çš„æ•°æ®
        base_price = np.random.uniform(50, 200)
        prices = [base_price]
        
        # è‚¡ç¥¨ç‰¹å®šå‚æ•°
        volatility = np.random.uniform(0.01, 0.05)
        drift = np.random.uniform(-0.001, 0.001)
        
        for i in range(n_samples):
            # å‡ ä½•å¸ƒæœ—è¿åŠ¨
            dt = 1/252  # æ—¥é¢‘æ•°æ®
            dW = np.random.normal(0, np.sqrt(dt))
            
            # ä»·æ ¼å˜åŒ–
            price_change = drift * dt + volatility * dW
            new_price = prices[-1] * np.exp(price_change)
            prices.append(new_price)
        
        # æ ‡å‡†åŒ–ä»·æ ¼åºåˆ—
        prices = np.array(prices)
        normalized_prices = (prices - np.mean(prices)) / np.std(prices)
        
        # åˆ›å»ºåºåˆ—
        for i in range(len(normalized_prices) - seq_length):
            sequence = normalized_prices[i:i+seq_length]
            all_sequences.append(sequence.reshape(-1, 1))
    
    return np.array(all_sequences)

# GANä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    real_data = generate_gan_training_data(n_samples=1000, seq_length=100)
    
    # åˆ›å»ºGANæ¨¡å‹
    gan = FinancialGAN(seq_length=100, latent_dim=100)
    gan.build_gan()
    
    # è®­ç»ƒGAN
    d_losses, g_losses = gan.train_gan(real_data, epochs=5000, batch_size=32)
    
    # ç”Ÿæˆæ–°çš„è‚¡ä»·åºåˆ—
    generated_data = gan.generate_samples(100)
    
    print(f"ç”Ÿæˆäº† {generated_data.shape[0]} ä¸ªé•¿åº¦ä¸º {generated_data.shape[1]} çš„è‚¡ä»·åºåˆ—")
    print(f"åˆ¤åˆ«å™¨æœ€ç»ˆæŸå¤±: {d_losses[-1]:.4f}")
    print(f"ç”Ÿæˆå™¨æœ€ç»ˆæŸå¤±: {g_losses[-1]:.4f}")
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- å¼ºåŒ–å­¦ä¹  -->
                    <section id="reinforcement-learning" class="content-section mb-5">
                        <h2>ğŸ¯ å¼ºåŒ–å­¦ä¹ äº¤æ˜“ç­–ç•¥</h2>
                        <div class="model-card">
                            <h4>æ·±åº¦Qç½‘ç»œ(DQN)äº¤æ˜“ <span class="badge bg-success complexity-badge">æ—¶é—´å¤æ‚åº¦: O(TÂ·A)</span></h4>
                            <div class="math-formula">
                                <h5>å¼ºåŒ–å­¦ä¹ æ•°å­¦åŸç†</h5>
                                <p><strong>Qå‡½æ•°æ›´æ–°ï¼š</strong></p>
                                \[ Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha[r_{t+1} + \gamma \max_a Q(s_{t+1}, a) - Q(s_t, a_t)] \]
                                <p><strong>ç­–ç•¥æ¢¯åº¦ï¼š</strong></p>
                                \[ \nabla_\theta J(\theta) = \mathbb{E}[\nabla_\theta \log \pi_\theta(a|s) \cdot A(s,a)] \]
                                <p><strong>ä¼˜åŠ¿å‡½æ•°ï¼š</strong></p>
                                \[ A(s,a) = Q(s,a) - V(s) \]
                            
<div class="code-example">
                                <h6>DQNäº¤æ˜“æ™ºèƒ½ä½“</h6>
                                <pre><code class="language-python">
class TradingDQN:
    """
    æ·±åº¦Qç½‘ç»œäº¤æ˜“æ™ºèƒ½ä½“
    æ—¶é—´å¤æ‚åº¦: O(TÂ·AÂ·|Î¸|) - T:æ—¶é—´æ­¥, A:åŠ¨ä½œæ•°, |Î¸|:ç½‘ç»œå‚æ•°
    ç©ºé—´å¤æ‚åº¦: O(|Î¸| + |M|) - M:ç»éªŒå›æ”¾ç¼“å†²åŒºå¤§å°
    """
    def __init__(self, state_size, action_size, learning_rate=0.001):
        self.state_size = state_size
        self.action_size = action_size  # 0: hold, 1: buy, 2: sell
        self.memory = []
        self.memory_size = 10000
        self.epsilon = 1.0  # æ¢ç´¢ç‡
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = learning_rate
        self.gamma = 0.95  # æŠ˜æ‰£å› å­
        self.q_network = self.build_model()
        self.target_network = self.build_model()
        self.update_target_network()
        
    def build_model(self):
        """æ„å»ºDQNç½‘ç»œ"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, input_dim=self.state_size, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(self.action_size, activation='linear')
        ])
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),
            loss='mse'
        )
        return model
    
    def update_target_network(self):
        """æ›´æ–°ç›®æ ‡ç½‘ç»œ"""
        self.target_network.set_weights(self.q_network.get_weights())
    
    def remember(self, state, action, reward, next_state, done):
        """å­˜å‚¨ç»éªŒ"""
        self.memory.append((state, action, reward, next_state, done))
        if len(self.memory) > self.memory_size:
            self.memory.pop(0)
    
    def act(self, state):
        """é€‰æ‹©åŠ¨ä½œ"""
        if np.random.random() <= self.epsilon:
            return np.random.choice(self.action_size)
        
        q_values = self.q_network.predict(state.reshape(1, -1), verbose=0)
        return np.argmax(q_values[0])
    
    def replay(self, batch_size=32):
        """ç»éªŒå›æ”¾è®­ç»ƒ"""
        if len(self.memory) < batch_size:
            return
        
        batch = random.sample(self.memory, batch_size)
        states = np.array([e[0] for e in batch])
        actions = np.array([e[1] for e in batch])
        rewards = np.array([e[2] for e in batch])
        next_states = np.array([e[3] for e in batch])
        dones = np.array([e[4] for e in batch])
        
        # è®¡ç®—ç›®æ ‡Qå€¼
        target_q_values = self.target_network.predict(next_states, verbose=0)
        max_target_q_values = np.max(target_q_values, axis=1)
        
        targets = rewards + (self.gamma * max_target_q_values * (1 - dones))
        
        # å½“å‰Qå€¼
        current_q_values = self.q_network.predict(states, verbose=0)
        
        # æ›´æ–°ç›®æ ‡
        for i in range(batch_size):
            current_q_values[i][actions[i]] = targets[i]
        
        # è®­ç»ƒç½‘ç»œ
        self.q_network.fit(states, current_q_values, epochs=1, verbose=0)
        
        # è¡°å‡æ¢ç´¢ç‡
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# äº¤æ˜“ç¯å¢ƒç±»
class TradingEnvironment:
    """è‚¡ç¥¨äº¤æ˜“ç¯å¢ƒ"""
    def __init__(self, data, initial_balance=10000, transaction_cost=0.001):
        self.data = data
        self.initial_balance = initial_balance
        self.transaction_cost = transaction_cost
        self.reset()
    
    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        self.current_step = 0
        self.balance = self.initial_balance
        self.shares_held = 0
        self.net_worth = self.initial_balance
        self.max_net_worth = self.initial_balance
        return self._get_state()
    
    def _get_state(self):
        """è·å–å½“å‰çŠ¶æ€"""
        if self.current_step >= len(self.data) - 1:
            return np.zeros(10)  # è¿”å›é›¶çŠ¶æ€
        
        # æŠ€æœ¯æŒ‡æ ‡çŠ¶æ€
        current_price = self.data.iloc[self.current_step]['close']
        
        # ç®€åŒ–çš„çŠ¶æ€ç‰¹å¾
        state = np.array([
            current_price / 100,  # æ ‡å‡†åŒ–ä»·æ ¼
            self.balance / self.initial_balance,  # ä½™é¢æ¯”ä¾‹
            self.shares_held / 100,  # æŒè‚¡æ•°é‡
            self.net_worth / self.initial_balance,  # å‡€å€¼æ¯”ä¾‹
            # æ·»åŠ æ›´å¤šæŠ€æœ¯æŒ‡æ ‡...
            0, 0, 0, 0, 0, 0  # å ä½ç¬¦
        ])
        return state
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        if self.current_step >= len(self.data) - 1:
            return self._get_state(), 0, True, {}
        
        current_price = self.data.iloc[self.current_step]['close']
        
        # æ‰§è¡ŒåŠ¨ä½œ
        if action == 1:  # ä¹°å…¥
            shares_to_buy = self.balance // (current_price * (1 + self.transaction_cost))
            if shares_to_buy > 0:
                cost = shares_to_buy * current_price * (1 + self.transaction_cost)
                self.balance -= cost
                self.shares_held += shares_to_buy
        
        elif action == 2:  # å–å‡º
            if self.shares_held > 0:
                revenue = self.shares_held * current_price * (1 - self.transaction_cost)
                self.balance += revenue
                self.shares_held = 0
        
        # æ›´æ–°å‡€å€¼
        self.net_worth = self.balance + self.shares_held * current_price
        
        # è®¡ç®—å¥–åŠ±
        reward = (self.net_worth - self.initial_balance) / self.initial_balance
        
        # æ›´æ–°æœ€å¤§å‡€å€¼
        if self.net_worth > self.max_net_worth:
            self.max_net_worth = self.net_worth
        
        self.current_step += 1
        done = self.current_step >= len(self.data) - 1
        
        return self._get_state(), reward, done, {'net_worth': self.net_worth}

# DQNäº¤æ˜“ç¤ºä¾‹
def demo_dqn_trading():
    """DQNäº¤æ˜“æ¼”ç¤º"""
    # ç”Ÿæˆè™šæ‹Ÿè‚¡ä»·æ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    
    price = 100
    prices = []
    for i in range(1000):
        # éšæœºæ¸¸èµ° + è¶‹åŠ¿
        change = np.random.normal(0, 0.02) + 0.0001 * np.sin(i * 0.01)
        price *= (1 + change)
        prices.append(price)
    
    data = pd.DataFrame({
        'date': dates,
        'close': prices
    })
    
    # åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“
    env = TradingEnvironment(data)
    agent = TradingDQN(state_size=10, action_size=3)
    
    # è®­ç»ƒ
    episodes = 100
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        
        while True:
            action = agent.act(state)
            next_state, reward, done, info = env.step(action)
            agent.remember(state, action, reward, next_state, done)
            
            state = next_state
            total_reward += reward
            
            if done:
                break
        
        # ç»éªŒå›æ”¾
        if len(agent.memory) > 32:
            agent.replay()
        
        # æ›´æ–°ç›®æ ‡ç½‘ç»œ
        if episode % 10 == 0:
            agent.update_target_network()
        
        if episode % 20 == 0:
            print(f"Episode {episode}, Total Reward: {total_reward:.4f}, Net Worth: {info.get('net_worth', 0):.2f}")
    
    return agent, env

# è¿è¡ŒDQNäº¤æ˜“æ¼”ç¤º
if __name__ == "__main__":
    import random
    dqn_agent, trading_env = demo_dqn_trading()
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- è‡ªç¼–ç å™¨ -->
                    <section id="autoencoder" class="content-section mb-5">
                        <h2>ğŸ”„ è‡ªç¼–ç å™¨å¼‚å¸¸æ£€æµ‹</h2>
                        <div class="model-card">
                            <h4>å˜åˆ†è‡ªç¼–ç å™¨(VAE) <span class="badge bg-info complexity-badge">æ—¶é—´å¤æ‚åº¦: O(E + D)</span></h4>
                            <div class="math-formula">
                                <h5>VAEæ•°å­¦åŸç†</h5>
                                <p><strong>ELBOæŸå¤±ï¼š</strong></p>
                                \[ \mathcal{L} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z|x) || p(z)) \]
                                <p><strong>é‡å‚æ•°åŒ–æŠ€å·§ï¼š</strong></p>
                                \[ z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I) \]
                                <p><strong>KLæ•£åº¦ï¼š</strong></p>
                                \[ D_{KL} = \frac{1}{2} \sum_{i=1}^{d} (1 + \log(\sigma_i^2) - \mu_i^2 - \sigma_i^2) \]
                            
<div class="code-example">
                                <h6>é‡‘èå¼‚å¸¸æ£€æµ‹VAE</h6>
                                <pre><code class="language-python">
class FinancialVAE:
    """
    é‡‘èæ•°æ®å˜åˆ†è‡ªç¼–ç å™¨
    ç”¨äºå¼‚å¸¸äº¤æ˜“æ£€æµ‹å’Œæ•°æ®é™ç»´
    æ—¶é—´å¤æ‚åº¦: O(E + D) - E:ç¼–ç å™¨, D:è§£ç å™¨
    ç©ºé—´å¤æ‚åº¦: O(|Î¸_E| + |Î¸_D| + d) - d:æ½œåœ¨ç©ºé—´ç»´åº¦
    """
    def __init__(self, input_dim, latent_dim=20):
        self.input_dim = input_dim
        self.latent_dim = latent_dim
        self.encoder = None
        self.decoder = None
        self.vae = None
    def build_encoder(self):
        """æ„å»ºç¼–ç å™¨"""
        inputs = tf.keras.layers.Input(shape=(self.input_dim,))
        x = tf.keras.layers.Dense(128, activation='relu')(inputs)
        x = tf.keras.layers.Dense(64, activation='relu')(x)
        # æ½œåœ¨ç©ºé—´å‚æ•°
        z_mean = tf.keras.layers.Dense(self.latent_dim)(x)
        z_log_var = tf.keras.layers.Dense(self.latent_dim)(x)
        self.encoder = tf.keras.Model(inputs, [z_mean, z_log_var])
        return self.encoder
    
    def build_decoder(self):
        """æ„å»ºè§£ç å™¨"""
        latent_inputs = tf.keras.layers.Input(shape=(self.latent_dim,))
        x = tf.keras.layers.Dense(64, activation='relu')(latent_inputs)
        x = tf.keras.layers.Dense(128, activation='relu')(x)
        outputs = tf.keras.layers.Dense(self.input_dim, activation='sigmoid')(x)
        self.decoder = tf.keras.Model(latent_inputs, outputs)
        return self.decoder
    
    def sampling(self, args):
        """é‡å‚æ•°åŒ–é‡‡æ ·"""
        z_mean, z_log_var = args
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon
    
    def build_vae(self):
        """æ„å»ºå®Œæ•´VAEæ¨¡å‹"""
        # æ„å»ºç¼–ç å™¨å’Œè§£ç å™¨
        self.build_encoder()
        self.build_decoder()
        
        # VAEè¾“å…¥
        inputs = tf.keras.layers.Input(shape=(self.input_dim,))
        z_mean, z_log_var = self.encoder(inputs)
        
        # é‡‡æ ·å±‚
        z = tf.keras.layers.Lambda(self.sampling)([z_mean, z_log_var])
        
        # è§£ç å™¨è¾“å‡º
        outputs = self.decoder(z)
        
        # æ„å»ºVAEæ¨¡å‹
        self.vae = tf.keras.Model(inputs, outputs)
        
        # è‡ªå®šä¹‰æŸå¤±å‡½æ•°
        def vae_loss(y_true, y_pred):
            # é‡æ„æŸå¤±
            reconstruction_loss = tf.keras.losses.mse(y_true, y_pred)
            reconstruction_loss *= self.input_dim
            
            # KLæ•£åº¦æŸå¤±
            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
            kl_loss = tf.reduce_mean(kl_loss)
            kl_loss *= -0.5
            
            return tf.reduce_mean(reconstruction_loss + kl_loss)
        
        self.vae.compile(
            optimizer='adam',
            loss=vae_loss
        )
        
        return self.vae
    
    def train(self, X_train, epochs=100, batch_size=32):
        """è®­ç»ƒVAEæ¨¡å‹"""
        # æ•°æ®æ ‡å‡†åŒ–
        from sklearn.preprocessing import MinMaxScaler
        self.scaler = MinMaxScaler()
        X_scaled = self.scaler.fit_transform(X_train)
        
        # è®­ç»ƒæ¨¡å‹
        history = self.vae.fit(
            X_scaled, X_scaled,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.2,
            verbose=1
        )
        
        return history
    
    def detect_anomalies(self, X_test, threshold_percentile=95):
        """å¼‚å¸¸æ£€æµ‹"""
        # æ ‡å‡†åŒ–æ•°æ®
        X_scaled = self.scaler.transform(X_test)
        
        # é‡æ„æ•°æ®
        X_reconstructed = self.vae.predict(X_scaled)
        
        # è®¡ç®—é‡æ„è¯¯å·®
        reconstruction_errors = np.mean(np.square(X_scaled - X_reconstructed), axis=1)
        
        # è®¾å®šé˜ˆå€¼
        threshold = np.percentile(reconstruction_errors, threshold_percentile)
        
        # æ ‡è®°å¼‚å¸¸
        anomalies = reconstruction_errors > threshold
        
        return anomalies, reconstruction_errors, threshold

# ç”Ÿæˆé‡‘èå¼‚å¸¸æ•°æ®
def generate_financial_anomaly_data(n_samples=1000, n_features=10):
    """ç”ŸæˆåŒ…å«å¼‚å¸¸çš„é‡‘èæ•°æ®"""
    np.random.seed(42)
    
    # æ­£å¸¸æ•°æ®
    normal_data = []
    for i in range(int(n_samples * 0.9)):
        sample = []
        for j in range(n_features):
            # æ¨¡æ‹Ÿæ­£å¸¸çš„é‡‘èæŒ‡æ ‡
            value = 50 + 10 * np.sin(i * 0.1) + np.random.normal(0, 2)
            sample.append(value)
        normal_data.append(sample)
    
    # å¼‚å¸¸æ•°æ®
    anomaly_data = []
    for i in range(int(n_samples * 0.1)):
        sample = []
        for j in range(n_features):
            # å¼‚å¸¸å€¼ï¼šæç«¯æ³¢åŠ¨
            if np.random.random() < 0.5:
                value = np.random.choice([20, 80]) + np.random.normal(0, 5)
            else:
                value = 50 + np.random.normal(0, 15)
            sample.append(value)
        anomaly_data.append(sample)
    
    # åˆå¹¶å¹¶æ‰“ä¹±æ•°æ®
    all_data = normal_data + anomaly_data
    labels = [0] * len(normal_data) + [1] * len(anomaly_data)
    
    indices = np.random.permutation(len(all_data))
    data = np.array(all_data)[indices]
    labels = np.array(labels)[indices]
    
    return data, labels

# VAEå¼‚å¸¸æ£€æµ‹æ¼”ç¤º
def demo_vae_anomaly_detection():
    """VAEå¼‚å¸¸æ£€æµ‹æ¼”ç¤º"""
    # ç”Ÿæˆæ•°æ®
    data, true_labels = generate_financial_anomaly_data()
    
    # åˆ†å‰²æ•°æ®
    split_idx = int(0.8 * len(data))
    X_train = data[:split_idx]
    X_test = data[split_idx:]
    y_test = true_labels[split_idx:]
    
    # åˆ›å»ºå’Œè®­ç»ƒVAE
    vae = FinancialVAE(input_dim=10, latent_dim=5)
    vae.build_vae()
    
    print("è®­ç»ƒVAEæ¨¡å‹...")
    history = vae.train(X_train, epochs=50)
    
    # å¼‚å¸¸æ£€æµ‹
    anomalies, errors, threshold = vae.detect_anomalies(X_test)
    
    # è¯„ä¼°ç»“æœ
    from sklearn.metrics import classification_report
    print(f"\næ£€æµ‹åˆ° {np.sum(anomalies)} ä¸ªå¼‚å¸¸ç‚¹")
    print(f"çœŸå®å¼‚å¸¸ç‚¹: {np.sum(y_test)} ä¸ª")
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, anomalies.astype(int)))
    
    return vae, anomalies, errors

# è¿è¡ŒVAEæ¼”ç¤º
if __name__ == "__main__":
    vae_model, detected_anomalies, reconstruction_errors = demo_vae_anomaly_detection()
                                </code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- å®é™…åº”ç”¨æ¡ˆä¾‹ -->
                    <section id="practical-applications" class="content-section mb-5">
                        <h2>ğŸ’¼ å®é™…åº”ç”¨æ¡ˆä¾‹</h2>
                        
                        <div class="model-card">
                            <h5>ğŸ“ˆ æ™ºèƒ½é‡åŒ–äº¤æ˜“ç³»ç»Ÿ</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># åŸºäºæ·±åº¦å­¦ä¹ çš„é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
import yfinance as yf
from datetime import datetime, timedelta

class DeepTradingSystem:
    def __init__(self, symbols, lookback_window=60):
        self.symbols = symbols
        self.lookback_window = lookback_window
        self.models = {}
        self.scalers = {}
        self.positions = {symbol: 0 for symbol in symbols}
        self.portfolio_value = 100000  # åˆå§‹èµ„é‡‘
        
    def fetch_data(self, symbol, period="2y"):
        """è·å–è‚¡ç¥¨æ•°æ®"""
        stock = yf.Ticker(symbol)
        data = stock.history(period=period)
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        data['SMA_20'] = data['Close'].rolling(window=20).mean()
        data['SMA_50'] = data['Close'].rolling(window=50).mean()
        data['RSI'] = self.calculate_rsi(data['Close'])
        data['MACD'] = self.calculate_macd(data['Close'])
        data['Volatility'] = data['Close'].rolling(window=20).std()
        
        return data.dropna()
    
    def calculate_rsi(self, prices, window=14):
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    def calculate_macd(self, prices, fast=12, slow=26):
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        return ema_fast - ema_slow
    
    def prepare_features(self, data):
        """å‡†å¤‡æ¨¡å‹ç‰¹å¾"""
        features = ['Close', 'Volume', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Volatility']
        feature_data = data[features].values
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = MinMaxScaler()
        scaled_features = scaler.fit_transform(feature_data)
        
        return scaled_features, scaler
    
    def create_sequences(self, data, target):
        """åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®"""
        X, y = [], []
        for i in range(self.lookback_window, len(data)):
            X.append(data[i-self.lookback_window:i])
            y.append(target[i])
        return np.array(X), np.array(y)
    
    def build_model(self, input_shape):
        """æ„å»ºLSTMæ¨¡å‹"""
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(50, return_sequences=True, input_shape=input_shape),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.LSTM(50, return_sequences=True),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.LSTM(50),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(25),
            tf.keras.layers.Dense(1, activation='sigmoid')  # 0-1ä¹‹é—´çš„ä¿¡å·å¼ºåº¦
        ])
        
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model
    
    def train_model(self, symbol):
        """è®­ç»ƒå•ä¸ªè‚¡ç¥¨çš„æ¨¡å‹"""
        print(f"è®­ç»ƒ {symbol} çš„æ¨¡å‹...")
        
        # è·å–æ•°æ®
        data = self.fetch_data(symbol)
        
        # å‡†å¤‡ç‰¹å¾
        features, scaler = self.prepare_features(data)
        self.scalers[symbol] = scaler
        
        # åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆæœªæ¥æ”¶ç›Šç‡çš„æ–¹å‘ï¼‰
        future_returns = data['Close'].pct_change().shift(-1)
        target = (future_returns > 0).astype(int).values[:-1]  # 1è¡¨ç¤ºä¸Šæ¶¨ï¼Œ0è¡¨ç¤ºä¸‹è·Œ
        
        # åˆ›å»ºåºåˆ—
        X, y = self.create_sequences(features[:-1], target)
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•é›†
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # æ„å»ºå’Œè®­ç»ƒæ¨¡å‹
        model = self.build_model((self.lookback_window, features.shape[1]))
        
        # æ—©åœå’Œæ¨¡å‹æ£€æŸ¥ç‚¹
        callbacks = [
            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)
        ]
        
        history = model.fit(
            X_train, y_train,
            epochs=100,
            batch_size=32,
            validation_data=(X_test, y_test),
            callbacks=callbacks,
            verbose=0
        )
        
        self.models[symbol] = model
        
        # è¯„ä¼°æ¨¡å‹
        test_pred = model.predict(X_test)
        accuracy = np.mean((test_pred.flatten() > 0.5) == y_test)
        print(f"{symbol} æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.3f}")
        
        return history
    
    def generate_signal(self, symbol, current_data):
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        if symbol not in self.models:
            return 0
        
        model = self.models[symbol]
        scaler = self.scalers[symbol]
        
        # å‡†å¤‡å½“å‰æ•°æ®
        features = ['Close', 'Volume', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Volatility']
        feature_data = current_data[features].values
        scaled_data = scaler.transform(feature_data)
        
        # è·å–æœ€è¿‘çš„åºåˆ—
        if len(scaled_data) >= self.lookback_window:
            sequence = scaled_data[-self.lookback_window:].reshape(1, self.lookback_window, -1)
            prediction = model.predict(sequence, verbose=0)[0][0]
            
            # è½¬æ¢ä¸ºäº¤æ˜“ä¿¡å·
            if prediction > 0.7:  # å¼ºçƒˆçœ‹æ¶¨
                return 1
            elif prediction < 0.3:  # å¼ºçƒˆçœ‹è·Œ
                return -1
            else:
                return 0  # æŒæœ‰
        
        return 0
    
    def execute_trade(self, symbol, signal, current_price):
        """æ‰§è¡Œäº¤æ˜“"""
        position_size = self.portfolio_value * 0.1  # æ¯æ¬¡äº¤æ˜“ä½¿ç”¨10%çš„èµ„é‡‘
        
        if signal == 1 and self.positions[symbol] <= 0:  # ä¹°å…¥ä¿¡å·
            shares = position_size / current_price
            self.positions[symbol] += shares
            self.portfolio_value -= shares * current_price
            print(f"ä¹°å…¥ {symbol}: {shares:.2f} è‚¡ï¼Œä»·æ ¼: ${current_price:.2f}")
            
        elif signal == -1 and self.positions[symbol] > 0:  # å–å‡ºä¿¡å·
            shares = self.positions[symbol]
            self.positions[symbol] = 0
            self.portfolio_value += shares * current_price
            print(f"å–å‡º {symbol}: {shares:.2f} è‚¡ï¼Œä»·æ ¼: ${current_price:.2f}")
    
    def backtest(self, start_date, end_date):
        """å›æµ‹ç­–ç•¥"""
        print(f"\nå¼€å§‹å›æµ‹: {start_date} åˆ° {end_date}")
        
        portfolio_values = []
        dates = []
        
        # è·å–å›æµ‹æœŸé—´çš„æ•°æ®
        for symbol in self.symbols:
            data = self.fetch_data(symbol, period="1y")
            data = data[start_date:end_date]
            
            for date, row in data.iterrows():
                signal = self.generate_signal(symbol, data.loc[:date])
                self.execute_trade(symbol, signal, row['Close'])
                
                # è®¡ç®—å½“å‰ç»„åˆä»·å€¼
                total_value = self.portfolio_value
                for sym, pos in self.positions.items():
                    if pos > 0:
                        current_data = self.fetch_data(sym, period="1d")
                        if not current_data.empty:
                            total_value += pos * current_data['Close'].iloc[-1]
                
                portfolio_values.append(total_value)
                dates.append(date)
        
        # è®¡ç®—å›æµ‹ç»“æœ
        initial_value = 100000
        final_value = portfolio_values[-1] if portfolio_values else initial_value
        total_return = (final_value - initial_value) / initial_value
        
        print(f"\nå›æµ‹ç»“æœ:")
        print(f"åˆå§‹èµ„é‡‘: ${initial_value:,.2f}")
        print(f"æœ€ç»ˆä»·å€¼: ${final_value:,.2f}")
        print(f"æ€»æ”¶ç›Šç‡: {total_return:.2%}")
        
        return portfolio_values, dates

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºäº¤æ˜“ç³»ç»Ÿ
    symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA']
    trading_system = DeepTradingSystem(symbols)
    
    # è®­ç»ƒæ¨¡å‹
    for symbol in symbols:
        trading_system.train_model(symbol)
    
    # å›æµ‹ç­–ç•¥
    start_date = '2023-01-01'
    end_date = '2023-12-31'
    portfolio_values, dates = trading_system.backtest(start_date, end_date)
    
    print("\nğŸš€ æ·±åº¦å­¦ä¹ é‡åŒ–äº¤æ˜“ç³»ç»Ÿéƒ¨ç½²å®Œæˆï¼")
</code></pre>
                            </div>
                        </div>
                        
                        <div class="row mt-4">
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h5>ğŸ›¡ï¸ æ™ºèƒ½é£é™©ç®¡ç†ç³»ç»Ÿ</h5>
                                    <div class="code-example">
                                        <pre><code class="language-python"># åŸºäºæ·±åº¦å­¦ä¹ çš„é£é™©ç®¡ç†ç³»ç»Ÿ
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

class RiskManagementSystem:
    def __init__(self):
        self.anomaly_detector = None
        self.var_model = None
        self.stress_test_model = None
        self.scaler = StandardScaler()
        
    def detect_anomalies(self, transaction_data):
        """å¼‚å¸¸äº¤æ˜“æ£€æµ‹"""
        features = ['amount', 'frequency', 'time_of_day', 'location_risk']
        X = transaction_data[features]
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)
        
        # ä½¿ç”¨Isolation Forestæ£€æµ‹å¼‚å¸¸
        self.anomaly_detector = IsolationForest(
            contamination=0.1, random_state=42
        )
        anomalies = self.anomaly_detector.fit_predict(X_scaled)
        
        # è¿”å›å¼‚å¸¸äº¤æ˜“
        return transaction_data[anomalies == -1]
    
    def calculate_var(self, returns, confidence_level=0.05):
        """è®¡ç®—é£é™©ä»·å€¼(VaR)"""
        # ä½¿ç”¨LSTMé¢„æµ‹æ”¶ç›Šç‡åˆ†å¸ƒ
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(50, input_shape=(30, 1)),
            tf.keras.layers.Dense(25),
            tf.keras.layers.Dense(1)
        ])
        
        model.compile(optimizer='adam', loss='mse')
        
        # è®­ç»ƒæ¨¡å‹é¢„æµ‹æ”¶ç›Šç‡
        # ... è®­ç»ƒä»£ç  ...
        
        # è®¡ç®—VaR
        var = np.percentile(returns, confidence_level * 100)
        return var

# ä½¿ç”¨ç¤ºä¾‹
risk_system = RiskManagementSystem()
print("é£é™©ç®¡ç†ç³»ç»Ÿå·²å¯åŠ¨")
</code></pre>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h5>ğŸ” åæ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ</h5>
                                    <div class="code-example">
                                        <pre><code class="language-python"># æ·±åº¦å­¦ä¹ åæ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

class FraudDetectionSystem:
    def __init__(self):
        self.model = None
        self.feature_encoders = {}
        
    def preprocess_data(self, data):
        """æ•°æ®é¢„å¤„ç†"""
        # ç¼–ç åˆ†ç±»ç‰¹å¾
        categorical_features = ['merchant_category', 'card_type', 'location']
        
        for feature in categorical_features:
            if feature in data.columns:
                le = LabelEncoder()
                data[feature] = le.fit_transform(data[feature])
                self.feature_encoders[feature] = le
        
        return data
    
    def build_model(self, input_dim):
        """æ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu', input_dim=input_dim),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return model
    
    def train(self, transaction_data, labels):
        """è®­ç»ƒæ¨¡å‹"""
        # é¢„å¤„ç†æ•°æ®
        processed_data = self.preprocess_data(transaction_data)
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            processed_data, labels, test_size=0.2, random_state=42
        )
        
        # æ„å»ºæ¨¡å‹
        self.model = self.build_model(X_train.shape[1])
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            X_train, y_train,
            epochs=50,
            batch_size=32,
            validation_data=(X_test, y_test),
            verbose=1
        )
        
        return history
    
    def predict_fraud(self, transaction):
        """é¢„æµ‹æ¬ºè¯ˆæ¦‚ç‡"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        # é¢„å¤„ç†å•ä¸ªäº¤æ˜“
        processed_transaction = self.preprocess_data(transaction)
        
        # é¢„æµ‹
        fraud_probability = self.model.predict(processed_transaction)[0][0]
        
        return {
            'fraud_probability': fraud_probability,
            'is_fraud': fraud_probability > 0.5,
            'risk_level': 'High' if fraud_probability > 0.8 else 
                         'Medium' if fraud_probability > 0.5 else 'Low'
        }

# ä½¿ç”¨ç¤ºä¾‹
fraud_detector = FraudDetectionSystem()
print("åæ¬ºè¯ˆç³»ç»Ÿå·²åˆå§‹åŒ–")
</code></pre>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="model-card mt-4">
                            <h5>ğŸ“Š æ™ºèƒ½æŠ•èµ„ç»„åˆä¼˜åŒ–</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æŠ•èµ„ç»„åˆä¼˜åŒ–
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
import gym
from collections import deque
import random

class PortfolioOptimizationAgent:
    def __init__(self, state_size, action_size, learning_rate=0.001):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = deque(maxlen=2000)
        self.epsilon = 1.0  # æ¢ç´¢ç‡
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = learning_rate
        self.model = self._build_model()
        self.target_model = self._build_model()
        self.update_target_model()
        
    def _build_model(self):
        """æ„å»ºæ·±åº¦Qç½‘ç»œ"""
        model = tf.keras.Sequential([
            layers.Dense(128, activation='relu', input_dim=self.state_size),
            layers.Dropout(0.2),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(32, activation='relu'),
            layers.Dense(self.action_size, activation='linear')
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate),
            loss='mse'
        )
        
        return model
    
    def update_target_model(self):
        """æ›´æ–°ç›®æ ‡ç½‘ç»œ"""
        self.target_model.set_weights(self.model.get_weights())
    
    def remember(self, state, action, reward, next_state, done):
        """å­˜å‚¨ç»éªŒ"""
        self.memory.append((state, action, reward, next_state, done))
    
    def act(self, state):
        """é€‰æ‹©åŠ¨ä½œ"""
        if np.random.random() <= self.epsilon:
            return random.randrange(self.action_size)
        
        q_values = self.model.predict(state, verbose=0)
        return np.argmax(q_values[0])
    
    def replay(self, batch_size=32):
        """ç»éªŒå›æ”¾è®­ç»ƒ"""
        if len(self.memory) < batch_size:
            return
        
        batch = random.sample(self.memory, batch_size)
        states = np.array([e[0] for e in batch])
        actions = np.array([e[1] for e in batch])
        rewards = np.array([e[2] for e in batch])
        next_states = np.array([e[3] for e in batch])
        dones = np.array([e[4] for e in batch])
        
        states = np.squeeze(states)
        next_states = np.squeeze(next_states)
        
        targets = rewards + 0.95 * np.amax(self.target_model.predict(next_states, verbose=0), axis=1) * (1 - dones)
        targets_full = self.model.predict(states, verbose=0)
        
        ind = np.array([i for i in range(batch_size)])
        targets_full[[ind], [actions]] = targets
        
        self.model.fit(states, targets_full, epochs=1, verbose=0)
        
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

class PortfolioEnvironment:
    def __init__(self, data, initial_balance=10000):
        self.data = data
        self.initial_balance = initial_balance
        self.current_step = 0
        self.balance = initial_balance
        self.shares_held = np.zeros(len(data.columns))
        self.net_worth = initial_balance
        self.max_net_worth = initial_balance
        
    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        self.current_step = 0
        self.balance = self.initial_balance
        self.shares_held = np.zeros(len(self.data.columns))
        self.net_worth = self.initial_balance
        self.max_net_worth = self.initial_balance
        
        return self._get_observation()
    
    def _get_observation(self):
        """è·å–å½“å‰çŠ¶æ€"""
        frame = np.array([
            self.balance,
            self.net_worth,
            *self.shares_held,
            *self.data.iloc[self.current_step].values
        ])
        
        return frame
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        current_price = self.data.iloc[self.current_step]
        
        # åŠ¨ä½œæ˜ å°„ï¼š0=æŒæœ‰ï¼Œ1=ä¹°å…¥ï¼Œ2=å–å‡º
        if action == 1:  # ä¹°å…¥
            # å¹³å‡åˆ†é…èµ„é‡‘è´­ä¹°æ‰€æœ‰èµ„äº§
            total_possible = self.balance // len(current_price)
            for i, price in enumerate(current_price):
                if price > 0:
                    shares_bought = total_possible // price
                    self.shares_held[i] += shares_bought
                    self.balance -= shares_bought * price
                    
        elif action == 2:  # å–å‡º
            # å–å‡ºæ‰€æœ‰æŒä»“
            for i, price in enumerate(current_price):
                if self.shares_held[i] > 0:
                    self.balance += self.shares_held[i] * price
                    self.shares_held[i] = 0
        
        # è®¡ç®—å½“å‰å‡€å€¼
        self.net_worth = self.balance + np.sum(self.shares_held * current_price)
        
        # è®¡ç®—å¥–åŠ±
        reward = self.net_worth - self.max_net_worth
        if self.net_worth > self.max_net_worth:
            self.max_net_worth = self.net_worth
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        self.current_step += 1
        done = self.current_step >= len(self.data) - 1
        
        return self._get_observation(), reward, done, {}

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    stock_data = pd.DataFrame({
        'AAPL': 100 * np.cumprod(1 + np.random.normal(0.001, 0.02, 1000)),
        'GOOGL': 1000 * np.cumprod(1 + np.random.normal(0.001, 0.025, 1000)),
        'MSFT': 200 * np.cumprod(1 + np.random.normal(0.001, 0.02, 1000))
    }, index=dates)
    
    # åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“
    env = PortfolioEnvironment(stock_data)
    state_size = len(env._get_observation())
    action_size = 3  # æŒæœ‰ã€ä¹°å…¥ã€å–å‡º
    
    agent = PortfolioOptimizationAgent(state_size, action_size)
    
    # è®­ç»ƒæ™ºèƒ½ä½“
    episodes = 100
    for episode in range(episodes):
        state = env.reset()
        state = np.reshape(state, [1, state_size])
        total_reward = 0
        
        for time in range(500):
            action = agent.act(state)
            next_state, reward, done, _ = env.step(action)
            next_state = np.reshape(next_state, [1, state_size])
            
            agent.remember(state, action, reward, next_state, done)
            state = next_state
            total_reward += reward
            
            if done:
                agent.update_target_model()
                print(f"Episode: {episode+1}, Total Reward: {total_reward:.2f}, Net Worth: {env.net_worth:.2f}")
                break
            
            if len(agent.memory) > 32:
                agent.replay(32)
    
    print("\nğŸ¯ æ™ºèƒ½æŠ•èµ„ç»„åˆä¼˜åŒ–ç³»ç»Ÿè®­ç»ƒå®Œæˆï¼")
</code></pre>
                            </div>
                        </div>
                    </section>
    </main>
                    <!-- æ€§èƒ½å¯¹æ¯” -->
                    <section id="performance-comparison" class="content-section mb-5">
                        <h2>ğŸ“Š æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½å¯¹æ¯”</h2>
                        
                        <div class="performance-metrics">
                            <h5>ğŸ“ˆ æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># ä¸åŒæ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score

# æ¨¡å‹æ€§èƒ½æ•°æ®
performance_data = {
    'æ¨¡å‹': ['çº¿æ€§å›å½’', 'SVM', 'éšæœºæ£®æ—', 'LSTM', 'CNN', 'Transformer'],
    'å‡†ç¡®ç‡': [0.72, 0.78, 0.82, 0.85, 0.87, 0.91],
    'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)': [2, 15, 8, 45, 30, 120],
    'å†…å­˜ä½¿ç”¨(GB)': [0.5, 1.2, 2.1, 4.5, 3.8, 8.2],
    'æ¨ç†é€Ÿåº¦(ms)': [1, 5, 3, 15, 12, 25]
}

df = pd.DataFrame(performance_data)
print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨ï¼š")
print(df)

# å¯è§†åŒ–æ€§èƒ½å¯¹æ¯”
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# å‡†ç¡®ç‡å¯¹æ¯”
axes[0,0].bar(df['æ¨¡å‹'], df['å‡†ç¡®ç‡'], color='skyblue')
axes[0,0].set_title('æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”')
axes[0,0].set_ylabel('å‡†ç¡®ç‡')
axes[0,0].tick_params(axis='x', rotation=45)

# è®­ç»ƒæ—¶é—´å¯¹æ¯”
axes[0,1].bar(df['æ¨¡å‹'], df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'], color='lightcoral')
axes[0,1].set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
axes[0,1].set_ylabel('æ—¶é—´(åˆ†é’Ÿ)')
axes[0,1].tick_params(axis='x', rotation=45)

# å†…å­˜ä½¿ç”¨å¯¹æ¯”
axes[1,0].bar(df['æ¨¡å‹'], df['å†…å­˜ä½¿ç”¨(GB)'], color='lightgreen')
axes[1,0].set_title('å†…å­˜ä½¿ç”¨å¯¹æ¯”')
axes[1,0].set_ylabel('å†…å­˜(GB)')
axes[1,0].tick_params(axis='x', rotation=45)

# æ¨ç†é€Ÿåº¦å¯¹æ¯”
axes[1,1].bar(df['æ¨¡å‹'], df['æ¨ç†é€Ÿåº¦(ms)'], color='gold')
axes[1,1].set_title('æ¨ç†é€Ÿåº¦å¯¹æ¯”')
axes[1,1].set_ylabel('æ—¶é—´(ms)')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
</code></pre>
                            </div>
                        </div>
                        
                        <div class="performance-metrics">
                            <h5>ğŸ¯ å®é™…äº¤æ˜“ç­–ç•¥å›æµ‹å¯¹æ¯”</h5>
                            <div class="code-example">
                                <pre><code class="language-python"># ä¸åŒæ¨¡å‹çš„äº¤æ˜“ç­–ç•¥å›æµ‹
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

class StrategyBacktest:
    def __init__(self, model_name, predictions, actual_prices):
        self.model_name = model_name
        self.predictions = predictions
        self.actual_prices = actual_prices
        self.returns = []
        self.positions = []
        
    def generate_signals(self):
        """æ ¹æ®é¢„æµ‹ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        signals = []
        for i in range(1, len(self.predictions)):
            if self.predictions[i] > self.predictions[i-1] * 1.02:  # é¢„æµ‹ä¸Šæ¶¨2%ä»¥ä¸Š
                signals.append(1)  # ä¹°å…¥
            elif self.predictions[i] < self.predictions[i-1] * 0.98:  # é¢„æµ‹ä¸‹è·Œ2%ä»¥ä¸Š
                signals.append(-1)  # å–å‡º
            else:
                signals.append(0)  # æŒæœ‰
        return signals
    
    def calculate_returns(self):
        """è®¡ç®—ç­–ç•¥æ”¶ç›Š"""
        signals = self.generate_signals()
        portfolio_value = 10000  # åˆå§‹èµ„é‡‘
        position = 0
        
        for i, signal in enumerate(signals):
            current_price = self.actual_prices[i+1]
            prev_price = self.actual_prices[i]
            
            if signal == 1 and position == 0:  # ä¹°å…¥
                position = portfolio_value / current_price
                portfolio_value = 0
            elif signal == -1 and position > 0:  # å–å‡º
                portfolio_value = position * current_price
                position = 0
            
            # è®¡ç®—å½“å‰ç»„åˆä»·å€¼
            current_value = portfolio_value + position * current_price
            self.returns.append(current_value)
            
        return self.returns
    
    def get_metrics(self):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        returns = self.calculate_returns()
        if len(returns) == 0:
            return {}
            
        total_return = (returns[-1] - 10000) / 10000
        daily_returns = np.diff(returns) / returns[:-1]
        sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252)
        max_drawdown = self.calculate_max_drawdown(returns)
        
        return {
            'æ€»æ”¶ç›Šç‡': f"{total_return:.2%}",
            'å¤æ™®æ¯”ç‡': f"{sharpe_ratio:.2f}",
            'æœ€å¤§å›æ’¤': f"{max_drawdown:.2%}",
            'èƒœç‡': f"{self.calculate_win_rate():.1%}"
        }
    
    def calculate_max_drawdown(self, returns):
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        peak = returns[0]
        max_dd = 0
        for value in returns:
            if value > peak:
                peak = value
            dd = (peak - value) / peak
            if dd > max_dd:
                max_dd = dd
        return max_dd
    
    def calculate_win_rate(self):
        """è®¡ç®—èƒœç‡"""
        signals = self.generate_signals()
        wins = 0
        total_trades = 0
        
        for i, signal in enumerate(signals):
            if signal != 0:
                total_trades += 1
                if i < len(self.actual_prices) - 2:
                    future_return = (self.actual_prices[i+2] - self.actual_prices[i+1]) / self.actual_prices[i+1]
                    if (signal == 1 and future_return > 0) or (signal == -1 and future_return < 0):
                        wins += 1
        
        return wins / total_trades if total_trades > 0 else 0

# æ¨¡æ‹Ÿä¸åŒæ¨¡å‹çš„é¢„æµ‹ç»“æœ
np.random.seed(42)
days = 252  # ä¸€å¹´äº¤æ˜“æ—¥
actual_prices = 100 * np.cumprod(1 + np.random.normal(0.001, 0.02, days))

# ä¸åŒæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§
models = {
    'LSTM': np.random.normal(0.85, 0.1, days),
    'CNN': np.random.normal(0.82, 0.12, days),
    'Transformer': np.random.normal(0.88, 0.08, days),
    'éšæœºæ£®æ—': np.random.normal(0.75, 0.15, days)
}

# ç”Ÿæˆé¢„æµ‹ä»·æ ¼ï¼ˆåŸºäºå‡†ç¡®æ€§ï¼‰
results = {}
for model_name, accuracy in models.items():
    # æ ¹æ®å‡†ç¡®æ€§ç”Ÿæˆé¢„æµ‹
    noise = np.random.normal(0, 0.05, days)
    predictions = actual_prices * (1 + noise * (1 - accuracy))
    
    # å›æµ‹ç­–ç•¥
    backtest = StrategyBacktest(model_name, predictions, actual_prices)
    metrics = backtest.get_metrics()
    results[model_name] = metrics

# æ˜¾ç¤ºç»“æœ
print("\nğŸ“Š ä¸åŒæ¨¡å‹äº¤æ˜“ç­–ç•¥æ€§èƒ½å¯¹æ¯”ï¼š")
print("=" * 60)
for model, metrics in results.items():
    print(f"\nğŸ¤– {model}:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value}")
</code></pre>
                            </div>
                        </div>
                        
                        <div class="row mt-4">
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h6>âš¡ è®¡ç®—æ•ˆç‡å¯¹æ¯”</h6>
                                    <ul>
                                        <li><strong>çº¿æ€§æ¨¡å‹</strong>: è®­ç»ƒå¿«ï¼Œæ¨ç†å¿«ï¼Œå†…å­˜å°</li>
                                        <li><strong>æ ‘æ¨¡å‹</strong>: è®­ç»ƒä¸­ç­‰ï¼Œæ¨ç†å¿«ï¼Œè§£é‡Šæ€§å¥½</li>
                                        <li><strong>ç¥ç»ç½‘ç»œ</strong>: è®­ç»ƒæ…¢ï¼Œæ¨ç†ä¸­ç­‰ï¼Œç²¾åº¦é«˜</li>
                                        <li><strong>æ·±åº¦å­¦ä¹ </strong>: è®­ç»ƒå¾ˆæ…¢ï¼Œæ¨ç†æ…¢ï¼Œç²¾åº¦æœ€é«˜</li>
                                    </ul>
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="model-card">
                                    <h6>ğŸ¯ åº”ç”¨åœºæ™¯å»ºè®®</h6>
                                    <ul>
                                        <li><strong>é«˜é¢‘äº¤æ˜“</strong>: é€‰æ‹©æ¨ç†é€Ÿåº¦å¿«çš„æ¨¡å‹</li>
                                        <li><strong>é£é™©ç®¡ç†</strong>: é€‰æ‹©ç¨³å®šæ€§å¥½çš„æ¨¡å‹</li>
                                        <li><strong>é•¿æœŸæŠ•èµ„</strong>: é€‰æ‹©å‡†ç¡®ç‡é«˜çš„æ¨¡å‹</li>
                                        <li><strong>å®æ—¶å†³ç­–</strong>: å¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </section>
                        </div>
                    </section>
    </main>
                </div>
            </div>
        </div>
    </div>
    <!-- ç§»åŠ¨ç«¯èœå•æŒ‰é’® -->
    
    
    <!-- JavaScript -->
    <script>
        // é¡¶éƒ¨å¯¼èˆªåŠŸèƒ½
        document.addEventListener('DOMContentLoaded', function() {
            const navButtons = document.querySelectorAll('.nav-btn');
            const contentSections = document.querySelectorAll('.content-section');
            
            // é»˜è®¤æ˜¾ç¤ºç¬¬ä¸€ä¸ªç« èŠ‚
            if (contentSections.length > 0) {
                contentSections[0].classList.add('active');
            }
            if (navButtons.length > 0) {
                navButtons[0].classList.add('active');
            }
            
            // å¯¼èˆªæŒ‰é’®ç‚¹å‡»äº‹ä»¶
            navButtons.forEach(button => {
                button.addEventListener('click', function(e) {
                    e.preventDefault();
                    
                    // ç§»é™¤æ‰€æœ‰æ´»åŠ¨çŠ¶æ€
                    navButtons.forEach(btn => btn.classList.remove('active'));
                    contentSections.forEach(section => section.classList.remove('active'));
                    
                    // æ·»åŠ å½“å‰æ´»åŠ¨çŠ¶æ€
                    this.classList.add('active');
                    
                    // æ˜¾ç¤ºå¯¹åº”çš„å†…å®¹ç« èŠ‚
                    const targetSection = this.getAttribute('data-section');
                    const targetElement = document.getElementById(targetSection);
                    if (targetElement) {
                        targetElement.classList.add('active');
                        
                        // æ»šåŠ¨åˆ°å†…å®¹åŒºåŸŸ
                        targetElement.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                });
            });
            
            // é”®ç›˜å¯¼èˆªæ”¯æŒ
            document.addEventListener('keydown', function(e) {
                const activeIndex = Array.from(navButtons).findIndex(button => 
                    button.classList.contains('active'));
                
                if (e.key === 'ArrowRight' && activeIndex < navButtons.length - 1) {
                    e.preventDefault();
                    navButtons[activeIndex + 1].click();
                } else if (e.key === 'ArrowLeft' && activeIndex > 0) {
                    e.preventDefault();
                    navButtons[activeIndex - 1].click();
                }
            });
        });
        
        // æ·»åŠ è¿›åº¦æŒ‡ç¤ºå™¨
        function updateProgress() {
            const activeIndex = Array.from(document.querySelectorAll('.nav-btn'))
                .findIndex(button => button.classList.contains('active'));
            const totalSections = document.querySelectorAll('.nav-btn').length;
            const progress = ((activeIndex + 1) / totalSections) * 100;
            
            console.log(`å­¦ä¹ è¿›åº¦: ${Math.round(progress)}%`);
        }
    </script>
</body>
</html>